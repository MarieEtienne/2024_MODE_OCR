[
  {
    "objectID": "OCR_pollen.html",
    "href": "OCR_pollen.html",
    "title": "Effects of grazing on Swedish meadows",
    "section": "",
    "text": "Terrestrial ecosystems were dominated for several million years by large herbivorous mammals, which then declined at the end of the Pleistocene under the pressure of the first prehistoric human populations. The loss of these large herbivore species (aurochs, wild horses and anes, woolly rhinoceros…) was also synonymous with the loss of the ecosystem services they provided. (lundgren2020human?)\nFor several years, the “rewilding” movement has been aiming to restore these ecosystem services by reintroducing species into large European natural areas, and the present study seeks to assess the extent to which introduced herbivore species have an influence on vegetation. (garido2019experimental?)"
  },
  {
    "objectID": "OCR_pollen.html#data-visualization",
    "href": "OCR_pollen.html#data-visualization",
    "title": "Effects of grazing on Swedish meadows",
    "section": "1.Data visualization",
    "text": "1.Data visualization\n\nggplot(data=df)+\n  geom_boxplot(aes(x=treatment, y=num.species))+\n  geom_jitter(aes(x=treatment, y=num.species)) + \n  labs(x=\"Treatment\", y=\"Species richness\")\n\n\n\n\nFig 1 : Effect of grassland on species richness\n\n\n\n\nThe specific richness of grazed areas appears to be greater than in ungrazed areas @ref(fig:fig1).\n\nhyp1&lt;-lm(num.species~1,data=df)\nhyp0&lt;-lm(num.species~treatment,data=df)\nanova(hyp0,hyp1)\n\nAnalysis of Variance Table\n\nModel 1: num.species ~ treatment\nModel 2: num.species ~ 1\n  Res.Df    RSS Df Sum of Sq     F    Pr(&gt;F)    \n1    402 2280.1                                 \n2    403 2417.0 -1   -136.87 24.13 1.312e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nThe p-value is less than 0.05, so grazing has a significant effect on specific richness."
  },
  {
    "objectID": "OCR_pollen.html#choice-of-model-in-this-section-we-assume-that-grazing-treatment-depends-on-the-season-and-year-of-observation",
    "href": "OCR_pollen.html#choice-of-model-in-this-section-we-assume-that-grazing-treatment-depends-on-the-season-and-year-of-observation",
    "title": "Effects of grazing on Swedish meadows",
    "section": "2.Choice of model: in this section, we assume that grazing (treatment) depends on the season and year of observation",
    "text": "2.Choice of model: in this section, we assume that grazing (treatment) depends on the season and year of observation\n\nmodComplet&lt;-LinearModel(num.species~(treatment+season+year)*(treatment),data=df,selection = \"aic\")\nmodComplet\n\nResults for the complete model:\n==============================\nCall:\nLinearModel(formula = num.species ~ (treatment + season + year) * \n    (treatment), data = df, selection = \"aic\")\n\nResidual standard error: 2.201 on 394 degrees of freedom\nMultiple R-squared:  0.2103 \nF-statistic: 11.66 on 9 and 394 DF,  p-value: 2.732e-16 \nAIC = 647.3    BIC = 687.3\n\nResults for the model selected by AIC criterion:\n===============================================\nCall:\nLinearModel(formula = num.species ~ treatment + season + year + \n    treatment:year, data = df, selection = \"aic\")\n\nResidual standard error: 2.196 on 396 degrees of freedom\nMultiple R-squared:   0.21 \nF-statistic: 15.03 on 7 and 396 DF,  p-value: 1.95e-17 \nAIC = 643.5    BIC = 675.5\n\nFtest\n                    SS  df      MS F value    Pr(&gt;F)\ntreatment       107.32   1 107.315  22.255 3.315e-06\nseason          194.60   2  97.300  20.178 4.518e-09\nyear            133.15   2  66.575  13.806 1.599e-06\ntreatment:year   41.47   2  20.734   4.300   0.01421\nResiduals      1909.51 396   4.822                  \n\nTtest\n                                    Estimate Std. Error t value  Pr(&gt;|t|)\n(Intercept)                         8.109457   0.115553 70.1793 &lt; 2.2e-16\ntreatment - grazed                  0.525042   0.111295  4.7176 3.315e-06\ntreatment - ungrazed               -0.525042   0.111295 -4.7176 3.315e-06\nseason - autumn                    -0.857605   0.154433 -5.5532 5.150e-08\nseason - spring                     0.127684   0.179319  0.7120 0.4768541\nseason - summer                     0.729922   0.154433  4.7265 3.180e-06\nyear - 2014                         0.924700   0.178175  5.1898 3.370e-07\nyear - 2015                        -0.358379   0.154465 -2.3201 0.0208409\nyear - 2016                        -0.566321   0.154469 -3.6662 0.0002797\ntreatment - grazed : year - 2014   -0.456895   0.168272 -2.7152 0.0069130\ntreatment - ungrazed : year - 2014  0.456895   0.168272  2.7152 0.0069130\ntreatment - grazed : year - 2015    0.089175   0.151774  0.5876 0.5571677\ntreatment - ungrazed : year - 2015 -0.089175   0.151774 -0.5876 0.5571677\ntreatment - grazed : year - 2016    0.367720   0.151555  2.4263 0.0156989\ntreatment - ungrazed : year - 2016 -0.367720   0.151555 -2.4263 0.0156989\n\n\nThe results for the full model are as follows: p-value: 2.554e-16, AIC = 649, BIC = 681. However, the model chosen according to the AIC criterion shows the following results: p-value: 1.41e-17, AIC = 645.2 and BIC = 669.2. As the AIC criterion is smaller for this model than for the full model, we choose to retain: num.species ~ treatment + season + year + treatment:year. There is therefore an interaction between the pasture and its year of observation."
  },
  {
    "objectID": "OCR_pollen.html#validation-of-the-chosen-model-with-the-bartlett-test",
    "href": "OCR_pollen.html#validation-of-the-chosen-model-with-the-bartlett-test",
    "title": "Effects of grazing on Swedish meadows",
    "section": "3.Validation of the chosen model with the Bartlett test",
    "text": "3.Validation of the chosen model with the Bartlett test\n\nmodelAIC&lt;-lm(num.species~treatment+season+year+treatment:year,data=df)\n\nres&lt;-residuals(modelAIC)\nboxplot(res~treatment,data=df)\n\n\n\n\nValidation of the chosen model with the Bartlett test\n\n\n\nbartlett.test(res~treatment,data=df)\n\n\n    Bartlett test of homogeneity of variances\n\ndata:  res by treatment\nBartlett's K-squared = 1.9684, df = 1, p-value = 0.1606\n\nboxplot(res~season,data=df)\n\n\n\n\nValidation of the chosen model with the Bartlett test\n\n\n\nbartlett.test(res~season,data=df)\n\n\n    Bartlett test of homogeneity of variances\n\ndata:  res by season\nBartlett's K-squared = 4.3645, df = 2, p-value = 0.1128\n\nboxplot(res~year,data=df)\n\n\n\n\nValidation of the chosen model with the Bartlett test\n\n\n\nbartlett.test(res~year,data=df)\n\n\n    Bartlett test of homogeneity of variances\n\ndata:  res by year\nBartlett's K-squared = 3.7679, df = 2, p-value = 0.152\n\nboxplot(res~treatment:year,data=df)\n\n\n\n\nValidation of the chosen model with the Bartlett test\n\n\n\ndf$interaction &lt;- interaction(df$treatment, df$year)\nbartlett.test(res ~ interaction, data = df)\n\n\n    Bartlett test of homogeneity of variances\n\ndata:  res by interaction\nBartlett's K-squared = 6.3, df = 5, p-value = 0.2781\n\n\nFor the Bartlett tests, the p-values are all greater than 0.05, which means that homoscedasticity is respected for all our parameters, or that the variances are all equal for all our observations @ref(fig:fig2)."
  },
  {
    "objectID": "OCR_pollen.html#residual-normality-test-with-shapiro",
    "href": "OCR_pollen.html#residual-normality-test-with-shapiro",
    "title": "Effects of grazing on Swedish meadows",
    "section": "4. Residual normality test with Shapiro",
    "text": "4. Residual normality test with Shapiro\n\nhist(res,main=\"Histogramme residus\",xlab=\"Residus\")\n\n\n\n\nResidual normality test with Shapiro\n\n\n\nshapiro.test(res)\n\n\n    Shapiro-Wilk normality test\n\ndata:  res\nW = 0.99555, p-value = 0.3061\n\n\nResidual normality is respected, as our p-value is greater than 0.05: the data are compatible with a normal distribution. Our linear model is therefore valid, as residual normality is a key assumption for applying this model @ref(fig:fig3).\nConclusion:  Species richness therefore depends on grazing, season and year, as well as on the interaction grazing:year."
  },
  {
    "objectID": "OCR_pollen.html#effect-of-grazing-on-the-plant-height",
    "href": "OCR_pollen.html#effect-of-grazing-on-the-plant-height",
    "title": "Effects of grazing on Swedish meadows",
    "section": "1. Effect of grazing on the plant height",
    "text": "1. Effect of grazing on the plant height\nPotential relationship between Height and effect of treatment :\nLet’s start by representing plant size as a function of the applied treatment (grazing or no grazing) to have an idea of the possible effect.\n\nboxplot(df$logHeight.score~df$treatment, varwidth = TRUE, ylab = \"plant height (log)\", xlab = \"Treatment\", col='darkgrey', main = \"\", title = \"effect of grazing on the height\")\n\n\n\n\nEffect of treatment on height graph\n\n\n\nggplot(data=df)+\n  geom_boxplot(aes(x=treatment, y=logHeight.score))+\n  geom_jitter(aes(x=treatment, y=logHeight.score))+\n  ylab(\"Plant height (log)\") +\n  xlab(\"Treatment\")\n\n\n\n\nEffect of treatment on height graph\n\n\n\n\nInterpretation :\nThe median for the no grazing treatment is slightly higher than for the grazing treatment @ref(fig:fig4). The data also seems slightly more dispersed and spread out. So we could say that the plants without grazing are potentially higher than the ones which had the treatment.\nStatistical analysis of the relationship between Height and effect of treatment :\nWe saw earlier that there could be a potential effect of treatment on the plant’s height, we now want to know if this effect is really significant.\nWe perform an ANOVA to compare a random model with our model.\nSignificance test: Hypothesis H0: Grazing has no effect on plant height. Hypothesis H1: Grazing has an effect on plant height.\nThe p-value is 2.39e-4 &lt; 0.05. The test is significant, so hypothesis H0 is rejected. Grazing significantly reduces plant size."
  },
  {
    "objectID": "OCR_pollen.html#effect-of-grazing-on-the-seed-mass",
    "href": "OCR_pollen.html#effect-of-grazing-on-the-seed-mass",
    "title": "Effects of grazing on Swedish meadows",
    "section": "2. Effect of grazing on the seed mass",
    "text": "2. Effect of grazing on the seed mass\nNow, let’s study the seed mass of plants in relation to grazing.\nPotential relationship between seed mass and effect of treatment :\nLet’s start by representing the seed mass of plants as a function of the applied treatment (grazing or no grazing) to have an idea of the possible effect.\n\nboxplot(df$logSeedMass.score~df$treatment, varwidth = TRUE, ylab = \"Seed mass (log)\", xlab = \"Treatment\", col='darkgrey', main = \"\", title = \"effect of grazing on seed mass\")\n\n\n\n\nEffect of treatment on seed mass\n\n\n\nggplot(data=df)+\n  geom_boxplot(aes(x=treatment, y=logSeedMass.score))+\n  geom_jitter(aes(x=treatment, y=logSeedMass.score))+\n  labs(y = \"Seed mass (log)\", x = \"Treatment\")\n\n\n\n\nEffect of treatment on seed mass\n\n\n\n\nInterpretation :\nThe medians are almost identical @ref(fig:fig5). The data for the no grazing treatment also seems more dispersed and spread out. So we could say that there is potentially no effect of treatment on seed mass.\nStatistical analysis of the relationship between Height and effect of treatment :\nWe saw earlier that there could be no potential effect of treatment on seed mass. We now want to know if there is no significant difference.\nWe perform an ANOVA to compare the model where we only consider the effect of grazing with a model where the effect of grazing is random.\nSignificance test: Hypothesis H0: Grazing has no effect on seed mass. Hypothesis H1: Grazing has an effect on seed mass.\n\nhyp2&lt;-lm(logSeedMass.score~1,data=df)\nhyp3&lt;-lm(logSeedMass.score~treatment,data=df)\nanova(hyp2,hyp3)\n\nAnalysis of Variance Table\n\nModel 1: logSeedMass.score ~ 1\nModel 2: logSeedMass.score ~ treatment\n  Res.Df    RSS Df Sum of Sq      F Pr(&gt;F)\n1    403 457.54                           \n2    402 456.58  1   0.96445 0.8492 0.3573\n\n\nThe p-value = 0.3573 &gt; 0.05, so the seed mass under hypothesis H1 is not significantly different from that under hypothesis H0. We can conclude that there is no effect of grazing on seed mass."
  },
  {
    "objectID": "OCR_pollen.html#is-the-height-of-plants-only-affected-by-grazing",
    "href": "OCR_pollen.html#is-the-height-of-plants-only-affected-by-grazing",
    "title": "Effects of grazing on Swedish meadows",
    "section": "3. Is the height of plants only affected by grazing ?",
    "text": "3. Is the height of plants only affected by grazing ?\nWe will now analyze the effect of grazing on plant size more precisely. We want to know if the size is influenced by grazing (treatment) alone or by its interaction with other factors.\nFor this analysis, we will test the effects of grazing and its interaction with other factors on plant size through model analysis using the BIC criterion.\n\nhyp4&lt;-LinearModel(logHeight.score~(treatment+season+year+observer+logSeedMass.score+RatioPoll+R.score+C.score+S.score)*\n                    (treatment+season+year+observer+logSeedMass.score+RatioPoll+R.score+C.score+S.score), data=df, selection = \"bic\")\nhyp4\n\nResults for the complete model:\n==============================\nCall:\nLinearModel(formula = logHeight.score ~ (treatment + season + \n    year + observer + logSeedMass.score + RatioPoll + R.score + \n    C.score + S.score) * (treatment + season + year + observer + \n    logSeedMass.score + RatioPoll + R.score + C.score + S.score), \n    data = df, selection = \"bic\")\n\nResidual standard error: 0.6471 on 351 degrees of freedom\nMultiple R-squared:  0.8309 \nF-statistic: 33.16 on 52 and 351 DF,  p-value: 1.753e-106 \nAIC = -302.5    BIC = -90.45\n\nResults for the model selected by BIC criterion:\n===============================================\nCall:\nLinearModel(formula = logHeight.score ~ treatment + logSeedMass.score + \n    RatioPoll + R.score + C.score + S.score + treatment:logSeedMass.score + \n    treatment:RatioPoll + logSeedMass.score:R.score + logSeedMass.score:S.score + \n    RatioPoll:C.score + R.score:C.score + C.score:S.score, data = df, \n    selection = \"bic\")\n\nResidual standard error: 0.6667 on 390 degrees of freedom\nMultiple R-squared:  0.8005 \nF-statistic: 120.4 on 13 and 390 DF,  p-value: 1.368e-127 \nAIC = -313.8    BIC = -257.8\n\nFtest\n                                 SS  df     MS  F value    Pr(&gt;F)\ntreatment                     0.689   1  0.689   1.5498 0.2139129\nlogSeedMass.score             4.090   1  4.090   9.2027 0.0025783\nRatioPoll                     2.833   1  2.833   6.3736 0.0119787\nR.score                       0.024   1  0.024   0.0550 0.8147233\nC.score                      81.942   1 81.942 184.3546 &lt; 2.2e-16\nS.score                       0.018   1  0.018   0.0397 0.8420779\ntreatment:logSeedMass.score   4.390   1  4.390   9.8773 0.0018013\ntreatment:RatioPoll           3.009   1  3.009   6.7695 0.0096260\nlogSeedMass.score:R.score     6.250   1  6.250  14.0607 0.0002038\nlogSeedMass.score:S.score    11.658   1 11.658  26.2274 4.779e-07\nRatioPoll:C.score             3.110   1  3.110   6.9962 0.0084984\nR.score:C.score               4.854   1  4.854  10.9205 0.0010390\nC.score:S.score               4.599   1  4.599  10.3465 0.0014055\nResiduals                   173.347 390  0.444                   \n\nTtest\n                                           Estimate Std. Error  t value\n(Intercept)                               -2.771317   0.181401 -15.2773\ntreatment - grazed                        -0.057289   0.046019  -1.2449\ntreatment - ungrazed                       0.057289   0.046019   1.2449\nlogSeedMass.score                          0.238069   0.078477   3.0336\nRatioPoll                                 -0.073921   0.029280  -2.5246\nR.score                                    0.338994   1.445631   0.2345\nC.score                                    6.611139   0.486911  13.5777\nS.score                                   -0.272817   1.368404  -0.1994\ntreatment - grazed : logSeedMass.score    -0.118967   0.037854  -3.1428\ntreatment - ungrazed : logSeedMass.score   0.118967   0.037854   3.1428\ntreatment - grazed : RatioPoll             0.042710   0.016415   2.6018\ntreatment - ungrazed : RatioPoll          -0.042710   0.016415  -2.6018\nlogSeedMass.score : R.score                2.521365   0.672407   3.7498\nlogSeedMass.score : S.score               -3.791413   0.740326  -5.1213\nRatioPoll : C.score                        0.221980   0.083923   2.6450\nR.score : C.score                        -13.670288   4.136717  -3.3046\nC.score : S.score                         13.387882   4.162125   3.2166\n                                          Pr(&gt;|t|)\n(Intercept)                              &lt; 2.2e-16\ntreatment - grazed                       0.2139129\ntreatment - ungrazed                     0.2139129\nlogSeedMass.score                        0.0025783\nRatioPoll                                0.0119787\nR.score                                  0.8147233\nC.score                                  &lt; 2.2e-16\nS.score                                  0.8420779\ntreatment - grazed : logSeedMass.score   0.0018013\ntreatment - ungrazed : logSeedMass.score 0.0018013\ntreatment - grazed : RatioPoll           0.0096260\ntreatment - ungrazed : RatioPoll         0.0096260\nlogSeedMass.score : R.score              0.0002038\nlogSeedMass.score : S.score              4.779e-07\nRatioPoll : C.score                      0.0084984\nR.score : C.score                        0.0010390\nC.score : S.score                        0.0014055\n\n\nAfter the analysis, the final model with the lower BIC is : logH ~ treatment + logS + RatioPoll + R.score + C.score + S.score + treatment:logS + treatment:RatioPoll + logS:R.score + logS:S.score + RatioPoll:C.score + R.score:C.score + C.score:S.score\nThe results show that the factor treatment (grazing) by itself has no significant effect (p-value = 0.21 &gt; 0.05) on the height of plants and same goes for R.score and S.score. This means that the effect of treatment that we previously saw was mainly due to interactions between treatment and other factors."
  },
  {
    "objectID": "OCR_pollen.html#visualization-of-data-and-one-factor-analysis-of-variance",
    "href": "OCR_pollen.html#visualization-of-data-and-one-factor-analysis-of-variance",
    "title": "Effects of grazing on Swedish meadows",
    "section": "1. Visualization of data and one-factor analysis of variance",
    "text": "1. Visualization of data and one-factor analysis of variance\n\n# Boxplot \npar(mfrow=c(1,2))\n\n\nboxplot(df$RatioPoll~df$treatment, varwidth = TRUE, ylab = \"Ratio Pollinisation\", xlab = \"treatment\", col='blue', main = \"\")\n\n\n\n\nData visualization\n\n\n\n\nThe boxplot @ref(fig:fig6) shows no significant differences between plots grazed and those not grazed.\n\n# Anova\npoll1&lt;-lm(RatioPoll~1,data=df)\npoll2&lt;-lm(RatioPoll~treatment,data=df)\nanova(poll1,poll2)\n\nAnalysis of Variance Table\n\nModel 1: RatioPoll ~ 1\nModel 2: RatioPoll ~ treatment\n  Res.Df    RSS Df Sum of Sq      F  Pr(&gt;F)  \n1    403 2956.5                              \n2    402 2931.7  1    24.786 3.3987 0.06598 .\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nThe P-value is not significant at the 5% threshold, so we reject the hypothesis that grazing has an effect on the RatioPoll. The Anova test confirms our graphical observation: there is no difference between the grazed and natural plots."
  },
  {
    "objectID": "OCR_pollen.html#model-test",
    "href": "OCR_pollen.html#model-test",
    "title": "Effects of grazing on Swedish meadows",
    "section": "2.Model test",
    "text": "2.Model test\n\npoll3&lt;-LinearModel(RatioPoll~(treatment+season+year+observer+R.score+S.score+C.score)*\n                     (treatment+season+year+observer+R.score+S.score+C.score),data=df,selection = \"aic\")\npoll3\n\nResults for the complete model:\n==============================\nCall:\nLinearModel(formula = RatioPoll ~ (treatment + season + year + \n    observer + R.score + S.score + C.score) * (treatment + season + \n    year + observer + R.score + S.score + C.score), data = df, \n    selection = \"aic\")\n\nResidual standard error: 2.562 on 370 degrees of freedom\nMultiple R-squared:  0.1787 \nF-statistic: 2.439 on 33 and 370 DF,  p-value: 3.229e-05 \nAIC = 792.6    BIC = 928.6\n\nResults for the model selected by AIC criterion:\n===============================================\nCall:\nLinearModel(formula = RatioPoll ~ treatment + season + year + \n    R.score + S.score + C.score + treatment:R.score + treatment:C.score + \n    season:R.score + season:S.score + year:R.score + year:C.score + \n    R.score:C.score + S.score:C.score, data = df, selection = \"aic\")\n\nResidual standard error: 2.537 on 383 degrees of freedom\nMultiple R-squared:  0.1662 \nF-statistic: 3.816 on 20 and 383 DF,  p-value: 1.16e-07 \nAIC = 772.7    BIC = 856.7\n\nFtest\n                       SS  df     MS F value   Pr(&gt;F)\ntreatment            0.46   1  0.463  0.0719 0.788707\nseason              37.94   2 18.970  2.9472 0.053681\nyear                11.28   2  5.640  0.8762 0.417215\nR.score             32.37   1 32.371  5.0291 0.025497\nS.score              2.80   1  2.803  0.4354 0.509748\nC.score              0.00   1  0.001  0.0002 0.990072\ntreatment:R.score   52.95   1 52.954  8.2269 0.004356\ntreatment:C.score   65.29   1 65.287 10.1429 0.001567\nseason:R.score      31.54   2 15.770  2.4500 0.087647\nseason:S.score      24.73   2 12.366  1.9211 0.147854\nyear:R.score        43.06   2 21.532  3.3451 0.036290\nyear:C.score        26.21   2 13.107  2.0362 0.131930\nR.score:C.score     28.24   1 28.243  4.3878 0.036853\nS.score:C.score     19.80   1 19.804  3.0767 0.080223\nResiduals         2465.27 383  6.437                 \n\nTtest\n                                 Estimate Std. Error t value Pr(&gt;|t|)\n(Intercept)                      0.216628   0.554131  0.3909 0.696064\ntreatment - grazed               0.100399   0.374374  0.2682 0.788707\ntreatment - ungrazed            -0.100399   0.374374 -0.2682 0.788707\nseason - autumn                 -0.982083   0.406102 -2.4183 0.016058\nseason - spring                  0.456660   0.475236  0.9609 0.337202\nseason - summer                  0.525422   0.455257  1.1541 0.249170\nyear - 2014                      0.748663   0.571102  1.3109 0.190674\nyear - 2015                     -0.303283   0.479913 -0.6320 0.527794\nyear - 2016                     -0.445380   0.480008 -0.9279 0.354064\nR.score                         12.133698   5.410655  2.2426 0.025497\nS.score                         -3.199071   4.848189 -0.6598 0.509748\nC.score                          0.025179   2.022135  0.0125 0.990072\ntreatment - grazed : R.score     6.020273   2.098934  2.8683 0.004356\ntreatment - ungrazed : R.score  -6.020273   2.098934 -2.8683 0.004356\ntreatment - grazed : C.score    -3.909367   1.227511 -3.1848 0.001567\ntreatment - ungrazed : C.score   3.909367   1.227511  3.1848 0.001567\nseason - autumn : R.score        5.258101   2.401900  2.1891 0.029190\nseason - spring : R.score       -2.739087   3.015881 -0.9082 0.364332\nseason - summer : R.score       -2.519015   2.651050 -0.9502 0.342612\nseason - autumn : S.score        4.873384   3.018905  1.6143 0.107288\nseason - spring : S.score       -6.191616   3.371962 -1.8362 0.067102\nseason - summer : S.score        1.318232   2.969647  0.4439 0.657364\nyear - 2014 : R.score           -7.443157   3.103236 -2.3985 0.016939\nyear - 2015 : R.score            2.072046   2.435265  0.8509 0.395384\nyear - 2016 : R.score            5.371111   2.368027  2.2682 0.023874\nyear - 2014 : C.score            2.467530   1.456367  1.6943 0.091020\nyear - 2015 : C.score           -0.196500   1.156556 -0.1699 0.865178\nyear - 2016 : C.score           -2.271030   1.181944 -1.9214 0.055419\nR.score : C.score              -35.308042  16.855766 -2.0947 0.036853\nS.score : C.score               26.694777  15.219008  1.7540 0.080223\n\n\nThe model proposed by R does have a lower BIC than our initial model. However, some of the interactions retained by R have no significant effect. We decided to test a model without these interactions."
  },
  {
    "objectID": "OCR_pollen.html#model-adjustment",
    "href": "OCR_pollen.html#model-adjustment",
    "title": "Effects of grazing on Swedish meadows",
    "section": "3.Model adjustment",
    "text": "3.Model adjustment\n\npoll4&lt;-lm(RatioPoll~( treatment + season + year + \n    observer + R.score + S.score + C.score + treatment:R.score + \n    treatment:C.score + year:C.score + \n    observer:R.score + R.score:C.score),data=df)\nsummary(poll4)\n\n\nCall:\nlm(formula = RatioPoll ~ (treatment + season + year + observer + \n    R.score + S.score + C.score + treatment:R.score + treatment:C.score + \n    year:C.score + observer:R.score + R.score:C.score), data = df)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-4.5392 -1.1080 -0.4220  0.2947 29.6572 \n\nCoefficients: (1 not defined because of singularities)\n                           Estimate Std. Error t value Pr(&gt;|t|)   \n(Intercept)                 1.09759    1.02902   1.067  0.28680   \ntreatmentungrazed          -0.44174    0.74260  -0.595  0.55229   \nseasonspring               -0.87180    0.35892  -2.429  0.01559 * \nseasonsummer                0.07737    0.30486   0.254  0.79979   \nyear2015                   -1.02099    0.89211  -1.144  0.25313   \nyear2016                   -0.67267    0.91384  -0.736  0.46212   \nobserverB                        NA         NA      NA       NA   \nR.score                     4.06738    6.16403   0.660  0.50974   \nS.score                     4.06607    2.32128   1.752  0.08062 . \nC.score                     0.06155    3.33199   0.018  0.98527   \ntreatmentungrazed:R.score -11.89261    4.19861  -2.833  0.00486 **\ntreatmentungrazed:C.score   7.72917    2.47671   3.121  0.00194 **\nyear2015:C.score           -3.34651    2.37134  -1.411  0.15898   \nyear2016:C.score           -5.55088    2.36817  -2.344  0.01958 * \nobserverB:R.score          10.16478    4.53211   2.243  0.02547 * \nR.score:C.score           -11.47597   14.17758  -0.809  0.41875   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.582 on 389 degrees of freedom\nMultiple R-squared:  0.123, Adjusted R-squared:  0.09146 \nF-statistic: 3.898 on 14 and 389 DF,  p-value: 2.989e-06\n\n\nWe have observed that the R.score:C.score interaction is not significant, we test a new model without it.\n\npoll5&lt;-lm(RatioPoll~( treatment + season + year + \n    observer + R.score + S.score + C.score + treatment:R.score + \n    treatment:C.score + year:C.score + \n    observer:R.score ),data=df)\nsummary(poll5)\n\n\nCall:\nlm(formula = RatioPoll ~ (treatment + season + year + observer + \n    R.score + S.score + C.score + treatment:R.score + treatment:C.score + \n    year:C.score + observer:R.score), data = df)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-4.1056 -1.0829 -0.3976  0.2776 29.5917 \n\nCoefficients: (1 not defined because of singularities)\n                          Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)                 1.5512     0.8627   1.798  0.07294 .  \ntreatmentungrazed          -0.6179     0.7097  -0.871  0.38443    \nseasonspring               -0.8549     0.3582  -2.387  0.01746 *  \nseasonsummer                0.0786     0.3047   0.258  0.79658    \nyear2015                   -1.1152     0.8841  -1.261  0.20794    \nyear2016                   -0.7649     0.9063  -0.844  0.39919    \nobserverB                       NA         NA      NA       NA    \nR.score                     0.9309     4.7917   0.194  0.84607    \nS.score                     4.3275     2.2977   1.883  0.06039 .  \nC.score                    -1.8351     2.3679  -0.775  0.43881    \ntreatmentungrazed:R.score -12.5848     4.1088  -3.063  0.00234 ** \ntreatmentungrazed:C.score   8.7848     2.1046   4.174 3.69e-05 ***\nyear2015:C.score           -3.1669     2.3599  -1.342  0.18039    \nyear2016:C.score           -5.3600     2.3554  -2.276  0.02341 *  \nobserverB:R.score          10.4201     4.5191   2.306  0.02165 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.581 on 390 degrees of freedom\nMultiple R-squared:  0.1215,    Adjusted R-squared:  0.09227 \nF-statistic: 4.151 on 13 and 390 DF,  p-value: 1.82e-06\n\n\nThe p-value of S.score is not significant and does not appear in any significant interactions. We therefore decide to remove it\n\npoll6&lt;-lm(RatioPoll~( treatment + season + year + \n    observer + R.score + C.score + treatment:R.score + \n    treatment:C.score + year:C.score + \n    observer:R.score ),data=df)\nsummary(poll6)\n\n\nCall:\nlm(formula = RatioPoll ~ (treatment + season + year + observer + \n    R.score + C.score + treatment:R.score + treatment:C.score + \n    year:C.score + observer:R.score), data = df)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-4.3524 -1.1314 -0.4478  0.2407 29.8179 \n\nCoefficients: (1 not defined because of singularities)\n                          Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)                 1.7220     0.8607   2.001  0.04612 *  \ntreatmentungrazed          -0.5616     0.7113  -0.789  0.43034    \nseasonspring               -0.7979     0.3580  -2.229  0.02641 *  \nseasonsummer                0.1205     0.3049   0.395  0.69286    \nyear2015                   -1.1891     0.8861  -1.342  0.18038    \nyear2016                   -0.8061     0.9090  -0.887  0.37575    \nobserverB                       NA         NA      NA       NA    \nR.score                     1.2011     4.8051   0.250  0.80275    \nC.score                    -0.8569     2.3177  -0.370  0.71179    \ntreatmentungrazed:R.score -11.2879     4.0639  -2.778  0.00574 ** \ntreatmentungrazed:C.score   8.3717     2.1000   3.987    8e-05 ***\nyear2015:C.score           -3.6014     2.3562  -1.528  0.12721    \nyear2016:C.score           -5.9907     2.3390  -2.561  0.01081 *  \nobserverB:R.score          11.4602     4.4998   2.547  0.01125 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.589 on 391 degrees of freedom\nMultiple R-squared:  0.1136,    Adjusted R-squared:  0.08635 \nF-statistic: 4.174 on 12 and 391 DF,  p-value: 3.488e-06"
  },
  {
    "objectID": "OCR_pollen.html#validity-of-the-chosen-model",
    "href": "OCR_pollen.html#validity-of-the-chosen-model",
    "title": "Effects of grazing on Swedish meadows",
    "section": "4. Validity of the chosen model",
    "text": "4. Validity of the chosen model\nNow,we want to check the normality of residuals\n\npollfinal&lt;-lm(RatioPoll~(treatment + season + year + \n    observer + R.score + C.score + treatment:R.score + \n    treatment:C.score + year:C.score + \n    observer:R.score ),data=df)\nres&lt;-residuals(pollfinal)\nhist(res,main=\"Histogram residuals\",xlab=\"Residus\")\n\n\n\n\nCheck of the normality of residuals\n\n\n\nshapiro.test(res)\n\n\n    Shapiro-Wilk normality test\n\ndata:  res\nW = 0.58302, p-value &lt; 2.2e-16\n\n\nThe residuals are not normally distributed @ref(fig:fig7). We’re going to try and do some transformations using log and sqrt.\n\npoll7&lt;-lm(log(RatioPoll+1)~(treatment + season + year + \n    observer + R.score + C.score + treatment:R.score + \n    treatment:C.score + year:C.score + \n    observer:R.score ),data=df )\nsummary(poll7)\n\n\nCall:\nlm(formula = log(RatioPoll + 1) ~ (treatment + season + year + \n    observer + R.score + C.score + treatment:R.score + treatment:C.score + \n    year:C.score + observer:R.score), data = df)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-0.8616 -0.3817 -0.1199  0.2218  2.8725 \n\nCoefficients: (1 not defined because of singularities)\n                          Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)                0.54228    0.18640   2.909 0.003830 ** \ntreatmentungrazed         -0.07940    0.15406  -0.515 0.606579    \nseasonspring              -0.24842    0.07754  -3.204 0.001467 ** \nseasonsummer               0.05885    0.06603   0.891 0.373370    \nyear2015                  -0.30506    0.19190  -1.590 0.112717    \nyear2016                  -0.19844    0.19686  -1.008 0.314073    \nobserverB                       NA         NA      NA       NA    \nR.score                    2.37006    1.04064   2.277 0.023296 *  \nC.score                   -0.80696    0.50195  -1.608 0.108721    \ntreatmentungrazed:R.score -3.21826    0.88011  -3.657 0.000290 ***\ntreatmentungrazed:C.score  1.65481    0.45479   3.639 0.000311 ***\nyear2015:C.score           0.16798    0.51029   0.329 0.742186    \nyear2016:C.score          -0.42087    0.50656  -0.831 0.406573    \nobserverB:R.score          1.51327    0.97453   1.553 0.121276    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.5607 on 391 degrees of freedom\nMultiple R-squared:  0.1889,    Adjusted R-squared:  0.164 \nF-statistic: 7.588 on 12 and 391 DF,  p-value: 1.16e-12\n\n\nThe p-value of the shapiro test is still less than 0.05, so the residuals are still not normally distributed @ref(fig:fig8).\n\npoll7&lt;-LinearModel(sqrt(RatioPoll)~( season + C.score + treatment:R.score + \n    treatment:C.score + year:C.score ),data=df)\npoll7\n\n\nCall:\nLinearModel(formula = sqrt(RatioPoll) ~ (season + C.score + treatment:R.score + \n    treatment:C.score + year:C.score), data = df)\n\nResidual standard error: 0.7061 on 395 degrees of freedom\nMultiple R-squared:  0.1748 \nF-statistic: 10.46 on 8 and 395 DF,  p-value: 2.525e-13 \nAIC = -272.2    BIC = -236.2\n\nFtest\n                       SS  df      MS F value    Pr(&gt;F)\nseason              7.389   2  3.6947  7.4097 0.0006932\nC.score             0.001   1  0.0009  0.0019 0.9655856\ntreatment:R.score  23.467   2 11.7333 23.5310 2.213e-10\nC.score:treatment   6.411   1  6.4105 12.8562 0.0003785\nC.score:year        1.769   2  0.8846  1.7741 0.1709912\nResiduals         196.959 395  0.4986                  \n\nTtest\n                      Estimate Std. Error t value  Pr(&gt;|t|)\n(Intercept)           0.401349   0.094246  4.2585 2.574e-05\nseason - autumn       0.069439   0.050345  1.3793 0.1685968\nseason - spring      -0.213646   0.057100 -3.7416 0.0002099\nseason - summer       0.144207   0.050304  2.8667 0.0043695\nC.score              -0.011798   0.273266 -0.0432 0.9655856\ntreatment - grazed    4.700511   0.687383  6.8383 3.058e-11\ntreatment - ungrazed -4.700511   0.687383 -6.8383 3.058e-11\nR.score               0.349497   0.643971  0.5427 0.5876277\nyear - 2014          -0.912854   0.254592 -3.5856 0.0003785\nyear - 2015           0.246445   0.192734  1.2787 0.2017603\nyear - 2016           0.666409   0.266422  2.5013 0.0127768\n\npollfinal&lt;-lm(sqrt(RatioPoll)~( season + C.score + treatment:R.score + \n    treatment:C.score + year:C.score ),data=df)\nres&lt;-residuals(pollfinal)\nhist(res,main=\"Histogram residuals\",xlab=\"Residus\")\n\n\n\n\nTransformed residuals histogram\n\n\n\nshapiro.test(res)\n\n\n    Shapiro-Wilk normality test\n\ndata:  res\nW = 0.87207, p-value &lt; 2.2e-16\n\n\nConclusion:  We cannot evaluate the impact of grazing on the pollination strategy of plants because the constraints of the general linear model are not respected. In addition, we cannot apply a generalized linear model given the type and values of our data."
  },
  {
    "objectID": "prior_course.html",
    "href": "prior_course.html",
    "title": "Be ready for the course",
    "section": "",
    "text": "The Online Collaborative Resources (OCR) class will make intensive use of the Reproducible Science tools. For this class and as an investment for the future, you will need to:"
  },
  {
    "objectID": "prior_course.html#git-on-your-computer",
    "href": "prior_course.html#git-on-your-computer",
    "title": "Be ready for the course",
    "section": "Git on your computer",
    "text": "Git on your computer\nInstall Git on your personal computer: Go to the Git website and click on the computer screen on the right, which should offer you the version suitable for your operating system."
  },
  {
    "objectID": "prior_course.html#github-account",
    "href": "prior_course.html#github-account",
    "title": "Be ready for the course",
    "section": "GitHub account",
    "text": "GitHub account\nIf you don’t have one, you have to create a GitHub account and set up the link between your computer and the GitHub. Be careful with the login you choose, this account will be used professionally and you may want to avoid pseudo like toto2024, or ladybug288.\nGitHub is just one solution to share git repositories online, you may work later with gitlab with is very similar to GitHub."
  },
  {
    "objectID": "prior_course.html#a-ssh-connection",
    "href": "prior_course.html#a-ssh-connection",
    "title": "Be ready for the course",
    "section": "A SSH connection",
    "text": "A SSH connection\nTo have smooth interactions with Github, you have to use a SSH and to do so, you will to generate SSH key on your computer and copy paste the public SSH key id_rsa.pub on your GitHub account.\n\nOpen a terminal (any terminal on Mac and Linux, the Git bash program you have installed with git if you are using Windows)\ntype the command\nssh-keygen\nDO NOT ENTER ANY PASSPHRASE while asked, simply press enter (twice generally)\nYou should have a directory named .ssh in your main personnal folder. Open the file id_rsa.pub with any text basic editor (like notepad, gedit …) and copy the key.\nGo to the settings of your GitHub account, choose the SSH and GPG keys, then press New SSH key and paste the previously copied key."
  },
  {
    "objectID": "prior_course.html#let-me-know-who-you-are",
    "href": "prior_course.html#let-me-know-who-you-are",
    "title": "Be ready for the course",
    "section": "Let me know who you are",
    "text": "Let me know who you are\nPlease enter your name and GitHub login on this spreadsheet and indicate in the last column whether you are already familiar with some markup languages (markdown, HTML) and if you have prior experience with Git or any version control system.\nPlease try to install all of this as soon as possible, and if you encounter any difficulties, don’t hesitate to contact me by email or come to me at the beginning of the class.\nIt will be easier if you can follow this procedure on your laptop and bring it to the class, but if you don’t have any laptop we will able to use the computers in the classroom (however this tedious installation process will have to be repeated on your personal computer)"
  },
  {
    "objectID": "Determinants_ant_diversity.html",
    "href": "Determinants_ant_diversity.html",
    "title": "Determinants of Ant Species Density",
    "section": "",
    "text": "INTRODUCTION\n\n1. Article presentation\nOur data come from the article “Biogeography at a Regional Scale: Determinants of Ant Species Density in New England Bogs and Forests” by (Gotelli_2002?).\n\n\n2. Biological context\nGotelli and Ellison are two ecologists, the first one specializing in questions of organization of animal and plant communities, the second one in the disintegration and reassembly of ecosystems following natural and anthropogenic disturbances. Here, they focused on the influence of the latitudinal gradient on the species richness of ants in the state of New England in the northeastern United States. Their study was carried out on 22 sites where, for each, 25 traps were placed in an ombrotrophic peat bog and 25 in the surrounding forest. The species of ants contained in the traps are subsequently identified in the laboratory and, for a given site and habitat, they calculated the species richness (total number of species present).\n\n\n3. Datas and variables\nThe variables used are :\n- Site : the name of the sampled site\n- Latitude : site latitude (quantitative)\n- Altitude : site altitude (quantitative)\n- Area : the area of the peat bog of the site (quantitative)\n- Location : the location of the traps (“Bog” or “Forest”) (qualitative)\n- Nsp : the specific richness of ants, corresponding to the response variable\n\n\n4. Research question\nGotelli and Ellison address 3 questions in this study, but we focus here on two:\n1) Is species density correlated with latitude over such a narrow latitudinal range?\n2) Does the latitudinal gradient persist after statistically controlling for site differences in vegetation composition?\nIn other words: what are the quantitative (latitude, altitude, area) and qualitative (location) variables that determine ant species richness in New England peatlands?\n\n\n5. Importing the dataset\nFrom then on, we can import the dataset located in file “BogAnts.txt”\n\n\nCode\n# Session Configuration :\nrm(list=ls()) # Cleaning the work environment\n\n# Importation\ndataAnts &lt;- read.table(\"BogAnts.txt\", dec=\".\", header = TRUE)\n\n# Transforming location into a factor\ndataAnts$Location&lt;-as.factor(dataAnts$Location)\n\n# Checking the type of variables\nstr(dataAnts)\n\n\n'data.frame':   44 obs. of  6 variables:\n $ Site     : chr  \"ARC\" \"ARC\" \"BH\" \"BH\" ...\n $ Latitude : num  42.3 42.3 42.6 42.6 45 ...\n $ Elevation: int  95 95 274 274 133 133 210 210 362 362 ...\n $ Area     : int  1190 1190 105369 105369 38023 38023 73120 73120 38081 38081 ...\n $ Location : Factor w/ 2 levels \"Bog\",\"Forest\": 2 1 2 1 2 1 2 1 2 1 ...\n $ Nsp      : int  9 8 10 8 6 5 9 4 6 2 ...\n\n\nConclusion :\nQualitative or quantitative variables are well considered as such.\n\n\n6. Which model and why?\nTo model the relationship between a quantitative response variable \\(Y\\) and explanatory variables \\(X_{1}\\),\\(X_{2}\\)…\\(X_{p}\\), quantitative and/or qualitative we use general linear models, or glm, (linear regression, ANCOVA, ANOVA). To be able to use these glm, three conditions of application are necessary: ​​homogeneity of variances, residual independence and residual normality. However, the \\(Y\\) responses analyzed in ecology can sometimes be discrete and deviate from the hypothesis of normality.\nFor discrete response variables (counts, binary data), the variance of \\(Y\\) generally varies with the mean of \\(Y\\). This relationship then seems to indicate that the variance cannot be homogeneous in a data set, due to its dependence on the mean. However, general linear models have a constant variance as their application hypothesis (i.e. a homogeneity of the variance). Furthermore, when applying a general linear model to count data, the predicted values ​​obtained may be negative (which is impossible given the nature of \\(Y\\)) and the residuals may not be normally distributed. Therefore, using a general linear model (glm) on discrete responses very generally generates deviations from the application conditions. In conclusion, it becomes necessary to use a method more suited to the analysis of discrete response variables such as generalized linear models (glim).\nHere are the steps to follow to establish a generalized linear model:\n1. Formulate the hypothesis of the distribution law of the response variable \\(Y_{i}\\)\n2. Explore the data (outliers, distribution of values,) with (Zuur_2010?) protocol\n3. Analyze the interactions between the variables Y and Xs (analysis of the relationships between X and Y, between Xs, and search for collinearity between Xs)\n4. Proceed with statistical analyses (construction of the model, analysis of the coefficients, explanatory power of the model)\n5. Conclude on the results\nA generalized linear model is written as follows (equation 1): \\[g(\\mu_{y})= \\alpha+ \\beta_{1}.X_{i1}+ \\beta_{2}.X_{i2}+\\beta_{3}.X_{i3}+...\\beta_{p}.X_{ip} = \\eta  \\tag{1}\\] The linear predictor, \\(\\eta\\), is derived from the linear model as the sum of the \\(p\\) terms associated with each of the \\(\\beta_{p}\\) parameters. Its value is obtained by transforming the value of \\(Y\\) by the link function, and the predicted value of \\(Y\\) is obtained by applying to \\(\\eta\\) the inverse function of the link function.\nTo illustrate this point, we are interested in counts. A count is a discrete and positive random variable. It is possible that the distribution of its values follows a Poisson distribution, a Negative Binomial distribution or even a Normal distribution when the values are very large.\nOur example illustrates a distribution following the Poisson law.\nThe Poisson law is useful for describing rare and independent discrete events. Thus, a variable \\(Y\\) that follows a Poisson law with parameter \\(\\lambda\\) is written as follows (equation 2): \\[Pr(Y=y)=\\frac{e^{-\\lambda}.\\ lambda^y}{y!} \\tag{2}\\] where \\(y\\) represents the observed number of occurrences (i.e., \\(y\\)=0, 1, 2…} and \\(\\lambda\\) the mean and variance of the Poisson law (i.e. in the Poisson law: E(\\(y\\))= Var(\\(y\\))=\\(\\lambda\\)).\nIn a Poisson-type glim, the link function is the log function. Thus, the model is written (equation 3): \\[log(\\mu_{y})= \\alpha+ \\beta_{1}.X{i1}+ \\beta_{2}.X{i2}+\\beta_{3}.X{i3}+...\\beta_{p}.X{ip} = \\eta  \\tag{3}\\] 150 / 5 000 The predicted values ​​of \\(Y\\) are obtained by applying to \\(\\eta\\) the inverse function of the link function, here the log function (equation 4): \\[\\mu_{y}= e^{\\alpha+ \\beta_{1}.X{i1}+ \\beta_{2}.X{i2}+\\beta_{3}.X{i3}+...\\beta_{p}.X{ip}} = e^{\\eta}  \\tag{4}\\]\nGeneralized linear models of the Poisson type have an error structure that follows a Poisson distribution. This structure allows, among other things, to precisely define the relationship between the mean and the variance. This relationship is exploited by the maximum likelihood method to estimate the coefficients and standard errors of the parameters of the GLM model.\n\n\n7. Environment Configuration and Packages\nTo analyze our data we set up the session by cleaning the workspace. We will also need to load the following packages : knitr, ggplot2, tinytext, corrplot, plot3D, DHARMa, rcompanion, lattice, patchwork, MASS et rcompanion\n\n\n8. Checking for missing data\n\n\nCode\n# Checking for missing data\ncolSums(is.na(dataAnts))\n\n\n     Site  Latitude Elevation      Area  Location       Nsp \n        0         0         0         0         0         0 \n\n\nCode\nsummary(dataAnts)\n\n\n     Site              Latitude       Elevation          Area       \n Length:44          Min.   :41.97   Min.   :  1.0   Min.   :   248  \n Class :character   1st Qu.:42.17   1st Qu.: 95.0   1st Qu.:  8852  \n Mode  :character   Median :42.56   Median :223.0   Median : 38052  \n                    Mean   :43.02   Mean   :232.7   Mean   :144528  \n                    3rd Qu.:44.29   3rd Qu.:353.0   3rd Qu.: 89208  \n                    Max.   :44.95   Max.   :543.0   Max.   :864970  \n   Location       Nsp        \n Bog   :22   Min.   : 2.000  \n Forest:22   1st Qu.: 4.000  \n             Median : 6.000  \n             Mean   : 7.023  \n             3rd Qu.: 8.250  \n             Max.   :18.000  \n\n\nThere are no missing values.\n\n\n9. Analysis process\nFrom this, we will first examine the dataset (outliers, potential relationships between Y and Xs, …) in order to have a first impression. Subsequently, we will carry out our statistical analysis by building and refining our model. Finally, we will analyze its coefficients and its explanatory power in order to validate it or not.\n\n\n\nDATA EXPLORATION\n\n1. Data overview\n\na. Outliers in Y and distribution of Y values\nThe first step in exploring the dataset is to check for potential outliers in the response variable \\(Y\\) and to examine the distribution of its values.\nOutliers: In ecological datasets, it is common to encounter individuals with extreme values for the response variable. These individuals, due to their unusual values, may disproportionately impact model construction. However, these extreme values may arise from either the natural variability of ecological phenomena or from errors (e.g., measurement or handling errors). Identifying these individuals prior to statistical analysis helps prevent errors and, if necessary, justifies the exclusion of certain outliers to improve the model’s robustness.\nOutliers can be identified using a Boxplot or a Cleveland plot of the values of \\(Y\\).\n\n\nCode\n# Boxplot \nbp &lt;- ggplot(data = dataAnts, aes(y = Nsp))+\n  geom_boxplot()+\n  labs(subtitle = \"A. Boxplot\",\n       y = \"species richness\")+\n  theme(\n    panel.background = element_rect(fill=\"white\"),\n    panel.grid.major = element_blank(), \n    panel.grid.minor = element_blank(),\n    axis.text.x = element_blank(), \n    axis.ticks.x = element_blank(),\n    \n    axis.title.x = element_text(size = 8, color = \"darkblue\"),\n    axis.title.y = element_text(size = 8, color = \"darkblue\"),\n    plot.title = element_text(size = 14, face = \"bold\", color = \"black\"),       \n    plot.subtitle = element_text(size = 10, color = \"black\"),                  \n    plot.caption = element_text(size = 4, face = \"italic\", color = \"darkgrey\")\n  )\n\n# Cleveland plot \ncp &lt;- ggplot(data = dataAnts, aes(x = Nsp, y = 1:nrow(dataAnts)))+\n  geom_jitter(width = 0.1, size = 3, color = \"black\")+\n  labs(subtitle = \"B. Cleveland plot\",\n       x = \"species richness\")+\n  theme_minimal()+\n  theme(\n    panel.grid.major.x = element_blank(),\n    panel.grid.minor.x = element_blank(),\n    axis.text.y = element_blank(),\n    axis.ticks.y = element_blank(),\n    axis.title.y = element_blank(),\n    \n    axis.title.x = element_text(size = 8, color = \"darkblue\"),\n    plot.title = element_text(size = 14, face = \"bold\", color = \"black\"),       \n    plot.subtitle = element_text(size = 10, color = \"black\"),                  \n    plot.caption = element_text(size = 4, face = \"italic\", color = \"darkgrey\")\n  )\n\n## Display\n(bp + cp) + \n  plot_layout(widths = c(1, 2)) \n\n\n\n\n\nFigure 1: Analyse of Y outliers\n\n\n\n\nAccording to Figure 1, \\(Y\\) does not exhibit any extreme or outlier values.\nDistribution of values: Analyzing the distribution of the values of \\(Y\\) allows us to preliminarily identify the probability distribution that best explains the ongoing ecological processes. This is particularly interesting if the data suggest a non-linear or asymmetric relationship.\nThe distribution of \\(Y\\) values can be visualized using a histogram or a Normal Q-Q plot.\n\n\nCode\n# Histogram\nhg &lt;- ggplot(data = dataAnts, aes(x = Nsp))+\n  geom_histogram(binwidth = 2, fill = \"blue\", color = \"black\")+\n  theme_minimal()+\n  labs(subtitle = \"A. Histogram\",\n       x = \"species richness\",\n       y = \"frequency\")+\n  theme(\n    axis.title.x = element_text(size = 8, color = \"darkblue\"),\n    axis.title.y = element_text(size = 8, color = \"darkblue\"),\n    plot.title = element_text(size = 14, face = \"bold\", color = \"black\"),       \n    plot.subtitle = element_text(size = 10, color = \"black\"),                  \n    plot.caption = element_text(size = 4, face = \"italic\", color = \"darkgrey\")\n    )\n\nqqp &lt;- ggplot(data = dataAnts, aes(sample = Nsp))+\n  geom_qq_line(color = \"red\", size = 1.2)+\n  geom_qq()+\n  theme_minimal()+\n  labs(subtitle = \"B. Q-Q plot\",\n       x = \"theorical quantiles\",\n       y = \"observed quantiles\")+\n  theme(\n    axis.title.x = element_text(size = 8, color = \"darkblue\"),\n    axis.title.y = element_text(size = 8, color = \"darkblue\"),\n    plot.title = element_text(size = 14, face = \"bold\", color = \"black\"),       \n    plot.subtitle = element_text(size = 10, color = \"black\"),                  \n    plot.caption = element_text(size = 4, face = \"italic\", color = \"darkgrey\")\n  )\n\n# Display\n(hg + qqp) +\n  plot_layout(widths = c(1, 2)) \n\n\n\n\n\nFigure 2: Analyse of Y distribution\n\n\n\n\nThe distribution of \\(Y\\) (negative exponential, Figure 2 A) and the nature of the dataset (count data without aggregation) suggest that \\(Y\\) follows a Poisson distribution. This hypothesis is supported by the deviation from normality of \\(Y\\) observed values shown in Figure 2 B.\nConclusion :\nAfter analyzing the outliers and the distribution of the response variable $Y$, it appears appropriate to use \\(Y\\) as is while applying a Poisson distribution.\n\n\nb. X quantitative: presence of outliers and distribution of X values\nThe dataset has three quantitative explanatory variables: Latitude, Elevation, and Area. Just like for the response variable \\(Y\\), it is necessary to examine the presence of outliers as well as the distribution of each of these explanatory variables.\nLatitude :\n\n\nCode\np1 &lt;- ggplot(dataAnts) +\n  aes(x=Latitude, y=factor(1:nrow(dataAnts), levels = 1:nrow(dataAnts))) + # display in the order of appearance\n  geom_jitter(width=0, height=0.1) +\n  scale_x_continuous(breaks = seq(41.5, 45, by = 0.5)) + # values of the X axis\n  labs(subtitle = \"A. Cleveland Plot\",\n       x= \"Latitude\") +  # Titres\n  theme_minimal() +\n  theme(axis.text.y = element_blank(),   # remove the labels from the Y axis\n        axis.ticks.y = element_blank(),  # remove the ticks from the Y axis\n        axis.title.y = element_blank(),  # remove the title from the X axis\n        axis.title.x = element_text(size = 8, color = \"darkblue\"),\n        plot.title = element_text(size = 14, face = \"bold\", color = \"black\"),\n        plot.subtitle = element_text(size = 10, color = \"black\")\n        )   \n\np2 &lt;- ggplot(dataAnts) +\n  aes(x = Latitude) +  \n  geom_histogram(binwidth = 0.25, fill = \"blue\", color = \"black\", alpha = 0.7) +  # histogram\n  scale_x_continuous(breaks = seq(41.5, 45, by = 0.5)) +  # values of the X axis\n  scale_y_continuous(breaks = seq(0, 10, by = 2)) +  # values of the Y axis \n  labs(subtitle = \"B. Histogram\",\n       x = \"Latitude\") +  # title\n  theme_minimal() +  # theme of the graph: minimal\n  theme(\n    axis.title.x = element_text(size = 8, color = \"darkblue\"), \n    axis.title.y = element_text(size = 8, color = \"darkblue\"),\n    plot.subtitle = element_text(size = 10, color = \"black\")\n  ) \n\np3 &lt;- ggplot(dataAnts, aes(sample = Latitude)) +\n  labs(subtitle = \"C. Quantile-Quantile Plot\",\n       caption = \"From the dataset dataAnts\",\n       x = \"theorical quantiles\",\n       y = \"observed quantiles\") +\n  stat_qq() +  # observed quantiles\n  stat_qq_line(col = \"red\", size = 1) +  # theorical quantiles\n  theme_minimal() + \n  theme(\n    axis.title.x = element_text(size = 8, color = \"darkblue\"),\n    axis.title.y = element_text(size = 8, color = \"darkblue\"),\n    plot.title = element_text(size = 14, face = \"bold\", color = \"black\"),       \n    plot.subtitle = element_text(size = 10, color = \"black\"),                  \n    plot.caption = element_text(size = 4, face = \"italic\", color = \"darkgrey\") \n  ) \n\n(p1 / p2) | p3 + \n  plot_layout(guides = \"collect\")\n\n\n\n\n\nFigure 3: Analyse of explanatory variable Latitude\n\n\n\n\nThere are no outliers observed in the Cleveland plot (Figure 3 A) or in the histogram (Figure 3 B).\nThe Quantile plot (Figure 3 C) shows a deviation from normality. This suggests that it is more appropriate to use a generalized linear model (glm) rather than a classical linear model (lm).\nElevation :\n\n\n\n\n\nFigure 4: Analyse of explanatory variable Elevation\n\n\n\n\nNo outliers are observed in the Cleveland plot (Figure 4 A) or in the histogram (Figure 4 B).\nThe Quantile plot (Figure 4 C) shows a deviation from normality. This suggests that it is advisable to use a generalized linear model rather than a classical linear model.\nArea :\n\n\n\n\n\nFigure 5: Analyse of explanatory variable Area\n\n\n\n\nWe observe outliers in the Cleveland plot (Figure 5 A) and in the histogram (Figure 5 B) due to the presence of very extensive peatlands. We can apply a transformation to this variable and consider a logarithmic transformation.\n\n\n\n\n\nFigure 6: Analyse of explanatory variable log(Area)\n\n\n\n\nNo outliers are observed in the Cleveland plot (Figure 6 A) or in the histogram (Figure 6 B).\nConclusion :\nThe analysis of outliers and the distribution of the variables suggest that, after modification, the three quantitative variables (covariates) Latitude, Elevation, and LogArea can be used in the construction of the model.\n\n\nc. X qualitative : number of modalities and number of individuals per modalities\nWhen the dataset includes qualitative variables (factors), it is essential to analyze the balance of modalities: if there are more individuals in one modality compared to another, their weight in the model may lead to a biased final interpretation.\n\n\nCode\nsummary(dataAnts$Location)\n\n\n   Bog Forest \n    22     22 \n\n\nHere, the data are well distributed between the two modalities (Bog = peatlands and Forest = forests).\nConclusion :\nThe analysis of outliers and the distribution of the qualitative variable suggest that it can be used in the construction of the model.\n\n\n\n2. Analysis of interactions between variables Y and Xs\n\na. Analyze the potential relationship between Y and Xs\nIn order to test the possible relationship between the response variable \\(Y\\) and the explanatory variables \\(Xs\\), it will be essential to carry out statistical modelling, as this is the only way to test the significance of the relationships. However, we can start by performing graphical analyses to better visualize the data and get an idea\n\n\nCode\npar(mfrow=c(2,2))\n\n# For the latitude variable\nplot(dataAnts$Nsp~dataAnts$Latitude,pch=16,col='deepskyblue4',xlab='Latitude',ylab='Ant species richness', main = \"A. Latitude\")\n\n# For the altitude variable\nplot(dataAnts$Nsp~dataAnts$Elevation,pch=16,col='deepskyblue4',xlab='Elevation',ylab='Ant species richness', main = \"B. Elevation\")\n\n# For the variable peatland area\nplot(dataAnts$Nsp~dataAnts$LogArea,pch=16,col='deepskyblue4',xlab='Peatland area',ylab='Ant species richness', main = \"C. Peatland area\")\n\n# For the location variable\nboxplot(dataAnts$Nsp~dataAnts$Location, varwidth = TRUE, ylab = \"Ant species richness\", xlab = \"Location\", col=c('saddlebrown','palegreen4'), main = \"D. Location\")\n\n\n\n\n\nFigure 7: Analyse of relation between Y and explanatory variable\n\n\n\n\nRelationship between ant species richness and latitude (Figure 7 A): We can see that the higher the latitude, the lower the species richness. We can say that the further north we are, the fewer ant species there are.\nRelationship between ant species richness and altitude (Figure 7 B): In this graph, we can again see that the higher the altitude, the lower the species richness.\nRelationship between ant species richness and bog area (Figure 7 C): Here, there appears to be no relationship between ant species richness and bog area.\nRelationship between ant species richness and location (Figure 7 D.): Here, there appears to be a relationship between location and ant species richness, with higher species richness in forests than in bogs.\nConclusion :\nIt seems that the further north and the higher the relief, the lower the ant species richness. What’s more, if we’re in a forest, the species richness will be greater than in bogs.\n\n\nb. Analysis of Potential Interactions Among the X Variables\nWe aim to study interactions between the factor and the three covariates. Thus, we exclude any interaction among the quantitative explanatory variables. We use a graphical approach to estimate the potential interactive effect among these different variables.\n\n\nCode\npar(mfrow=c(1,3))\n\n# Interactions between Latitude & Location\nplot(dataAnts$Nsp~dataAnts$Latitude,type='n',ylab = \"Ant specific richness\",xlab=\"Latitude\", main=\"A.\")\npoints(dataAnts$Nsp[dataAnts$Location==\"Bog\"]~dataAnts$Latitude[dataAnts$Location==\"Bog\"],pch=16,cex=2,col='saddlebrown')\npoints(dataAnts$Nsp[dataAnts$Location==\"Forest\"]~dataAnts$Latitude[dataAnts$Location==\"Forest\"],pch=17,cex=2,col='palegreen4')\n\n# Interactions between Altitude & Localisation\nplot(dataAnts$Nsp~dataAnts$Elevation,type='n',ylab = \"Ant specific richness\",xlab=\"Elevation\", main=\"B.\")\npoints(dataAnts$Nsp[dataAnts$Location==\"Bog\"]~dataAnts$Elevation[dataAnts$Location==\"Bog\"],pch=16,cex=2,col='saddlebrown')\npoints(dataAnts$Nsp[dataAnts$Location==\"Forest\"]~dataAnts$Elevation[dataAnts$Location==\"Forest\"],pch=17,cex=2,col='palegreen4')\n\n# Interactions between Superficie de la tourbière & Localisation\nplot(dataAnts$Nsp~dataAnts$LogArea,type='n',ylab = \"Ant specific richness\",xlab=\"Bog area\", main=\"C.\")\npoints(dataAnts$Nsp[dataAnts$Location==\"Bog\"]~dataAnts$LogArea[dataAnts$Location==\"Bog\"],pch=16,cex=2,col='saddlebrown')\npoints(dataAnts$Nsp[dataAnts$Location==\"Forest\"]~dataAnts$LogArea[dataAnts$Location==\"Forest\"],pch=17,cex=2,col='palegreen4')\n\n\n\n\n\nFigure 8: Analyse of relation between explanatory variable\n\n\n\n\nGenerally if we look at Figure 8, we can assume an interaction between covariates if the slopes formed by the two point clouds are different. Here, the clouds do not clearly reveal any similarity or difference in trend for each graph. It is therefore difficult to draw conclusions about these interactions.\n\n\nc. Checking for Potential Collinearity Among the X Variables\nWe aim to avoid collinearity among the explanatory variables in our modeling to prevent multiple variables from providing the same information. To do this, we must examine the statistical relationships that may exist among the variables by calculating the correlation between quantitative \\(X\\) variables, and analyzing the influence of the qualitative \\(X\\) on the quantitative \\(X\\) variables using plot graphics.\n\n\nCode\n# Checking for collinearity between independent continuous variables\n# Creating a scatterplot for each pair of covariates\nnewdata&lt;-cbind(dataAnts$Latitude,dataAnts$Elevation,dataAnts$LogArea)\ncolnames(newdata)&lt;-c('Latitude','Elevation','Log Bog area')\nnewdata&lt;-data.frame(newdata)\nplot(newdata,pch=16,col='deepskyblue4')\n\n\n\n\n\nFigure 9: Analyse of collinearity between independant continuous variables, scatterplot for each pair of covariates\n\n\n\n\n\n\nCode\n# Calculating correlation for each pair of covariates\nM&lt;-cor(newdata)\ncorrplot.mixed(M,upper=\"square\",lower.col=\"black\", tl.col=\"black\",cl.cex = 0.8,tl.cex = 0.7,number.cex =0.8)\n\n\n\n\n\nFigure 10: Analyse of collinearity between independant continuous variables, correlation for each pair of covariates\n\n\n\n\n\n\nCode\npar(mfrow=c(1,3))\n\n# Checking for collinearity between categories and continuous variables\n# Latitude and Location\nboxplot(dataAnts$Latitude~dataAnts$Location, varwidth = TRUE, ylab = \"Latitude\", xlab = \"Location\",col=c('saddlebrown','palegreen4'))\n\n# Altitude and Location\nboxplot(dataAnts$Elevation~dataAnts$Location, varwidth = TRUE, ylab = \"Elevation\", xlab = \"Location\",col=c('saddlebrown','palegreen4'))\n\n# Bog Area and Location\nboxplot(dataAnts$LogArea~dataAnts$Location, varwidth = TRUE, ylab = \"Bog area\", xlab = \"Location\",col=c('saddlebrown','palegreen4'))\n\n\n\n\n\nFigure 11: Analyse of collinearity between categories and continuous variables\n\n\n\n\nIn the first graph (Figure 9), we can see that the point clouds do not appear to show any trend toward collinearity. This impression is confirmed by the calculated values in the following figure (Figure 10), where the values are well below 0.7, which is commonly used as a threshold for collinearity (above this, variables are considered correlated). The almost complete overlap of the boxplots (Figure 11) further supports the non-collinearity of these factors.\nConclusion :\nThere does not appear to be any collinearity among the variables, so we can retain them all.\n\n\n\n\nSTATISTICAL ANALYSIS\n\n1. Model construction\nWe aim to produce the best model for predicting the number of species. The response variable is a count (a discrete quantitative variable) with small numbers (&lt;30), so the appropriate distribution is the Poisson distribution. We’re going to model it using a generalized linear Poisson model.\nTo arrive at the “candidate” model to be tested, we’ll start with the “complete” model, i.e. with all the explanatory variables and their interactions, and use Backward selection to select the variables and interactions to be retained.\nLet’s start with the complete model:\n\n\nCode\n# model formulation with the fonction glm() and family=poisson(link=\"log\")\nmod1&lt;-glm(Nsp~ Location\n        + Latitude\n        + Elevation\n        + LogArea\n        + Location:Latitude\n        + Location:Elevation\n        + Location:LogArea\n        ,data=dataAnts\n        ,family=poisson(link=\"log\"))\n\n\nBased on this complete model, we will eliminate the insignificant interactions step by step.\n\n\nCode\n# Step 1\ndrop1(mod1,test=\"Chi\")\n\n\nSingle term deletions\n\nModel:\nNsp ~ Location + Latitude + Elevation + LogArea + Location:Latitude + \n    Location:Elevation + Location:LogArea\n                   Df Deviance    AIC     LRT Pr(&gt;Chi)\n&lt;none&gt;                  39.973 216.33                 \nLocation:Latitude   1   39.981 214.34 0.00801   0.9287\nLocation:Elevation  1   40.370 214.72 0.39675   0.5288\nLocation:LogArea    1   40.075 214.43 0.10247   0.7489\n\n\nAll three interactions are insignificant. We remove the ‘Location:Latitude’ interaction as it is the ‘least significant’. We can also see that the drop1() function informs us that it’s by removing this interaction that we get the best AIC.\nWe obtain the following model:\n\n\nCode\n# Step 2\nmod1&lt;-glm(Nsp~ Location\n        + Latitude\n        + Elevation\n        + LogArea\n        + Location:Elevation\n        + Location:LogArea\n        ,data=dataAnts\n        ,family=poisson(link=\"log\"))\n\ndrop1(mod1,test=\"Chi\")\n\n\nSingle term deletions\n\nModel:\nNsp ~ Location + Latitude + Elevation + LogArea + Location:Elevation + \n    Location:LogArea\n                   Df Deviance    AIC     LRT  Pr(&gt;Chi)    \n&lt;none&gt;                  39.981 214.34                      \nLatitude            1   55.094 227.45 15.1134 0.0001012 ***\nLocation:Elevation  1   40.426 212.78  0.4446 0.5049344    \nLocation:LogArea    1   40.078 212.43  0.0974 0.7550075    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nIn the same way, we remove the ‘Location:LogArea’ interaction.\n\n\nCode\n# Step 3\nmod1&lt;-glm(Nsp~ Location\n        + Latitude\n        + Elevation\n        + LogArea\n        + Location:Elevation\n        ,data=dataAnts\n        ,family=poisson(link=\"log\"))\n\ndrop1(mod1,test=\"Chi\")\n\n\nSingle term deletions\n\nModel:\nNsp ~ Location + Latitude + Elevation + LogArea + Location:Elevation\n                   Df Deviance    AIC     LRT  Pr(&gt;Chi)    \n&lt;none&gt;                  40.078 212.43                      \nLatitude            1   55.176 225.53 15.0976 0.0001021 ***\nLogArea             1   40.273 210.63  0.1943 0.6593240    \nLocation:Elevation  1   40.499 210.85  0.4208 0.5165445    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nWe also remove the ‘Location:Elevation’ interaction. We now look at the significance of the explanatory variables.\n\n\nCode\n# Step 4\nmod1&lt;-glm(Nsp~ Location\n        + Latitude\n        + Elevation\n        + LogArea\n        ,data=dataAnts\n        ,family=poisson(link=\"log\"))\n\ndrop1(mod1,test=\"Chi\")\n\n\nSingle term deletions\n\nModel:\nNsp ~ Location + Latitude + Elevation + LogArea\n          Df Deviance    AIC     LRT  Pr(&gt;Chi)    \n&lt;none&gt;         40.499 210.85                      \nLocation   1   70.185 238.54 29.6856 5.081e-08 ***\nLatitude   1   55.621 223.97 15.1221 0.0001008 ***\nElevation  1   49.909 218.26  9.4100 0.0021580 ** \nLogArea    1   40.690 209.04  0.1913 0.6618646    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nAs the ‘LogArea’ variable does not have a siginificative effect, we eliminate it from the model.\n\n\nCode\n# Step 5\nmod1&lt;-glm(Nsp~ Location\n        + Latitude\n        + Elevation\n        ,data=dataAnts\n        ,family=poisson(link=\"log\"))\n\ndrop1(mod1,test=\"Chi\")\n\n\nSingle term deletions\n\nModel:\nNsp ~ Location + Latitude + Elevation\n          Df Deviance    AIC     LRT  Pr(&gt;Chi)    \n&lt;none&gt;         40.690 209.04                      \nLocation   1   70.376 236.73 29.6856 5.081e-08 ***\nLatitude   1   56.649 223.00 15.9590 6.473e-05 ***\nElevation  1   50.284 216.64  9.5938  0.001952 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nThe remaining explanatory variables are significant, so we retain this model as a candidate.\nWe will then identify the candidate model using an approach other than the significance of the p-values: the AIC with the stepwise mode.\n\n\nCode\n# complete model construction\nmodelcomplet&lt;- glm(Nsp~ Location\n        + Latitude\n        + Elevation\n        + LogArea\n        + Location:Latitude\n        + Location:Elevation\n        + Location:LogArea\n        ,data=dataAnts\n        ,family=poisson(link=\"log\"))\n\n# model selection\nmodfinal&lt;-stepAIC(modelcomplet,direction=\"both\")\n\n\nStart:  AIC=216.33\nNsp ~ Location + Latitude + Elevation + LogArea + Location:Latitude + \n    Location:Elevation + Location:LogArea\n\n                     Df Deviance    AIC\n- Location:Latitude   1   39.981 214.34\n- Location:LogArea    1   40.075 214.43\n- Location:Elevation  1   40.370 214.72\n&lt;none&gt;                    39.973 216.33\n\nStep:  AIC=214.34\nNsp ~ Location + Latitude + Elevation + LogArea + Location:Elevation + \n    Location:LogArea\n\n                     Df Deviance    AIC\n- Location:LogArea    1   40.078 212.43\n- Location:Elevation  1   40.426 212.78\n&lt;none&gt;                    39.981 214.34\n+ Location:Latitude   1   39.973 216.33\n- Latitude            1   55.094 227.45\n\nStep:  AIC=212.43\nNsp ~ Location + Latitude + Elevation + LogArea + Location:Elevation\n\n                     Df Deviance    AIC\n- LogArea             1   40.273 210.63\n- Location:Elevation  1   40.499 210.85\n&lt;none&gt;                    40.078 212.43\n+ Location:LogArea    1   39.981 214.34\n+ Location:Latitude   1   40.075 214.43\n- Latitude            1   55.176 225.53\n\nStep:  AIC=210.63\nNsp ~ Location + Latitude + Elevation + Location:Elevation\n\n                     Df Deviance    AIC\n- Location:Elevation  1   40.690 209.04\n&lt;none&gt;                    40.273 210.63\n+ LogArea             1   40.078 212.43\n+ Location:Latitude   1   40.270 212.62\n- Latitude            1   56.212 224.57\n\nStep:  AIC=209.04\nNsp ~ Location + Latitude + Elevation\n\n                     Df Deviance    AIC\n&lt;none&gt;                    40.690 209.04\n+ Location:Elevation  1   40.273 210.63\n+ LogArea             1   40.499 210.85\n+ Location:Latitude   1   40.650 211.00\n- Elevation           1   50.284 216.64\n- Latitude            1   56.649 223.00\n- Location            1   70.376 236.73\n\n\nCode\n# final model\ndrop1(modfinal,test=\"Chi\")\n\n\nSingle term deletions\n\nModel:\nNsp ~ Location + Latitude + Elevation\n          Df Deviance    AIC     LRT  Pr(&gt;Chi)    \n&lt;none&gt;         40.690 209.04                      \nLocation   1   70.376 236.73 29.6856 5.081e-08 ***\nLatitude   1   56.649 223.00 15.9590 6.473e-05 ***\nElevation  1   50.284 216.64  9.5938  0.001952 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nCode\nsummary(modfinal)\n\n\n\nCall:\nglm(formula = Nsp ~ Location + Latitude + Elevation, family = poisson(link = \"log\"), \n    data = dataAnts)\n\nCoefficients:\n                 Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)    11.9368121  2.6214970   4.553 5.28e-06 ***\nLocationForest  0.6354389  0.1195664   5.315 1.07e-07 ***\nLatitude       -0.2357930  0.0616638  -3.824 0.000131 ***\nElevation      -0.0011411  0.0003749  -3.044 0.002337 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 102.76  on 43  degrees of freedom\nResidual deviance:  40.69  on 40  degrees of freedom\nAIC: 209.04\n\nNumber of Fisher Scoring iterations: 4\n\n\nNote: it is recommended to use AIC with more than 40 individuals per parameter, otherwise there is AICc ((YannickOutreman?)).\nConclusion :\nBoth methods arrive at the same candidate model: Nsp~Latitude+Elevation+LogArea.\n\n\n2. Coefficients analysis\nThe next step is to analyze the coefficients. We’ll be looking at the precise effect of the selected explanatory variables (Latitude, Elevation, LogArea) on ant species richness.\n\n\nCode\n# Coefficients \nsummary(mod1)\n\n\n\nCall:\nglm(formula = Nsp ~ Location + Latitude + Elevation, family = poisson(link = \"log\"), \n    data = dataAnts)\n\nCoefficients:\n                 Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)    11.9368121  2.6214970   4.553 5.28e-06 ***\nLocationForest  0.6354389  0.1195664   5.315 1.07e-07 ***\nLatitude       -0.2357930  0.0616638  -3.824 0.000131 ***\nElevation      -0.0011411  0.0003749  -3.044 0.002337 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 102.76  on 43  degrees of freedom\nResidual deviance:  40.69  on 40  degrees of freedom\nAIC: 209.04\n\nNumber of Fisher Scoring iterations: 4\n\n\nCode\n#                 Estimate Std. Error z value Pr(&gt;|z|)    \n#(Intercept)    11.9368121  2.6214970   4.553 5.28e-06 ***\n#LocationForest  0.6354389  0.1195664   5.315 1.07e-07 ***\n#Latitude       -0.2357930  0.0616638  -3.824 0.000131 ***\n#Elevation      -0.0011411  0.0003749  -3.044 0.002337 ** \n\n#Null deviance: 102.76  on 43  degrees of freedom\n#Residual deviance:  40.69  on 40  degrees of freedom\n\n\nThe model’s summary() allows us to see the coefficients corresponding to each variable, as well as the intercept (based on the population mean). For a factor (qualitative variable), the coefficient corresponds to the comparison between the given modality and the so-called “reference” modality, whose coefficient is equal to 0. The deviance scores will be used in the following section. This table shows the different coefficients:\nLocation factor\n- \\(Location_{Bog}\\) = 0 (reference modality for Location)\n- \\(Location_{Forest}\\) = \\(+0.63^{**}\\)\nLatitude covariate\n- \\(\\beta_{Latitude}\\) = \\(-0.23^{***}\\)\nElevation covariate\n- \\(\\beta_{Elevation}\\) = \\(-0.001^{***}\\)\nThe candidate model with the coefficients is written (equation 5): \\[ log(Species\\:Richness) = 11.93^{***} + (Location_{Bog} = 0 ;\\:Location_{Forest} = +0.63^{***})\\:- 0.23^{***}.Latitude\\: -0.001^{***}. Elevation   \\tag{5}\\]\nReminder: to model a discrete quantitative variable with a generalized linear model, we use a link function. Here, with Poisson distribution, we use the log() function.\n\n\n3. Explanatory power of the model\nTo determine the quality of our model, we’ll calculate the distance between the candidate model and the null model. The null model is a model that summarizes the data with a single parameter: the mean of \\(Y\\). This model does not explain the data.\nOne way of determining model quality is to calculate a pseudo R²*. To do this, we determine the distance between the deviance of the null model and the residual deviance of the candidate model (equation 6).\n\\[Pseudo\\:R^2=100\\:.\\:\\frac{Null\\:Deviance- Residual\\:Deviance}{Null\\:Deviance} \\tag{6}\\]\nWe can calculate the pseudo R² in three different ways: with the McFadden method, the Cox and Snell method or the Nagelkerke method. The last two methods require the ‘rcompagnon’ package.\nIn our example, as seen in the previous section, the null model has a deviance of 102.76 and the residual deviance is 40.69.\nWe will therefore calculate the quality of the model with the following lines:\n\n\nCode\n# Estimate of deviance explained\n(mod1$null.deviance-mod1$deviance)/mod1$null.deviance\n\n\n[1] 0.6040372\n\n\nCode\n# Some others estimates of deviance explained - package 'rcompanion'\nlibrary(rcompanion)\nnagelkerke(mod1)\n\n\n$Models\n                                                                                      \nModel: \"glm, Nsp ~ Location + Latitude + Elevation, poisson(link = \\\"log\\\"), dataAnts\"\nNull:  \"glm, Nsp ~ 1, poisson(link = \\\"log\\\"), dataAnts\"                              \n\n$Pseudo.R.squared.for.model.vs.null\n                             Pseudo.R.squared\nMcFadden                             0.235913\nCox and Snell (ML)                   0.756039\nNagelkerke (Cragg and Uhler)         0.757956\n\n$Likelihood.ratio.test\n Df.diff LogLik.diff  Chisq    p.value\n      -3     -31.036 62.073 2.1197e-13\n\n$Number.of.observations\n         \nModel: 44\nNull:  44\n\n$Messages\n[1] \"Note: For models fit with REML, these statistics are based on refitting with ML\"\n\n$Warnings\n[1] \"None\"\n\n\nHere, the estimate of deviance explained is 60% or 75%, depending on the method used.\n\n\nCode\nplot(fitted(mod1)~dataAnts$Nsp,col='dodgerblue3',pch=16,ylab=\"Estimated values\",xlab=\"Observed values\")\nabline(0,1)\n\n\n\n\n\nFigure 12: Representation of predict values\n\n\n\n\n\n\n4. Model validation\nThe independence of residuals is the only limitation of the generalized linear model. Analysis of the residuals therefore enables us to identify possible trends and check for the presence of influential statistical units.\nTo begin with, checking for overdispersion is essential when running a Poisson generalized linear model. For all generalized linear models using count data, we need to check for the absence of overdispersion.\nTo do this, we calculate a parameter called the ‘scale parameter’. If its value is significantly greater than 1 (from 1.6 or 1.7), there is overdispersion. The model is therefore invalid.\n\na. Checking for overdispersion\nWhen the dispersion index is greater than 1.5, there are various explanations.\nIt may be due to :\n\nOutliers are present in the data set. They need to be eliminated.\nMissing covariates. They need to be added to the model.\nMissing interactions. Add them to the model.\nZero inflation occurs. Use negative Binomial regression with zero inflation ((Long_1997?))\nA dependency between the data and a factor or variable is present. A general linear mixed model should be used. ((Johnson_et_al_2015?))\nRelationship between data and variables or factors is not linear. A generalized additive model must be used. ((Irz_et_Levi-Valensin_2016?))\nThe link function is bad. The link function must be changed.\nThe variation of \\(Y\\) is large. We must use a generalized linear model following a negative binomial distribution. ((Chahine_1965?))\n\nIn our example, we will calculate the scale parameter. To do this, we will use the command :\n\n\nCode\n# Scale parameter calculation\nE1 &lt;- resid(mod1, type = \"pearson\") # (Y - mu) / sqrt(mu)\nN  &lt;- nrow(dataAnts)\np  &lt;- length(coef(mod1))\nsum(E1^2) / (N - p)\n\n\n[1] 1.029116\n\n\nConclusion :\nHere, dispersion is 1.02, there is no overdispersion.\n\n\nb. Residual analysis\nAlthough the assumptions of normality and homogeneity of residuals are not expected in generalized linear models, we can analyze them graphically. By plotting the residuals against the model’s significant \\(Xs\\), we need to validate the absence of a trend in their distribution. If we find a trend, the modeling may be problematic: it may be due to a lack of fit, data dependency or influential observations. Remember that in generalized linear models, we use Pearson residuals because they include heterogeneity of variance and are easy to calculate and understand.\n\n\nCode\nresid&lt;-residuals(mod1, type=\"pearson\")\n\npar(mfrow=c(3,2))\n# Histogram\nhist(resid,col='dodgerblue3',xlab=\"residuals\",main=\"A.\")\n# Quantile-Quantile plot\nqqnorm(resid,pch=16,col='dodgerblue3',xlab='', main=\"B.\")\nqqline(resid,col='red',lwd=2)\n\n# Residuals vs fitted\nplot(resid~fitted(mod1)\n      , col='dodgerblue3'\n      , pch=16, main=\"C.\")\nabline(h = 0)\n\n# Residuals against Location factor\nboxplot(resid~ dataAnts$Location, \n         varwidth = TRUE,\n         ylab = \"Residuals\",\n         xlab = \"Location\",\n         main = \"D.\")\n\n# Residuals against Latitude\nplot(resid~ dataAnts$Latitude, \n         pch=16,\n         col=\"dodgerblue3\",\n         ylab = \"Residuals\",\n         xlab = \"Latitude\",\n         main = \"E.\")\nabline(h = 0)\n\n# Residuals against Elevation\nplot(resid~ dataAnts$Elevation, \n         pch=16,\n         col=\"dodgerblue3\",\n         ylab = \"Residuals\",\n         xlab = \"Elevation\",\n         main = \"F.\")\nabline(h = 0)\n\n\n\n\n\nFigure 13: Analyse of residuals\n\n\n\n\nThe histogram of residuals (Figure 13 A) and the Q-Q plot (Figure 13 B) show relatively normal residuals. The following four graphs (Figure 13 C, D ,E and F) show the distribution of residuals according to model estimates and the three explanatory variables. We can see that the residuals remain homogeneous whatever the values of the explanatory variables.\nConclusion :\nWe can conclude there is no tendency in the residuals.\n\n\nc. Checking for influent individuals\n\n\nCode\npar(mfrow = c(1, 1))\nplot(cooks.distance(mod1), type = \"h\", ylim = c(0, 1), main=\"Figure 26\")\nabline(h = 1, col = 2,lwd = 3)\n\n\n\n\n\nFigure 14: Analyse of influent individuals\n\n\n\n\nConclusion :\nHere (Figure 14), there are no overly influential individuals.\n\n\nd. Residual analysis with DHARMa\nFor a different graphical representation, we can use the ‘DHARMa’ package. This package can be used to analyze residuals, in particular overdispersion and outliers. Residuals that do not comply with expected values are highlighted in red.\n\n\nCode\n# TestDispersion(mod1)\nlibrary(DHARMa)\nsimulationOutput &lt;- simulateResiduals(fittedModel = mod1, plot = F)\nresiduals(simulationOutput)\n\n\n [1] 0.18239618 0.80151718 0.58807555 0.91926545 0.47936926 0.80054278\n [7] 0.21988509 0.20392550 0.63926446 0.23771974 0.93979633 1.00000000\n[13] 0.55147536 0.10846697 0.10852467 0.18784519 0.67846792 0.26581684\n[19] 0.48230426 0.36551653 0.66505642 0.91389210 0.90974035 0.32702672\n[25] 0.27414285 0.55547244 0.04495447 0.01279264 0.77714308 0.53842229\n[31] 0.80358226 0.69900441 0.77700439 0.54884684 0.66172468 0.46419915\n[37] 0.30537691 0.14932406 0.82094811 0.23204016 0.13914854 0.38413168\n[43] 0.14453694 0.91036913\n\n\nCode\nplot(simulationOutput)\nresiduals(simulationOutput, quantileFunction = qnorm, outlierValues = c(-7,7))\n\n\n [1] -0.90627115  0.84705290  0.22259735  1.40014770 -0.05173666  0.84356157\n [7] -0.77258135 -0.82768134  0.35649343 -0.71365672  1.55306609  7.00000000\n[13]  0.12938973 -1.23472214 -1.23441223 -0.88586483  0.46341887 -0.62551412\n[19] -0.04437121 -0.34375165  0.42630289  1.36511850  1.33915783 -0.44813823\n[25] -0.60033094  0.13949991 -1.69587828 -2.23244931  0.76258012  0.09645977\n[31]  0.85448653  0.52153923  0.76211526  0.12274843  0.41717468 -0.08986022\n[37] -0.50899774 -1.03933681  0.91898431 -0.73214458 -1.08415273 -0.29464726\n[43] -1.06015545  1.34303160\n\n\n\n\n\nFigure 15: Dharma\n\n\n\n\n\n\nCode\n# Residuals with covariate\nplotResiduals(simulationOutput, form = dataAnts$Latitude)\n\n\n\n\n\nFigure 16: Dharma\n\n\n\n\nConclusion :\nIn our example, the residuals are not overdispersed and show no outliers (Figure 15, Figure 16).\n\n\n\n\nCONCLUSION\nThe selected model is (equation 5):\n\\[ log(Species\\:Richness) = 11.93^{***} + (Location_{Bog} = 0 ;\\:Location_{Forest} = +0.63^{***})\\:- 0.23^{***}.Latitude\\: -0.001^{***}. Elevation  \\]\nIts dispersion index is estimated at 1.02, indicating the absence of overdispersion, which validates our model.\nFurthermore, we detect no influential data points that could bias the model.\nThe estimated pseudo R² of 0.60 suggests that this model effectively explains our data (the null model deviance is 102.76, while the residual deviance is 40.69).\nWe conclude that ant species richness in the New England bogs depends on:\n\nLocation: Species richness is higher in forests than in bogs, linked to vegetation cover and available light;\nLatitude: Species richness decreases with increasing latitude;\nElevation: Although its effect is smaller, elevation also influences species richness.\n\nIn both forests and bogs, latitude is the most significant predictor of species density.\nHowever, further research on a larger scale is necessary to generalize these findings, as this study covers only a limited geographical area with two habitat types."
  },
  {
    "objectID": "r_chapter.html",
    "href": "r_chapter.html",
    "title": "The Companion book a M1 MODE student should have!",
    "section": "",
    "text": "title: “Modèles matriciels et applications” group: “Quentin, Alexie, Jeanne, Laurane”\nbibliography: references.bib execute: freeze: auto output: html_document: toc: true toc_float: true —\nThis chapter is a simple example using R\nYou can import R package using the code\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.0     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\nand then describe the purpose of your chapter as well as executing R command.\nFor example a basic summary of a dataset is given by\n\ndf &lt;- read.table(\"https://gist.githubusercontent.com/slopp/ce3b90b9168f2f921784de84fa445651/raw/4ecf3041f0ed4913e7c230758733948bc561f434/penguins.csv\", sep = \",\" , header = TRUE)\n\nand produce a graph\n\ndf %&gt;% ggplot() +\n    aes(x=species, y = body_mass_g) +\n    geom_boxplot()  \n\nWarning: Removed 2 rows containing non-finite outside the scale range\n(`stat_boxplot()`).\n\n\n\n\n\nA citation @bauer2023writing"
  },
  {
    "objectID": "instructions.html",
    "href": "instructions.html",
    "title": "How to contribute",
    "section": "",
    "text": "Create a specific branch for your chapter named an_explicit_name_for_the_branch and switch on this branch\n\ngit checkout -b an_explicit_name_for_the_branch\nIn the development of the project, you might find necessary to have several branches per chapter.\n\nCreate a quarto file for the chapter chapter0.qmd in your branch\n\ngit add chapter0.qmd\ngit commit -m \"first commit in the chapter branch\"\n\nPush everything on the remote repo on Github\n\nFor the first push after the branch creation, you have to specify the name of the branch on the remote repo and you can use git  push --set-upstream origin an_explicit_name_for_the_branch or\nFor the push to come after the first one, you will simply push by\ngit  push\nOnce you are quite happy with your production, you will be willing to integrate your production on the main branch. A good practice is to ask the permission to push on the main branch, which is named a pull request (PR).\n\nAsk for a PR on Github\nIf needed, specify in the PR message the package you need and mention MarieEtienne as reviewer of the PR.\n\nA mock rendering of the qmd file will start when you request a PR using the Github Action mechanism (called runner on gitlab). If the action passes (green signal), you can go to the next step. If not, you will have to fix the issue (again you can ask assistance if you don’t understand the error).\n\nOnce the PR is checked, mention one of your colleage as reviewer."
  },
  {
    "objectID": "instructions.html#one-chapter-corresponds-at-least-to-one-branch",
    "href": "instructions.html#one-chapter-corresponds-at-least-to-one-branch",
    "title": "How to contribute",
    "section": "",
    "text": "Create a specific branch for your chapter named an_explicit_name_for_the_branch and switch on this branch\n\ngit checkout -b an_explicit_name_for_the_branch\nIn the development of the project, you might find necessary to have several branches per chapter.\n\nCreate a quarto file for the chapter chapter0.qmd in your branch\n\ngit add chapter0.qmd\ngit commit -m \"first commit in the chapter branch\"\n\nPush everything on the remote repo on Github\n\nFor the first push after the branch creation, you have to specify the name of the branch on the remote repo and you can use git  push --set-upstream origin an_explicit_name_for_the_branch or\nFor the push to come after the first one, you will simply push by\ngit  push\nOnce you are quite happy with your production, you will be willing to integrate your production on the main branch. A good practice is to ask the permission to push on the main branch, which is named a pull request (PR).\n\nAsk for a PR on Github\nIf needed, specify in the PR message the package you need and mention MarieEtienne as reviewer of the PR.\n\nA mock rendering of the qmd file will start when you request a PR using the Github Action mechanism (called runner on gitlab). If the action passes (green signal), you can go to the next step. If not, you will have to fix the issue (again you can ask assistance if you don’t understand the error).\n\nOnce the PR is checked, mention one of your colleage as reviewer."
  },
  {
    "objectID": "instructions.html#as-a-reviewer",
    "href": "instructions.html#as-a-reviewer",
    "title": "How to contribute",
    "section": "As a reviewer",
    "text": "As a reviewer\nYour role is essential as you are responsible for the quality of the submission you were assigned to. Read carefully the production and ask for correction/clarification if needed. One you are happy with the correction you can accept the PR."
  },
  {
    "objectID": "fichier_r.html",
    "href": "fichier_r.html",
    "title": "Unveiling the influence of climatic factors on reproductive patterns in neotropical bats through a Bayesian framework",
    "section": "",
    "text": "French Guiana is a territory belonging to the bio-geographic unit of the Guiana Shield (Hollowell and Reynolds (2005)) With an area of 83,846 km², it hosts, like its neighboring territories, remarkable species diversity. Covered by 97% forest habitat mosaic, its extreme species diversity is well-documented. French Guiana represents a global hotspot in terms of bat species richness. The most commonly used method for studying bats in tropical regions is ground-level mist netting, followed by canopy netting and direct roost searche (MacSwiney G., Clarke, and Racey (2008)). It is with these methods that the first studies on bat community characterization were conducted (Charles-Dominique Pierre, Brosset André, and Jouard Sylvie (2001)). To date, very little work has focused on exploring the reproduction patterns of Neotropical bat communities. Reproductive patterns are closely related to rainfall regimes (Ruiz-Ramoni, Ramoni-Perazzi, and Munoz-Romo (2016)) frequently occurring twice a year in tropical regions.\n\nThe data collected on the species of bats captured by date and location in French Guiana, and containing information on sex, age and reproductive state\n\nThe meteorological data of French Guiana from 1950 to 2024\n\nThe capture locations coordinates (degree minute second)"
  },
  {
    "objectID": "fichier_r.html#a.-importation-of-datasets-and-packages",
    "href": "fichier_r.html#a.-importation-of-datasets-and-packages",
    "title": "Unveiling the influence of climatic factors on reproductive patterns in neotropical bats through a Bayesian framework",
    "section": "A. Importation of datasets and packages",
    "text": "A. Importation of datasets and packages"
  },
  {
    "objectID": "fichier_r.html#b.-processing-of-the-abiotic-dataset",
    "href": "fichier_r.html#b.-processing-of-the-abiotic-dataset",
    "title": "Unveiling the influence of climatic factors on reproductive patterns in neotropical bats through a Bayesian framework",
    "section": "B. Processing of the abiotic dataset",
    "text": "B. Processing of the abiotic dataset\n\nFirstly we concatenate all the abiotic data together\nThen we start to clean the abiotic the dataset by deleting all years that precede the first event of capture, the we use the Lubridate R package (Spinu, Grolemund, and Wickham (2010)) to formate the data column as we want and the dplyr R package (Wickham et al. (2023)) to reorganize the data set.\n\n\ndata_abiot&lt;-rbind(data_abiot_50_22, data_abiot_23_24)\ndata_abiot &lt;- data_abiot %&gt;%\n  filter(AAAAMMJJ &gt;= 20141028) %&gt;% \n  mutate(AAAAMMJJ = ymd(AAAAMMJJ)) %&gt;% \n  mutate(Year = year(AAAAMMJJ)) %&gt;% \n  mutate(AAAAMMJJ = format(AAAAMMJJ, \"%d-%m-%Y\")) %&gt;% \n  select(NUM_POSTE, NOM_USUEL, LAT, LON, AAAAMMJJ, RR, TM, TAMPLI, FFM, Year) %&gt;%\n  rename(date = AAAAMMJJ, rain_mm = RR, Temperature = TM, ampli_Temp = TAMPLI, wind_ms = FFM, COMMUNE = NOM_USUEL)%&gt;% \n  mutate(julian_day = yday(date)) \n\nComputing moonlight intensity :\n\nFunction that simulates the lunar cycle as a proxy for night-time luminosity\n\n\nLune &lt;- function(date){\n  sortie &lt;- c() \n  for(i in 1:length(date)){ \n    date_num &lt;- as.numeric(as.Date(date[i],format=\"%d-%m-%Y\")) \n    sortie[i] &lt;- (0.5*(cos((date_num-21)*((2*pi)/(29.530589)))+1)) \n  }\n  return(sortie)\n}\n\ndata_abiot$Lune &lt;-Lune(data_abiot$date)"
  },
  {
    "objectID": "fichier_r.html#c.-processing-of-the-biotic-dataset",
    "href": "fichier_r.html#c.-processing-of-the-biotic-dataset",
    "title": "Unveiling the influence of climatic factors on reproductive patterns in neotropical bats through a Bayesian framework",
    "section": "C. Processing of the biotic dataset",
    "text": "C. Processing of the biotic dataset\n\nData_chiro table pre-processing : We only keep the columns of interest, then we only keep the female individuals because the reproduction indices are mainly observable on females. We only keep adult individuals because this is the age class likely to have reproductive indices.\n\n\ndata_chiro &lt;- data_chiro %&gt;%\n  select(c(Année, Commune, Localité, Date, Espèce, Sexe, Repro, Age)) %&gt;% #select the columns we want\n  filter(Sexe == \"F\") %&gt;% \n  filter(Age == \"AD\") %&gt;% \n  filter(is.na(Repro)*1==0)%&gt;%\n  mutate(Date = ymd(Date)) %&gt;%  \n  mutate(Year = year(Date)) %&gt;% \n  mutate(Date = format(Date, \"%d-%m-%Y\"))%&gt;% \n  mutate(julian_day = yday(Date))%&gt;% #Date =julian_day\n  rename(LIEU_DIT = Localité, COMMUNE = Commune) #on renomme\n\nConverting DMS coordinates to decimal coordinates :\n\nFunction to converting minute/second degree into decimal degrees\n\n\nconvert_dms_to_decimal &lt;- function(dms) {\n  parts &lt;- str_match(dms, \"(\\\\d+)°(\\\\d+)'(\\\\d+\\\\.?\\\\d*)''\\\\s([NSEW])\")\n  degrees &lt;- as.numeric(parts[, 2]) \n  minutes &lt;- as.numeric(parts[, 3])\n  seconds &lt;- as.numeric(parts[, 4])\n  direction &lt;- parts[, 5]\n  decimal &lt;- degrees + minutes / 60 + seconds / 3600\n  if (direction %in% c(\"S\", \"W\")) {\n    decimal &lt;- -decimal\n  }\n  \n  return(decimal)\n}\n\n\nWe convert the DMS coordinates to decimal coordinates and we merge it with data_chiro by the capture locality\n\n\nlibrary(stringr)\ncoord_chiro &lt;- coord_chiro %&gt;%\n  rowwise() %&gt;%  \n  mutate(\n    lon_dms = str_extract(COORD, \"^[^N]+W\"), \n    lat_dms = str_extract(COORD, \"[^W]+N\"),  \n    Longitude = convert_dms_to_decimal(lon_dms), \n    Latitude = convert_dms_to_decimal(lat_dms) \n  ) %&gt;%\n  ungroup() %&gt;% \n  select(COMMUNE, LIEU_DIT, Latitude, Longitude)%&gt;%\n  rename(LAT = Latitude, LON = Longitude)\n\ndata_chiro &lt;- data_chiro %&gt;%\n  inner_join(coord_chiro, by = \"LIEU_DIT\") \n\ndata_chiro &lt;- data_chiro%&gt;%\n  select(COMMUNE.x,LIEU_DIT,Date,Espèce,Sexe,Repro,Age,Year,julian_day,LAT,LON)%&gt;% \n  rename(COMMUNE = COMMUNE.x)"
  },
  {
    "objectID": "fichier_r.html#d.-graphical-representation-of-french-guiana-with-the-incorporation-of-meteorological-stations-and-capture-points",
    "href": "fichier_r.html#d.-graphical-representation-of-french-guiana-with-the-incorporation-of-meteorological-stations-and-capture-points",
    "title": "Unveiling the influence of climatic factors on reproductive patterns in neotropical bats through a Bayesian framework",
    "section": "D. Graphical representation of French Guiana with the incorporation of meteorological stations and capture points",
    "text": "D. Graphical representation of French Guiana with the incorporation of meteorological stations and capture points\nIn the graphic we can see in blue the capture points and in green the meteorological stations\n\nlimite &lt;- matrix(c(-54.40582467596958,5.123666986130482,0 -54.45958864979806,4.753175826159146,0 -54.43393543693306,4.077331065323269,0 -54.01198973780399,3.581399050490593,0 -54.20921816638264,3.132878544854336,0 -54.21013685965725,2.796587485871633,0 -54.45803260870573,2.441977197957256,0 -54.68709817836254,2.314479358976484,0 -54.15543583603689,2.123868408305178,0 -53.7651653142448,2.30335873628299,0 -53.35415060581271,2.164099707075567,0 -52.94875879245732,2.132858726757194,0 -52.56611638847146,2.518366090728264,0 -52.59199025844659,2.634734023219086,0 -52.39229001432994,2.890167168832993,0 -52.37091318927082,3.144918005801542,0 -52.21064002801557,3.274351081759725,0 -51.9836274889358,3.696015530721377,0 -51.6721839730206,4.031282773145124,0 -51.63663780527241,4.28966735155517,0 -51.9023261931293,4.501855027711033,0 -52.05244725433236,4.818896971774704,0 -52.51627884489513,5.026927311475695,0 -52.703088477061,5.197262336288941,0 -53.15061905132664,5.577522799535109,0 -53.53420039840946,5.573574890423137,0 -53.95403768383684,5.781472322818466,0 -54.40582467596958,5.123666986130482),ncol=2,byrow=T)\n\nplot(limite[,1],limite[,2],type='l')\npoints(data_abiot$LON,data_abiot$LAT,pch=20,col='green')\npoints(coord_chiro$LON,coord_chiro$LAT,pch=20,col=\"blue\")\n\n\n\n\nTo estimate the meteorogical values at capture sites, we used spatial interpolation. For each date and each value of interest, we measured at first wether or not there was an spatial structure using the moran test. If there is no spatial structure, we estimate the value by meaning the observed values. If there is a spatial structure, we realise a kriging. Because of the necessity to automatise this interpolation, the method is not completely correct, however the weather in French Guiana is not very heterogenous, and is mostly gradients to the ocean or east-west gradient. Morover, the data we obtain show the same patterns of dry season and rain season, and for all the values."
  },
  {
    "objectID": "fichier_r.html#a.-quick-introduction-to-the-bayesian-approach",
    "href": "fichier_r.html#a.-quick-introduction-to-the-bayesian-approach",
    "title": "Unveiling the influence of climatic factors on reproductive patterns in neotropical bats through a Bayesian framework",
    "section": "A. Quick introduction to the Bayesian approach",
    "text": "A. Quick introduction to the Bayesian approach\nThis theorem is based on conditional probabilities :\n\\(P(B \\mid A) = \\displaystyle{\\frac{ P(A \\mid B) \\; P(B)}{P(A)}}\\)\nBut we might try to explain it more simply as this :\n\\[P(\\text{hypothesis} \\mid \\text{data}) = \\frac{ P(\\text{data} \\mid \\text{hypothesis}) \\; P(\\text{hypothesis})}{P(\\text{data})}\\]"
  },
  {
    "objectID": "fichier_r.html#b.-little-exploration-of-how-our-response-variable-react-with-different-covariates",
    "href": "fichier_r.html#b.-little-exploration-of-how-our-response-variable-react-with-different-covariates",
    "title": "Unveiling the influence of climatic factors on reproductive patterns in neotropical bats through a Bayesian framework",
    "section": "B. Little exploration of how our response variable react with different covariates",
    "text": "B. Little exploration of how our response variable react with different covariates\n\npar(mfrow=c(2,2))\n\nggplot(data_final, aes(Amplitude, repro_positive)) +\n  geom_point() + \n  geom_smooth(method = \"loess\") +\n  scale_y_continuous(trans='log10')\n\nWarning in scale_y_continuous(trans = \"log10\"): log-10 transformation introduced infinite values.\nlog-10 transformation introduced infinite values.\n\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning: Removed 16 rows containing non-finite outside the scale range\n(`stat_smooth()`).\n\n\n\n\nggplot(data_final, aes(julian_day, repro_positive)) +\n  geom_point() + \n  geom_smooth(method = \"loess\") +\n  scale_y_continuous(trans='log10')\n\nWarning in scale_y_continuous(trans = \"log10\"): log-10 transformation introduced infinite values.\nlog-10 transformation introduced infinite values.\n\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning: Removed 16 rows containing non-finite outside the scale range\n(`stat_smooth()`).\n\n\n\n\nggplot(data_final, aes(Pluie, repro_positive)) +\n  geom_point() + \n  geom_smooth(method = \"loess\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\nggplot(data_final, aes(Température, repro_positive)) +\n  geom_point() + \n  geom_smooth(method = \"loess\") +\n  scale_y_continuous(trans='log10')\n\nWarning in scale_y_continuous(trans = \"log10\"): log-10 transformation introduced infinite values.\nlog-10 transformation introduced infinite values.\n\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning: Removed 16 rows containing non-finite outside the scale range\n(`stat_smooth()`).\n\n\n\n\n\nAt this point, we might be tempted to see whether or not these climatic parameters influence the proportion of reproductive individuals… let’s try!!"
  },
  {
    "objectID": "fichier_r.html#c.-study-of-climatic-influence-on-the-proportion-of-breeding-indidivids",
    "href": "fichier_r.html#c.-study-of-climatic-influence-on-the-proportion-of-breeding-indidivids",
    "title": "Unveiling the influence of climatic factors on reproductive patterns in neotropical bats through a Bayesian framework",
    "section": "C. Study of climatic influence on the proportion of breeding indidivids",
    "text": "C. Study of climatic influence on the proportion of breeding indidivids\nLet’s see the distribution of reproductive individuals :\n\nhist(data_final$repro_positive, breaks = 20)\n\n\n\n\nThe number of individuals showing reproductive activity seems to follow a negative-binomial distribution, but we encountered some issues to write and fit model using a negative binomial distribution… anyway ! Let’s try to investigate with a binomial !\nFirst, we create an object containing our covariates of interest, we use a common practice which consists of centering-reducing the values of covariates:\n\ndatax &lt;- list(\n  N = nrow(data_final), \n  repro_positive = data_final$repro_positive,  \n  total_individuals = data_final$total_individuals,  \n  temp = (data_final$Température - mean(data_final$Température)) / sd(data_final$Température),  \n  rain = (data_final$Pluie - mean(data_final$Pluie)) / sd(data_final$Pluie),\n  julian_day = (data_final$julian_day - mean(data_final$julian_day)) / sd(data_final$julian_day))\n\nWe write our null model and we assume that the number of reproductive individuals follows a binomial distribution. Specifically, we define our model as follows:\n\\[\n\\text{repro_positive}[i] \\sim \\text{Binomial}(p[i], \\text{total_individuals}[i])\n\\]\nIn this model, \\(\\text{repro_positive}[i]\\) represents the number of reproductive individuals observed for each observation ( i ), while \\(\\text{total_individuals}[i]\\) is the total number of individuals in the corresponding group. The parameter \\(p[i]\\) is the probability of an individual being reproductive, modeled using the logit link function, where ( a ) is a parameter drawn from a normal distribution with mean 0 and a large variance (0.001), reflecting our prior belief about its value. \\[\n\\text{logit}(p[i]) = a\n\\]\nHere is the null model in Jags language:\n\nmodel_null &lt;- \n  paste(\"\nmodel {\n  for (i in 1:N) {\n    repro_positive[i] ~ dbin(p[i], total_individuals[i])  \n    logit(p[i]) &lt;- a\n  }\n  a ~ dnorm(0, 0.001)  \n}\n\")\n\nThen we set the initial values for the Monte-Carlo Markov Chains, we choose to set two chains to assess initial at different values to see if both converge to same distribution.\n\ninit1 &lt;- list (a = -0.5)\ninit2 &lt;- list (a = 0.5)   \ninits &lt;- list(init1,init2)\n\nWe specify the parameter we want to estimate :\n\nparameters &lt;- c(\"a\")\n\nThe run the model with the function jags() :\n\nchiro_model_null &lt;- jags(data = datax,\n              inits = inits, \n              parameters.to.save = parameters, \n              model.file = textConnection(model_null), \n              n.chains = 2, \n              n.iter = 5000, \n              n.burnin = 1000) \n\nmodule glm loaded\n\n\nWarning in jags.model(model.file, data = data, inits = init.values, n.chains =\nn.chains, : Unused variable \"temp\" in data\n\n\nWarning in jags.model(model.file, data = data, inits = init.values, n.chains =\nn.chains, : Unused variable \"rain\" in data\n\n\nWarning in jags.model(model.file, data = data, inits = init.values, n.chains =\nn.chains, : Unused variable \"julian_day\" in data\n\n\nCompiling model graph\n   Resolving undeclared variables\n   Allocating nodes\nGraph information:\n   Observed stochastic nodes: 246\n   Unobserved stochastic nodes: 1\n   Total graph size: 497\n\nInitializing model\n\n\nAfter fitting the model, we can explore how it went through some useful tools :\n\ntraceplot() allows to see how MCMC converge\n\n\ntraceplot(chiro_model_null, mfrow = c(1,1), varnames = c(\"a\"), ask = F)\n\nWarning in plot.window(...): \"varnames\" is not a graphical parameter\n\n\nWarning in plot.xy(xy, type, ...): \"varnames\" is not a graphical parameter\n\n\nWarning in axis(side = side, at = at, labels = labels, ...): \"varnames\" is not\na graphical parameter\n\nWarning in axis(side = side, at = at, labels = labels, ...): \"varnames\" is not\na graphical parameter\n\n\nWarning in box(...): \"varnames\" is not a graphical parameter\n\n\nWarning in title(...): \"varnames\" is not a graphical parameter\n\n\n\n\n\nWarning in plot.window(...): \"varnames\" is not a graphical parameter\n\n\nWarning in plot.xy(xy, type, ...): \"varnames\" is not a graphical parameter\n\n\nWarning in axis(side = side, at = at, labels = labels, ...): \"varnames\" is not\na graphical parameter\n\nWarning in axis(side = side, at = at, labels = labels, ...): \"varnames\" is not\na graphical parameter\n\n\nWarning in box(...): \"varnames\" is not a graphical parameter\n\n\nWarning in title(...): \"varnames\" is not a graphical parameter\n\n\n\n\nautocorr.plot(as.mcmc(chiro_model_null), ask = F)\n\n\n\n\n\n\n\nWe can also print the object that contain the model to check other features like the estimate of the parameter, the deviance, credible intervals or the number of values used to assess the posterior distribution (n.eff)\n\nprint(chiro_model_null)\n\nInference for Bugs model at \"4\", fit using jags,\n 2 chains, each with 5000 iterations (first 1000 discarded), n.thin = 4\n n.sims = 2000 iterations saved\n         mu.vect sd.vect    2.5%     25%     50%     75%   97.5%  Rhat n.eff\na          1.655   0.073   1.510   1.607   1.654   1.702   1.801 1.001  2000\ndeviance 755.004   1.436 754.025 754.119 754.441 755.291 759.292 1.004  2000\n\nFor each parameter, n.eff is a crude measure of effective sample size,\nand Rhat is the potential scale reduction factor (at convergence, Rhat=1).\n\nDIC info (using the rule, pD = var(deviance)/2)\npD = 1.0 and DIC = 756.0\nDIC is an estimate of expected predictive error (lower deviance is better).\n\n\nNow, we put the estimated values of the two MCMC chains in the same object :\n\nres&lt;-as.mcmc(chiro_model_null)\nres&lt;-rbind(res[[1]], res[[2]])\n\nThen we can compute the mean of the estimated values of the intercept that are &lt; 0 :\n\nmean(res[,'a']&lt;0)\n\n[1] 0\n\n\nAnd we can plot the estimated posterior distribution of our parameter ‘a’ :\n\npar(mfrow=c(1,1))\nplot(density(res[,'a']),xlab=\"\",ylab=\"\", main=\"intercept\",lwd=3,xlim=c(-0.1,2))\nabline(v=0,col='red',lwd=2)\n\n\n\n\nRemember that we defined a non-informative prior on parameter ‘a’ : a ~ dnorm(0, 0.001) to see if test the effect of ‘a’ on \\(p[i]\\)\nYou can compute the Watanabe-Akaike Information Criterion :\n\nsamples_waic_null&lt;-jags.samples(chiro_model_null$model, c(\"WAIC\", \"deviance\"), type = \"mean\",\n                           n.iter = 10000,\n                           n.burnin = 1000,\n                           n.thin = 1)\nsamples_waic_null$p_waic&lt;-samples_waic_null$WAIC\nsamples_waic_null$waic&lt;-samples_waic_null$deviance + samples_waic_null$p_waic\ntmp&lt;-sapply(samples_waic_null, sum)\nwaic_null&lt;-round(c(waic = tmp[[\"waic\"]], p_waic = tmp[[\"p_waic\"]]),1)\nwaic_null\n\n  waic p_waic \n 758.3    3.2 \n\n\nWe write and fit several models with different parameters (rain, temperature, julian day and thermal amplitude) and we compute the WAIC for each of them:\nHere the table of the different models we fitted :\n\nwaic_table&lt;-read.table(\"waic_model.txt\", header = T)\nwaic_table\n\n                          model  waic p_waic\n1          model_rain_temp_jday 523.3   18.4\n2 model_rain_temp_jday_thermamp 528.2   22.6\n3                    model_jday 533.9   11.9\n4               model_rain_jday 541.1   17.6\n5               model_rain_temp 594.0   10.8\n6                    model_null 616.3    3.2\n7                    model_rain 619.9    5.7"
  },
  {
    "objectID": "fichier_r.html#d.-the-best-model",
    "href": "fichier_r.html#d.-the-best-model",
    "title": "Unveiling the influence of climatic factors on reproductive patterns in neotropical bats through a Bayesian framework",
    "section": "D. The best model",
    "text": "D. The best model\nSo our best model is the one with rain/temperature/julian_day covariates, there it is :\n\nmodel_rain_temp_jday &lt;- \n  paste(\"\nmodel {\n  for (i in 1:N) {\n    repro_positive[i] ~ dbin(p[i], total_individuals[i])  # Distribution binomiale\n    logit(p[i]) &lt;- a + b.rain * rain[i] \n                     + b.rain2 * pow(rain[i],2)  \n                     + b.temp * temp[i] \n                     + b.julian_day * julian_day[i]\n                     + b.julian_day2 * pow(julian_day[i], 2)\n                     + b.julian_day3 * pow(julian_day[i], 3)\n                     + b.julian_day4 * pow(julian_day[i], 4)\n  }\n  \n  a ~ dnorm(0, 0.001)  # Prior sur l'intercept\n  b.rain ~ dnorm(0, 0.001)\n  b.rain2 ~ dnorm(0, 0.001)\n  b.temp ~ dnorm(0, 0.001)\n  b.julian_day ~ dnorm(0, 0.001)\n  b.julian_day2 ~ dnorm(0, 0.001) \n  b.julian_day3 ~ dnorm(0, 0.001)\n  b.julian_day4 ~ dnorm(0, 0.001)\n}\n\")\n\nWe decide to assess polynomial effect on \\(rain^2\\) and on \\(julian\\_day^4\\) because of the non-linearity effect on \\(repro\\_positive\\)\nAnd as we made before, we set the initial values for both MCMC, we specify the parameters to be estimated :\n\ninit1 &lt;- list (a = -0.5, \n               b.rain = -0.5, \n               b.rain2 = -0.5, \n               b.temp = -0.5,\n               b.julian_day = -0.5,\n               b.julian_day2= -0.5,\n               b.julian_day3= -0.5,\n               b.julian_day4 = -0.5) \n\ninit2 &lt;- list (a = 0.5, \n               b.rain = 0.5, \n               b.rain2 = 0.5, \n               b.temp = 0.5, \n               b.julian_day = 0.5,\n               b.julian_day2= 0.5,\n               b.julian_day3= 0.5,\n               b.julian_day4 = 0.5)\n\ninits &lt;- list(init1,init2)\n\nparameters &lt;- c(\"a\",\n                \"b.rain\", \n                \"b.rain2\", \n                \"b.temp\",\n                \"b.julian_day\" ,\n                \"b.julian_day2\",\n                \"b.julian_day3\",\n                \"b.julian_day4\")\n\nAnd we run jags() :\n\nchiro_rain_temp_jday &lt;- jags(data = datax,\n                        inits = inits, \n                        parameters.to.save = parameters, \n                        model.file = textConnection(model_rain_temp_jday), \n                        n.chains = 2, \n                        n.iter = 10000, \n                        n.burnin = 1000)\n\nCompiling model graph\n   Resolving undeclared variables\n   Allocating nodes\nGraph information:\n   Observed stochastic nodes: 246\n   Unobserved stochastic nodes: 8\n   Total graph size: 2709\n\nInitializing model\n\nchiro_rain_temp_jday\n\nInference for Bugs model at \"5\", fit using jags,\n 2 chains, each with 10000 iterations (first 1000 discarded), n.thin = 9\n n.sims = 2000 iterations saved\n              mu.vect sd.vect    2.5%     25%     50%     75%   97.5%  Rhat\na               0.420   0.149   0.129   0.318   0.422   0.523   0.706 1.001\nb.julian_day    0.144   0.253  -0.352  -0.025   0.145   0.317   0.620 1.002\nb.julian_day2   2.323   0.324   1.696   2.098   2.321   2.548   2.959 1.018\nb.julian_day3  -0.211   0.152  -0.493  -0.313  -0.215  -0.114   0.088 1.003\nb.julian_day4  -0.573   0.130  -0.815  -0.662  -0.576  -0.487  -0.321 1.000\nb.rain          0.439   0.222   0.004   0.293   0.438   0.582   0.877 1.001\nb.rain2         0.059   0.101  -0.079  -0.016   0.036   0.109   0.307 1.001\nb.temp          0.566   0.130   0.320   0.476   0.565   0.655   0.818 1.000\ndeviance      617.141   7.380 611.055 613.897 616.320 619.280 626.775 1.108\n              n.eff\na              2000\nb.julian_day   2000\nb.julian_day2  2000\nb.julian_day3  1800\nb.julian_day4  2000\nb.rain         2000\nb.rain2        2000\nb.temp         2000\ndeviance       1400\n\nFor each parameter, n.eff is a crude measure of effective sample size,\nand Rhat is the potential scale reduction factor (at convergence, Rhat=1).\n\nDIC info (using the rule, pD = var(deviance)/2)\npD = 27.2 and DIC = 644.4\nDIC is an estimate of expected predictive error (lower deviance is better).\n\n\nAs we made before, we check how the MCMC converged and we trace the autocorrelation plot :\n\ntraceplot(chiro_rain_temp_jday, mfrow = c(2,4), varnames = c(\"a\",\"b.rain\", \"b.rain2\",\"b.temp\",\"b.julian_day\" ,\"b.julian_day2\",\"b.julian_day3\",\"b.julian_day4\"), ask = F)\n\nWarning in plot.window(...): \"varnames\" is not a graphical parameter\n\n\nWarning in plot.xy(xy, type, ...): \"varnames\" is not a graphical parameter\n\n\nWarning in axis(side = side, at = at, labels = labels, ...): \"varnames\" is not\na graphical parameter\n\nWarning in axis(side = side, at = at, labels = labels, ...): \"varnames\" is not\na graphical parameter\n\n\nWarning in box(...): \"varnames\" is not a graphical parameter\n\n\nWarning in title(...): \"varnames\" is not a graphical parameter\n\n\nWarning in plot.window(...): \"varnames\" is not a graphical parameter\n\n\nWarning in plot.xy(xy, type, ...): \"varnames\" is not a graphical parameter\n\n\nWarning in axis(side = side, at = at, labels = labels, ...): \"varnames\" is not\na graphical parameter\n\nWarning in axis(side = side, at = at, labels = labels, ...): \"varnames\" is not\na graphical parameter\n\n\nWarning in box(...): \"varnames\" is not a graphical parameter\n\n\nWarning in title(...): \"varnames\" is not a graphical parameter\n\n\nWarning in plot.window(...): \"varnames\" is not a graphical parameter\n\n\nWarning in plot.xy(xy, type, ...): \"varnames\" is not a graphical parameter\n\n\nWarning in axis(side = side, at = at, labels = labels, ...): \"varnames\" is not\na graphical parameter\n\nWarning in axis(side = side, at = at, labels = labels, ...): \"varnames\" is not\na graphical parameter\n\n\nWarning in box(...): \"varnames\" is not a graphical parameter\n\n\nWarning in title(...): \"varnames\" is not a graphical parameter\n\n\nWarning in plot.window(...): \"varnames\" is not a graphical parameter\n\n\nWarning in plot.xy(xy, type, ...): \"varnames\" is not a graphical parameter\n\n\nWarning in axis(side = side, at = at, labels = labels, ...): \"varnames\" is not\na graphical parameter\n\nWarning in axis(side = side, at = at, labels = labels, ...): \"varnames\" is not\na graphical parameter\n\n\nWarning in box(...): \"varnames\" is not a graphical parameter\n\n\nWarning in title(...): \"varnames\" is not a graphical parameter\n\n\nWarning in plot.window(...): \"varnames\" is not a graphical parameter\n\n\nWarning in plot.xy(xy, type, ...): \"varnames\" is not a graphical parameter\n\n\nWarning in axis(side = side, at = at, labels = labels, ...): \"varnames\" is not\na graphical parameter\n\nWarning in axis(side = side, at = at, labels = labels, ...): \"varnames\" is not\na graphical parameter\n\n\nWarning in box(...): \"varnames\" is not a graphical parameter\n\n\nWarning in title(...): \"varnames\" is not a graphical parameter\n\n\nWarning in plot.window(...): \"varnames\" is not a graphical parameter\n\n\nWarning in plot.xy(xy, type, ...): \"varnames\" is not a graphical parameter\n\n\nWarning in axis(side = side, at = at, labels = labels, ...): \"varnames\" is not\na graphical parameter\n\nWarning in axis(side = side, at = at, labels = labels, ...): \"varnames\" is not\na graphical parameter\n\n\nWarning in box(...): \"varnames\" is not a graphical parameter\n\n\nWarning in title(...): \"varnames\" is not a graphical parameter\n\n\nWarning in plot.window(...): \"varnames\" is not a graphical parameter\n\n\nWarning in plot.xy(xy, type, ...): \"varnames\" is not a graphical parameter\n\n\nWarning in axis(side = side, at = at, labels = labels, ...): \"varnames\" is not\na graphical parameter\n\nWarning in axis(side = side, at = at, labels = labels, ...): \"varnames\" is not\na graphical parameter\n\n\nWarning in box(...): \"varnames\" is not a graphical parameter\n\n\nWarning in title(...): \"varnames\" is not a graphical parameter\n\n\nWarning in plot.window(...): \"varnames\" is not a graphical parameter\n\n\nWarning in plot.xy(xy, type, ...): \"varnames\" is not a graphical parameter\n\n\nWarning in axis(side = side, at = at, labels = labels, ...): \"varnames\" is not\na graphical parameter\n\nWarning in axis(side = side, at = at, labels = labels, ...): \"varnames\" is not\na graphical parameter\n\n\nWarning in box(...): \"varnames\" is not a graphical parameter\n\n\nWarning in title(...): \"varnames\" is not a graphical parameter\n\n\n\n\n\nWarning in plot.window(...): \"varnames\" is not a graphical parameter\n\n\nWarning in plot.xy(xy, type, ...): \"varnames\" is not a graphical parameter\n\n\nWarning in axis(side = side, at = at, labels = labels, ...): \"varnames\" is not\na graphical parameter\n\nWarning in axis(side = side, at = at, labels = labels, ...): \"varnames\" is not\na graphical parameter\n\n\nWarning in box(...): \"varnames\" is not a graphical parameter\n\n\nWarning in title(...): \"varnames\" is not a graphical parameter\n\nautocorr.plot(as.mcmc(chiro_rain_temp_jday), ask = F)\n\n\n\n\n\n\n\n\n\n\nWe put the estimate values in the same object :\n\nres&lt;-as.mcmc(chiro_rain_temp_jday)\nres&lt;-rbind(res[[1]], res[[2]])\n\nAnd we plot the estimated distribution of every parameters :\n\npar(mfrow=c(2,4))\nplot(density(res[,'a']),xlab=\"\",ylab=\"\", main=\"Intercept\",lwd=3,xlim=c(-0.1,2))\nabline(v=0,col='red',lwd=2)\nplot(density(res[,'b.rain']),xlab=\"\",ylab=\"\", main=\"Rainfall\",lwd=3)\nabline(v=0,col='red',lwd=2)\nplot(density(res[,'b.rain2']),xlab=\"\",ylab=\"\", main=\"Rainfall\",lwd=3)\nabline(v=0,col='red',lwd=2)\nplot(density(res[,'b.temp']),xlab=\"\",ylab=\"\", main=\"Temperature\",lwd=3, xlim=c(-0.1,1.5))\nabline(v=0,col='red',lwd=2)\nplot(density(res[,'b.julian_day']),xlab=\"\",ylab=\"\", main=\"julian_day\",lwd=3)\nabline(v=0,col='red',lwd=2)\nplot(density(res[,'b.julian_day2']),xlab=\"\",ylab=\"\", main=\"julian_day2\",lwd=3, xlim = c(0,4))\nabline(v=0,col='red',lwd=2)\nplot(density(res[,'b.julian_day3']),xlab=\"\",ylab=\"\", main=\"julian_day3\",lwd=3)\nabline(v=0,col='red',lwd=2)\nplot(density(res[,'b.julian_day4']),xlab=\"\",ylab=\"\", main=\"julian_day4\",lwd=3)\nabline(v=0,col='red',lwd=2)"
  },
  {
    "objectID": "fichier_r.html#e.-using-our-model",
    "href": "fichier_r.html#e.-using-our-model",
    "title": "Unveiling the influence of climatic factors on reproductive patterns in neotropical bats through a Bayesian framework",
    "section": "E. Using our model",
    "text": "E. Using our model\nNow let’s try to predict some values from our model to better understand the different relations between \\(repro\\_positive\\) and the different covariates.\nFirst, let’s simulate some data !\n\npred_data &lt;- expand.grid(\n  rain = seq(min(datax$rain), max(datax$rain), length.out = 1000), \n  temp = median(datax$temp),\n  julian_day = median(datax$julian_day))\n\nThis grid will allow us to simulate data from the source data.frame “data_final”, for some reasons that we don’t clearly understand… we need to sample each covariate at once and fix the other one to the median.\nThen we compute \\(p[i]\\) for each estimate value from the model : \\[\n\\text{logit}(p_i) = a + b_{\\text{rain}} \\cdot \\text{rain}_i + b_{\\text{rain2}} \\cdot \\text{rain}_i^2 + b_{\\text{temp}} \\cdot \\text{temp}_i + b_{\\text{julian_day}} \\cdot \\text{julian_day}_i + b_{\\text{julian_day2}} \\cdot \\text{julian_day}_i^2 + b_{\\text{julian_day3}} \\cdot \\text{julian_day}_i^3 + b_{\\text{julian_day4}} \\cdot \\text{julian_day}_i^4\n\\]\n\nn_sim&lt;-1000\n\np_sim &lt;- matrix(NA, nrow = n_sim, ncol = nrow(pred_data))\n\nfor (i in 1:n_sim) {\n  sample_idx &lt;- sample(1:nrow(res), 1)\n  a &lt;- res[sample_idx, \"a\"]\n  b.rain &lt;- res[sample_idx, \"b.rain\"]\n  b.rain2 &lt;- res[sample_idx, \"b.rain2\"]\n  b.temp &lt;- res[sample_idx, \"b.temp\"]\n  b.julian_day &lt;- res[sample_idx, \"b.julian_day\"]\n  b.julian_day2 &lt;- res[sample_idx, \"b.julian_day2\"]\n  b.julian_day3 &lt;- res[sample_idx, \"b.julian_day3\"]\n  b.julian_day4 &lt;- res[sample_idx, \"b.julian_day4\"]\n  \n  p_sim[i, ] &lt;- plogis(\n    a + \n      b.rain * pred_data$rain + b.rain2 * pred_data$rain^2 +\n      b.temp * pred_data$temp +\n      b.julian_day * pred_data$julian_day + \n      b.julian_day2 * pred_data$julian_day^2 +\n      b.julian_day3 * pred_data$julian_day^3 + \n      b.julian_day4 * pred_data$julian_day^4\n  )\n}\n\nThen we compute our credible intervals :\n\npred_data &lt;- pred_data %&gt;%\n  mutate(\n    mean_p = apply(p_sim, 2, mean),\n    lower = apply(p_sim, 2, quantile, probs = 0.025),\n    upper = apply(p_sim, 2, quantile, probs = 0.975)\n  )\n\nWe want to get back to the natural scale for the X-axis :\n\nmean(data_final$Pluie)\n\n[1] 6.95171\n\nsd(data_final$Pluie)\n\n[1] 10.36198\n\npred_data$rain &lt;- (pred_data$rain * 10.71609) + 7.087872\n\nThen we can plot our response variable with a covariate ! here the rain :\n\nggplot(pred_data, aes(x = rain)) +\n  geom_line(aes(y = mean_p), color = \"blue\") +\n  geom_ribbon(aes(ymin = lower, ymax = upper), alpha = 0.2) +\n  labs(x = \"Rain (Natural Scale)\", y = \"Probability of Reproduction\") +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))+\n  scale_y_continuous(limits = c(0, 1))\n\n\n\n\nSame task for julian_day… yes it’s a bit boring, we need to improve the code !\n\npred_data &lt;- expand.grid(\n  rain = median(datax$temp), \n  temp = median(datax$temp),\n  julian_day = seq(min(datax$julian_day), max(datax$julian_day), length.out = 1000))\np_sim &lt;- matrix(NA, nrow = n_sim, ncol = nrow(pred_data))\n\nfor (i in 1:n_sim) {\n  sample_idx &lt;- sample(1:nrow(res), 1)\n  a &lt;- res[sample_idx, \"a\"]\n  b.rain &lt;- res[sample_idx, \"b.rain\"]\n  b.rain2 &lt;- res[sample_idx, \"b.rain2\"]\n  b.temp &lt;- res[sample_idx, \"b.temp\"]\n  b.julian_day &lt;- res[sample_idx, \"b.julian_day\"]\n  b.julian_day2 &lt;- res[sample_idx, \"b.julian_day2\"]\n  b.julian_day3 &lt;- res[sample_idx, \"b.julian_day3\"]\n  b.julian_day4 &lt;- res[sample_idx, \"b.julian_day4\"]\n  \n  p_sim[i, ] &lt;- plogis(\n    a + \n      b.rain * pred_data$rain + b.rain2 * pred_data$rain^2 +\n      b.temp * pred_data$temp +\n      b.julian_day * pred_data$julian_day + \n      b.julian_day2 * pred_data$julian_day^2 +\n      b.julian_day3 * pred_data$julian_day^3 + \n      b.julian_day4 * pred_data$julian_day^4\n  )\n}\npred_data &lt;- pred_data %&gt;%\n  mutate(\n    mean_p = apply(p_sim, 2, mean),\n    lower = apply(p_sim, 2, quantile, probs = 0.025),\n    upper = apply(p_sim, 2, quantile, probs = 0.975)\n  )\n\nmean(data_final$julian_day)\n\n[1] 201.5163\n\nsd(data_final$julian_day)\n\n[1] 96.75666\n\npred_data$julian_day &lt;- (pred_data$julian_day * 95.50893) + 203.0329\n\nggplot(pred_data, aes(x = julian_day)) +\n  geom_line(aes(y = mean_p), color = \"blue\") +\n  geom_ribbon(aes(ymin = lower, ymax = upper), alpha = 0.2) +\n  labs(x = \"Julian day (Natural Scale)\", y = \"Probability of Reproduction\") +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))+\n  scale_y_continuous(limits = c(0, 1))\n\n\n\n\nResults: Those results suggest that the probability of being reproductive could be mainly influenced by the two rainy seasons that occurs in the lowlands of French Guiana and, therefore, with the fructification period of many plants. As the extreme majority of the species caugth with mist-nets are frugivorous.\n(We would greatly appreciate advice on how to improve this analysis!)"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Statistics to explore environmental questions",
    "section": "",
    "text": "This website is produced by the M2 MODE student uring year 2024-2025 as part of their assignment in the Online Collaborative Ressources course.\nAfter a short introduction regarding the principles and the tools of a reproducible science, they have been collaborating to produce a book wich presents an example based on environmental data for different statistical examples.\nTable of Contents\n\nBats analysis\nDeterminants of Ant Species Density\nEffects of grazing on Swedish meadows"
  },
  {
    "objectID": "simple_chapter.html",
    "href": "simple_chapter.html",
    "title": "A simple chapter with no code",
    "section": "",
    "text": "This chapter is a simple example of qmd format"
  },
  {
    "objectID": "simple_chapter.html#subsection",
    "href": "simple_chapter.html#subsection",
    "title": "A simple chapter with no code",
    "section": "subsection",
    "text": "subsection\na list\n\nblabla\nblabla 2\nblabla 3"
  }
]