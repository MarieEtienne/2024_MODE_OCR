---
title: "Analysis of the Factors Favorable to Nest Success of Different Bird Species in Two USA States, Wisconsin and Illinois"
author: "Rudy, Tanguy, Manon, Garan, Ana√´lle, Oceane, Victor"
bibliography: references_analyse_birds.bib
execute:
  freeze: auto
format:
  html:
    toc: true
    toc-location: left
---



**Do not forget to set your working directory in the right place** **Menu : Session/Set Working Directory/Choose directory** *And indicate Git/2024_MODE_OCR*

# Data presentation

The dataset (available following this link https://zenodo.org/records/8251495 ) used for this work contains nest records from different studies conducted in North America and more specifically in Wisconsin and Illinois. It was conducted in 13 different counties : Dane, Grant, Green, Iowa, Lafayette, Monroe, Rock, Lee, Ogle, Will, Grundy, Carroll, and Jo Daviess counties. The dataset contains the records of 3257 nests and for each of them different observations.

These observations are the following:

-   ***State***: Illinois or Wisconsin - *qualitative explanatory variable*
-   ***County***: Dane (Wisconsin), Grant (Wisconsin), Green (Wisconsin), Iowa (Wisconsin), Lafayette (Wisconsin), Monroe (Wisconsin), Rock (Wisconsin), Lee (Illinois), Ogle (Illinois), Will (Illinois), Grundy (Illinois), Carroll (Illinois), and Jo Daviess (Illinois) - *qualitative explanatory variable*
-   ***Habitat***: Cool-season Grassland, Pasture, Prairie, Warm-season Grassland - *qualitative explanatory variable*
-   ***Species***: Species of birds - Bobolink, Dickcissel, Eastern Meadowlark, Grasshopper Sparrow, Henslow‚Äôs Sparrow, Savannah Sparrow, Vesper Sparrow, and Western Meadowlark - *qualitative explanatory variable*
-   ***Years***: from 1991 to 2011 - *qualitative explanatory variable*
-   ***Nest Fate***: the fate of the chicks -\> Successly fledged at least one young (1) or Failed (0)- *quantitative explanatory variable*
-   ***Initiation Date***: Date of the first laided egg - *quantitative explanatory variable*
-   ***Number fledged***: Number of chicks that survived and fledged the nest - *quantitative explanatory variable*
-   ***Nest End Date***: the date when the fate of it was recorded - *quantitative explanatory variable*

All theses observations are presented in a table with the following collums :

-   *Nest_ID* = unique nest identifier
-   *State* = State in which nest was located (Illinois or Wisconsin)
-   *County* = County in the state in which nest was located
-   *Habitat* = Grassy habitat in which nest was located (pasture, cool-season grassland, warm-season grassland, or prairie)
-   *Species* = English common name
-   *Year* = Year nest was found
-   *Nest_Fate* = Successly fledged at least one young (1) or Failed (0).
-   *Initiation_Date* = Coded date when the first egg was laid. April 1 = 1; May 1 = 31; June 1 = 62; July 1 = 92; August 1 = 123; September 1 = 154
-   *Number_Fledged* = For a successful nest, number of young in nest on nest end date; For a failed nest, Number_Fledged is 0
-   *Nest_End_Date* = Coded date when the nest failed or was successful. April 1 = 1; May 1 = 31; June 1 = 62; July 1 = 92; August 1 = 123; September 1 = 154

# What kind of questions can we rise ?

Import dataset

```{r,include=FALSE}
# Datatset import under the name of "data"

data <- read.table("Bird_dataset.txt", header = TRUE, stringsAsFactors = TRUE)
```

Charge the packages Download the spDataLarge package, unavailable on CRAN

```{r}
if (!require(spDataLarge)) {
  stop("The package 'spDataLarge' must be installed from the following depot : https://nowosad.github.io/drat/ \n
        Use the following command in order to install : \n
        install.packages('spDataLarge', repos = 'https://nowosad.github.io/drat/', type = 'source')")

}
```

The rest of the packages

```{r, include=FALSE}
# List of required packages
required_packages <- c(
  "knitr",      # for R Markdown chunk options
  "ggplot2",    # for graphs
  "corrplot",   # for correlation matrix calculations
  "ggcorrplot",
  "plot3D",     # for 3D plots
  "DHARMa",     # for model diagnostics
  "rcompanion", # for pseudo R¬≤ in models
  "lattice",    # for multipanel graphics
  "dplyr",      # for data manipulation
  "FactoMineR", # for ordinations
  "factoextra", 
  "sf",         # for coordinats manipulation
  "terra",      # for maps creation
  "spData",     # for maps creation
  "tmap",       # for maps creation
  "leaflet",    # for maps creation
  "spDataLarge",  # for maps creation
  "maps",       # for maps creation
  "gifski"      # for gifs display
)


# Checking the presence of packages
for (package in required_packages) {
  if (!require(package, character.only = TRUE)) {
    stop(paste("The package", package, "must be installed. Please, use install.packages('", package, "')"))
  } else {
    library(package, character.only = TRUE)
  }
}
```

# First look at the data :

You can visualize the first rows of the dataset by running the following cell :

```{r}
# View the firsts lines of the dataset
head(data)
```

In order to picture the data in a more visual way, we will represent our dataset on a map. The first step in our map creation is the separation of the dataset by the counties.

```{r}
data_list_county <- split(data, data$County)

data_will <- data_list_county[["Will"]]
data_jo_daviess <- data_list_county[["Jo_Daviess"]]
data_lafayette <- data_list_county[["Lafayette"]]
data_iowa <- data_list_county[["Iowa"]]
data_dane <- data_list_county[["Dane"]]
data_green <- data_list_county[["Green"]]
data_grant <- data_list_county[["Grant"]]
data_grundy <- data_list_county[["Grundy"]]
data_lee_ogle <- data_list_county[["Lee/Ogle"]]
data_lee <- data_list_county[["Lee"]]
data_rock <- data_list_county[["Rock"]]
data_monroe <- data_list_county[["Monroe"]]
data_carroll <- data_list_county[["Carroll"]]
data_carroll_whiteside <- data_list_county[["Carroll/Whiteside"]]
```

We are now adding columns for the coordinates of each county, the coordinates were obtained by searching for the counties on openstreetmap.

```{r}
data_will <- data_will %>%
  mutate(longitude_column = -88.0817,
         latitude_column = 41.5250)

data_jo_daviess <- data_jo_daviess %>%
  mutate(longitude_column = -90.4290,
         latitude_column = 42.4167)

data_grundy <- data_grundy %>%
  mutate(longitude_column = -88.4210,
         latitude_column = 41.3570)

data_lee <- data_lee %>%
  mutate(longitude_column = -89.4850,
         latitude_column = 41.8430)

data_carroll <- data_carroll %>%
  mutate(longitude_column = -89.9826,
         latitude_column = 42.0956)

data_lafayette <- data_lafayette %>%
  mutate(longitude_column = -90.1160,
         latitude_column = 42.6825)

data_iowa <- data_iowa %>%
  mutate(longitude_column = -90.1160,
         latitude_column = 42.6825)

data_dane <- data_dane %>%
  mutate(longitude_column = -89.4012,
         latitude_column = 43.0731)

data_green <- data_green %>%
  mutate(longitude_column = -89.6387,
         latitude_column = 42.6017)

data_grant <- data_grant %>%
  mutate(longitude_column = -90.7082,
         latitude_column = 42.8475)

data_rock <- data_rock %>%
  mutate(longitude_column = -89.0187,
         latitude_column = 42.6828)

data_monroe <- data_monroe %>%
  mutate(longitude_column = -90.8129,
         latitude_column = 43.9447)

data_lee_ogle <- data_lee_ogle %>%
  mutate(longitude_column = -89.4038,
         latitude_column = 41.9293)

data_carroll_whiteside <- data_carroll_whiteside %>%
  mutate(longitude_column = -89.9742,
         latitude_column = 41.9527)
```

Now, for each county dataset, we subdivide the said dataset for each year when at least one nest has been observed in this county.

```{r}
county_names <- c("data_will", "data_jo_daviess", "data_lafayette", "data_iowa", 
                  "data_dane", "data_green", "data_grant", "data_grundy", 
                  "data_lee_ogle", "data_lee", "data_rock", "data_monroe", 
                  "data_carroll", "data_carroll_whiteside")

county_dataframes <- mget(county_names)
tables <- c()

for(i in seq_along(county_dataframes)) {
    county <- county_dataframes[[i]]
    county_name <- county_names[i]
    
    if (!is.data.frame(county)) {
        print(paste0("Error: ", county_name, " is not a dataframe"))
        next
    }
    
    if (!"Year" %in% colnames(county)) {
        print(paste0("Error: ", county_name, " does not contain a 'Year' column"))
        next
    }
    
    data_county_year <- split(county, county$Year)

    for(year in min(county$Year):max(county$Year)){
        tableau <- data_county_year[[as.character(year)]]
        
        if (!is.null(tableau)) {
            variable_name <- paste0(county_name, "_", year)
            tables <- c(tables, variable_name)
            assign(variable_name, tableau, envir = .GlobalEnv)
        }
    }
}
```

We went from a full dataset with everything mixed-up to multiple datasets for each year and each county when an observation is available.

Here are, for example, the first rows of the dataframe related to the county of Will in 1995

```{r}
head(data_will_1995)
```

The main information that we want to present on the map are the mean number of fledged birds by nest and the amount of data available for each county and each year.

Here is the creation of a summary dataframe that contains all these informations for each dataframe.

```{r}
annee <- c()
taux_de_reussite <- c()
nb_donnees <- c()
lat <- c()
lon<- c()

# Creation of a summary for each year
for(table_name in tables){
  tablecreated <- get(table_name)
  annee <- c(annee, tablecreated$Year[1])
  taux_de_reussite <- c(taux_de_reussite, sum(tablecreated$Number_Fledged)/nrow(tablecreated))
  nb_donnees <- c(nb_donnees, nrow(tablecreated))
  lat <- c(lat, tablecreated$latitude_column[1])
  lon <- c(lon, tablecreated$longitude_column[1])
}

# Creating a dataframe of thoose summaries
tableau <- data.frame(
  annee = annee, 
  Mean_number_fledged_by_nest = taux_de_reussite, 
  nb_donnees = nb_donnees, 
  lat = lat, 
  lon = lon
)

# Seting the dataframe as a spatial class in order to create a map
tableau_sf <- st_as_sf(tableau, coords = c("lon", "lat"), crs = 4326)
tableau_sf <- st_transform(tableau_sf, crs = st_crs(us_states))
```

As we now have all the data of interest in one single organized table, we can actually create the map.

```{r}
tmap_mode("view")

bird_anim <- tm_shape(us_states) + 
  tm_polygons() + 
  tm_shape(tableau_sf) + 
  tm_symbols(size = "Mean_number_fledged_by_nest", col = "nb_donnees", 
             style = "quantile", title.size = "Mean number fledged by nest", title.col = "Number of nest observed") + 
  tm_layout(title = "Bird Observations Over Time", 
            legend.position = c("left", "bottom"),
            frame = FALSE, 
            legend.show = T) +
  tm_facets(by = "annee", nrow = 1, ncol = 1, free.coords = FALSE)
```

And now, we just have to run the following cell to display the map.

```{r}
tmap_animation(bird_anim)
```

Please, check out the newly created map on the "Viewer" panel of your Rstudio application.

I believe that the first thing we can say about the data, is that it is unevenly distributed. Depending on the year and the county, the number of observed nests changes ; and sometimes not even a single observation is available.

# [1. Data exploration]{.underline}

### Repartition of the data through time

##### Statistical tests

In this part, several statistical tests are performed in order to answer questions.

-   *First question : Does the number of fledged birds depend on the species ?*

H0 : there is no differences between species

First, we observe the data with a boxplot. There is no significant differences through the boxplots.

```{r boxplots}
ggplot(data = data, 
       aes(x = Habitat, 
           y = Nest_End_Date)
       ) +
  geom_boxplot(aes(fill = Habitat)) +
  ggtitle("Nest_End_Date depending on the Habitat")
  theme(
    axis.text.x = element_blank(),
    plot.title = element_text(face = "bold")
    )
```

Then, we test the normality of the data. All the p-values are ranged in a dataframe.

```{r testnormality}
data |>
  # Selection of only two columns of interest
  dplyr::select(  
    Species, 
    Number_Fledged
  ) |>
  # Calculation of the p-value of the shapiro test for each species
  dplyr::group_by(Species) |>
  dplyr::summarise(
    shap = shapiro.test(Number_Fledged)$p
  )
```

Conclusion : each subset does not follow the normality. We can perform a U test (non parametric test) :

```{r Utest}
# Construction of an empty 8x8 dataframe. It will contains each p-value of the U test
cor_df <- as.data.frame(
  matrix(nrow = 8, ncol = 8, NA)
  )
  
# Retrive the species names
species <- as.character(unique(data$Species))

# Rename the matrix
colnames(cor_df) <- species
rownames(cor_df) <- species

data_species <- data |> 
  dplyr::select(
    Species, 
    Number_Fledged
    ) |>
  dplyr::arrange(Species)


for (sp1 in (1:(length(species)))){
  for (sp2 in (1:length(species))){

    ## Retrieve the data of the species 1
    species_1 <- data_species |>
      dplyr::filter(Species == species[sp1]) |>
      dplyr::select(Number_Fledged)

    ## Retrieve the data of the species 2
    species_2 <- data_species |>
      dplyr::filter(Species == species[sp2]) |>
      dplyr::select(Number_Fledged)
    
    ## Formating of the vector containing the number of fledged birds. 
    species_1 <- as.vector(species_1)$Number_Fledged
    species_2 <- as.vector(species_2)$Number_Fledged
    
    ## To put the p.values on the correlation matrix
    cor_df[sp1,sp2] <- wilcox.test(species_1, species_2)$p.value
  }
}
```

Now, we can observe the p-values in the following matrix :

```{r printpvalues}
ggcorrplot(
  corr = cor_df,
  lab = TRUE,
  lab_size = 3,
  show.diag = TRUE,
  type = "upper"
  ) +
  theme(
    axis.text.x = element_text(size = 8,
                               angle = 45),
    axis.text.y = element_text(size = 8)
    ) +
  scale_fill_gradient2(
    low = "tomato2", 
    high = "springgreen3", 
    midpoint = 0.2) +
  ggtitle("P-values of the U-tests with the number of fledged birds as variable")

```

Observation : we see that there is globally no differences in the mean of the groups. So we keep H0.

-   *Second question : we want to summarise the information depending on different factor.*

In the following chunks, a list named *data_summariser* is created and it will contains several dataframes. These dataframes summarise the different quantitative variables (i.e. Nest_Fate, Initiation_Date, Number_Fledged and Nest_End_Date) by the means and for each factor (i.e. County, State, Species and Habitat). There is one dataframe per factor. The goal is to better visualise the repartition of the species as a function of a factor AND to see the means.

Here, we summarise with the factor : Species.

```{r estimators}
## Calculation of the mean of each variables depending on the Species
data_sp <- data |>
  dplyr::select(
    Species,Nest_Fate,Initiation_Date, Number_Fledged, Nest_End_Date
  )|>
  dplyr::group_by(
    Species
    ) |>
  dplyr::summarise(
    count = n(),
    prop_Nest_Fate = sum(Nest_Fate) / length(Nest_Fate),
    mean_Init_Date = mean(Initiation_Date),
    mean_Number_Fledged = mean(Number_Fledged),
    mean_Nest_End_Date = mean(Nest_End_Date),
  )

## Calculation of the mean of each variables depending on the habitat
data_hab <- data |>
  dplyr::select(
    Habitat,Nest_Fate,Initiation_Date, Number_Fledged, Nest_End_Date
  )|>
  dplyr::group_by(
    Habitat
    ) |>
  dplyr::summarise(
    count = n(),
    prop_Nest_Fate = sum(Nest_Fate) / length(Nest_Fate),
    mean_Init_Date = mean(Initiation_Date),
    mean_Number_Fledged = mean(Number_Fledged),
    mean_Nest_End_Date = mean(Nest_End_Date),
  )

## Calculation of the mean of each variables depending on the state
data_state <- data |>
  dplyr::select(
    State,Nest_Fate,Initiation_Date, Number_Fledged, Nest_End_Date
  )|>
  dplyr::group_by(
    State
    ) |>
  dplyr::summarise(
    count = n(),
    prop_Nest_Fate = sum(Nest_Fate) / length(Nest_Fate),
    mean_Init_Date = mean(Initiation_Date),
    mean_Number_Fledged = mean(Number_Fledged),
    mean_Nest_End_Date = mean(Nest_End_Date),
  )

## Calculation of the mean of each variables depending on the county
data_county <- data |>
  dplyr::select(
    State, County, Nest_Fate,Initiation_Date, Number_Fledged, Nest_End_Date
  )|>
  dplyr::group_by(
    State, County
    ) |>
  dplyr::summarise(
    count = n(),
    prop_Nest_Fate = sum(Nest_Fate) / length(Nest_Fate),
    mean_Init_Date = mean(Initiation_Date),
    mean_Number_Fledged = mean(Number_Fledged),
    mean_Nest_End_Date = mean(Nest_End_Date),
  )
data_sp
```

We create a list called data_summariser that will contains each previously created tables.

```{r summarizedata}
data_summariser <-list()  # Creation of the due list data_summariser
data_summariser$Species <- data_sp # Add the Species table
data_summariser$Habitat <- data_hab 
data_summariser$State <- data_state
data_summariser$County <- data_county

data_summariser
```

Convert dates to months to make a MCA:

```{r datesinmonth}
### Creation of a function to replace the number by a month 

num_to_month <- function(num){
  if (num %in% (1:30)){
    res <- "april"
  } else if (num %in% (31:61)){
    res <- "may"
  } else if (num %in% (62:91)){
    res <- "june"
  } else if (num %in% (92:122)){
    res <- "july"
  } else if (num %in% (123:153)){
    res <- "august"
  } else {
    res <- "september"
  }
  return (res)
}
```

Now, we trasform all the quantitative variable into factors.

```{r quantitativeintofactor}
## Conversion into months 
data_ACM <- data
data_ACM$Initiation_Date <- lapply(X = data_ACM$Initiation_Date, 
                                FUN = num_to_month
                                )
data_ACM$Nest_End_Date <- lapply(X = data_ACM$Nest_End_Date, 
                              FUN = num_to_month
                              )
## Conversion into factors
data_ACM <- data_ACM |>
  dplyr::mutate(Nest_Fate = as.factor(Nest_Fate),
                Initiation_Date = as.factor(unlist(Initiation_Date)),
                Number_Fledged = as.factor(Number_Fledged),
                Nest_End_Date = as.factor(unlist(Nest_End_Date)),
                Year = as.factor(Year)
                )
```

##### MCA analysis (data exploring)

Before doing the MCA analysis, we must verify that all the modalities represent at least 3% of the data

```{r proptable}
# Proportions de chaques modalit√©s dans chaques variables:
prop.table(table(data_ACM$State))*100
prop.table(table(data_ACM$County))*100
prop.table(table(data_ACM$Habitat))*100
prop.table(table(data_ACM$Species))*100
prop.table(table(data_ACM$Year))*100
prop.table(table(data_ACM$Nest_Fate))*100
prop.table(table(data_ACM$Number_Fledged))*100
prop.table(table(data_ACM$Initiation_Date))*100
prop.table(table(data_ACM$Nest_End_Date))*100
```

Some of the modalities are under-represented. We must delete them. The modalities under-represented are: Countries Carroll, Carroll/Whiteside, Grundy, Lee and Rock, Species Henslow's Sparrow and Western Meadowlark, half of the years modalities, 6 fledged chicks, and months April and August for both nest initiation date and nest end date.

```{r sortingcounty}
prop.table(table(data_ACM$County))*100 < 3
# We must delete the data of counties Carroll, Carroll/Whiteside, Grundy, Lee and Rock
data_ACM <- data_ACM[-which(data_ACM$County == "Carroll" | 
                              data_ACM$County == "Carroll/Whiteside" | 
                              data_ACM$County == "Grundy" | 
                              data_ACM$County == "Lee" | 
                              data_ACM$County == "Rock"),]
data_ACM$County <- droplevels(data_ACM$County)
```

```{r sortingspecies}
prop.table(table(data_ACM$Species))*100 < 3
# We must delete the data of species Henslow's_Sparrow and Western_Meadowlark
data_ACM <- data_ACM[-which(data_ACM$Species == "Henslow's_Sparrow" | 
                              data_ACM$Species == "Western_Meadowlark"),]
data_ACM$Species <- droplevels(data_ACM$Species)
```

```{r sortingyears}
prop.table(table(data_ACM$Year))*100 < 3
summary(prop.table(table(data_ACM$Year))*100 < 3)
# As half of the modalities are under-represented, we will group the years by 3.

data_ACM <- data_ACM %>%
  mutate(Year = factor(case_when(
    Year %in% c("1991", "1992", "1993") ~ "1991-1993",
    Year %in% c("1994", "1995", "1996") ~ "1994-1996",
    Year %in% c("1997", "1998", "1999") ~ "1997-1999",
    Year %in% c("2000", "2001", "2002") ~ "2000-2002",
    Year %in% c("2003", "2004", "2005") ~ "2003-2005",
    Year %in% c("2006", "2007", "2008") ~ "2006-2008",
    Year %in% c("2009", "2010", "2011") ~ "2009-2011"
  ), levels = c("1991-1993", "1994-1996", "1997-1999", "2000-2002", "2003-2005", "2006-2008", "2009-2011")))

prop.table(table(data_ACM$Year))*100 < 3
# None of the years are still under-represented.
```

```{r sortingnumber_fledged}
prop.table(table(data_ACM$Number_Fledged))*100 < 3
# We will group the nest with 5 or 6 fledged chicks with a modality labelled ">5"
levels(data_ACM$Number_Fledged) <- c(levels(data_ACM$Number_Fledged), ">5")
data_ACM[which(data_ACM$Number_Fledged == 5 | data_ACM$Number_Fledged == 6),]$Number_Fledged <- as.factor(">5")
data_ACM$Number_Fledged <- droplevels(data_ACM$Number_Fledged)
```

```{r sortinginitiation_date}
prop.table(table(data_ACM$Initiation_Date))*100 < 3
# We must delete the data with an initiation date in August and April.
data_ACM <- data_ACM[-which(data_ACM$Initiation_Date == "august" | 
                              data_ACM$Initiation_Date == "april"),]
data_ACM$Initiation_Date <- droplevels(data_ACM$Initiation_Date)
```

```{r sortingnest_end_date}
prop.table(table(data_ACM$Nest_End_Date))*100 < 3
# We must delete the data with an end date in August and April.
data_ACM <- data_ACM[-which(data_ACM$Nest_End_Date == "august" | 
                              data_ACM$Nest_End_Date == "april"),]
data_ACM$Nest_End_Date <- droplevels(data_ACM$Nest_End_Date)
```

Now, we can check again that no modalities are under-represented (threshold 3%).

```{r proptableagain}
# Proportions de chaques modalit√©s dans chaques variables:
prop.table(table(data_ACM$State))*100
prop.table(table(data_ACM$County))*100
prop.table(table(data_ACM$Habitat))*100
prop.table(table(data_ACM$Species))*100
prop.table(table(data_ACM$Year))*100
prop.table(table(data_ACM$Nest_Fate))*100
prop.table(table(data_ACM$Number_Fledged))*100
prop.table(table(data_ACM$Initiation_Date))*100
prop.table(table(data_ACM$Nest_End_Date))*100
```

All the modalities are enough represented. We can now start the MCA analysis.

```{r mca}
# MCA without the Nest IDs.
ACM_bird <- MCA(data_ACM[,-1])
```

```{r inertiaofaxis}
fviz_eig(ACM_bird, main="histogram of % inertia", addlabels = T)
```

The inertia holded by the first axis is very low (9.3%)

Let's see wich modalities are significantly contributing to the analysis, for the axis 1 and 2

```{r contributionsofmodalities}
fviz_contrib(ACM_bird, choice='var', axes=1)
fviz_contrib(ACM_bird, choice='var', axes=2)
```

Let's print only the modalities above the thresold of 1/n, n is the number of modalities, and the modalities above this thresold are significantly contributing to the MCA.

```{r printcontributingmodalities}
# We set the thresold for significant modalities
threshold <- (1/nrow(ACM_bird$var$contrib))*100

# We extract significant contributions for dim 1
var_contrib <- get_mca_var(ACM_bird)$contrib
significant_vars_dim1 <- rownames(var_contrib)[var_contrib[, 1] > threshold]
length(significant_vars_dim1)

# We extract significant contributions for dim 2
significant_vars_dim2 <- rownames(var_contrib)[var_contrib[, 2] > threshold]
length(significant_vars_dim2)

significant_vars_tot <- unique(c(significant_vars_dim1, significant_vars_dim2))
length(significant_vars_tot)
# There is 24 significant modalities on dimension 1 and 2. Let's print them on the graph

fviz_mca_var(ACM_bird, col.var='blue', repel = T, alpha.var = "contrib")
fviz_mca_var(ACM_bird, col.var='blue', repel = T, select.var = list(contrib = 24))
```

```{r printindividals_modalities}
# Representation of the individuals between axis 1 and 2, coloring for each variable
plotellipses(ACM_bird, means = F)
```

We can see that the nests are clearly separated by the state they come from. We can see a light shift on axis 2 with the nest fate values. The other variables are forming less distinct groups.

On axis 1, the most contributing variable is the state Illinois. It is associated with the specie Dickcissel, with the county Will and Lee/Ogle, years 1994-1996, and the warm season on Grassland. On the other side of the axis, the specie Savannah Sparrow is higly associated with years 2000-2002, and also with the county Lafayette and Iowa and the state Wisconsin.

On axis 2, the most contributing variable is the county Dane, and associated with years 2006-2008 and cool season Grassland. It is also associated with the specie Bobolink, the nest fate equal 1, and the number fledged superior or equal to 5. To say otherwise, the nesting birds have a better success in the county Dane, especially between 2006 and 2008 and during the cool season in grasslands. The specie Bobolink is also highly successive in nesting a lot of chicks. On the other side of the axis, the variable significantly contributing are years 1997-1999, state Illinois, nest end in July, habitat pasture and county Jo Daviess, with nest fate 0 and number fledged 0. Therefore, it is most likely that these conditions are decreasing the probabilities of success in nesting chicks.

# II. Analysing the relationship between nest fate and county, habitat, species, year, initiation date using a generalized linear model (GLM) with a binomial distribution

## A. Data Exploration

In this part we choose to explain the nest fate with different variables. We chose to focus on the state of Illinois because adding the state might lead to bad modelling as there might be not enough data for each of them.

```{r,include=FALSE}

# Selecting the data of interest (here our study is going to focus on the state of illinois)
data_Illinois <- subset(data, data$State == "Illinois")

# Converting explanatory variables (or covariates) into factor (they were intially character chain )
data_Illinois$County <- as.factor(data_Illinois$County)
data_Illinois$Habitat <- as.factor(data_Illinois$Habitat)
data_Illinois$Species <- as.factor(data_Illinois$Species)
data_Illinois$Year <- as.factor(data_Illinois$Year)

# checking for missing values
colSums(is.na(data_Illinois))

```

Variables are :

-   *Nest_Fate* : Response variable, binary
-   *County* : qualitative explanatory variable
-   *Habitat* : qualitative explanatory variable
-   *Species* : qualitative explanatory variable
-   *Year* : qualitative explanatory variable
-   *Initiation_Date* : Quantitative explanatory variable

**Aim of the study** : We want to model the fate of the nest as a response of the County, the Habitat, the Species, the Year, the Initiation date. We are looking for a model that could explain the distribution of Nest fate.

**Method** : Here our response variable is either a sucess or a failure. This response follows a **binomial distribution** with the probability density function $$P(X = k) = \binom{n}{k} p^k (1-p)^{n-k}$$

The term $$ \binom{n}{k} $$ is the binomial coefficient, which represents the number of ways to choose ( k ) successes from ( n ) trials.

$$ p $$ is the probability of success on a single trial.

$$1 - p$$ is the probability of failure on a single trial.

Every statistical analysis starts with the exploration of the dataset.

### Outlier in $Y$

Here we are checking the values of Y (the values of Nest Fate)

```{r dataY}
#| echo: true
#| code-fold: true
#| code-summary: "Show the code"
# Number of 0 and 1 in Y
table(data_Illinois$Nest_Fate)

```

According to the results table, it appears that overall, there are roughly twice as many failures as successes.

### For quantitative Xs : outlier and distribution of $X$ values

Here we have one quantitative explanatory variable $X$. We check its distribution and if there is any outlier value.

```{r dataCov, fig.height=3, fig.width=8}
#| echo: true
#| code-fold: true
#| code-summary: "Show the code"

par(mfrow=c(1,3))

# Length
# Cleveland plot
dotchart(data_Illinois$Initiation_Date,pch=16,col='dodgerblue3',xlab='Initiation Date')
# Histogram
hist(data_Illinois$Initiation_Date,col='dodgerblue3',xlab="Initiation Date",main="")
# Quantile-Quantile plot
qqnorm(data_Illinois$Initiation_Date,pch=16,col='dodgerblue3',xlab='')
qqline(data_Illinois$Initiation_Date,col='red',lwd=2)
```

We do not observe any outliers and it seems that the initiation date of the nesting period follows a normal distribution.

### For each qualitative explanatory variable $X$ : Modalities and number of individuals for each of them

We need to analyse the modalities and the number of individuals for each modality.

```{r}

#| echo: true
#| code-fold: true
#| code-summary: "Show the code"

# Factor County
summary(data_Illinois$County)

# Factor Habitat
summary(data_Illinois$Habitat)

# Factor Species
summary(data_Illinois$Species)

# Factor Year
summary(data_Illinois$Year)
```

The results tables provided by our script show different things. First of all for the **County** variable we can observe that some counties have very little records. For example Carrol/Whiteside has 5 records of nest while counties like Jo Daviess have 292 records. This could lead to mis-modelling so attention on the model results is necessary. For **Habitat** variable it seems that one habitat in particular (Pasture) has more records than the other. For the **Species** variable, similarly to county variable, we observe that some species have more records than others. We observe the same for the **Year** variable.

### Relationships between Y and Xs ?

We can then analyse graphically if we might have relationships between $Y$ and $Xs$.

```{r datagraph, fig.height=4, fig.width=10}
#| echo: true
#| code-fold: true
#| code-summary: "Show the code"

par(mfrow=c(1,3), mar=c(5, 4, 4, 2) + 0.1) 

# Initiation_Date
plot(data_Illinois$Nest_Fate ~ data_Illinois$Initiation_Date, 
     pch=16, 
     col='dodgerblue3',
     xlab='Initiation_Date', 
     ylab='Nest_Fate',
     cex.lab=1.2,  
     cex.axis=1.2)

# Define the color palette
color <- c('dodgerblue3', 'darkred', 'forestgreen', 'gold', 
           'purple', 'orange', 'cyan', 'magenta', 
           'salmon', 'lightseagreen', 'plum', 
           'yellowgreen', 'sandybrown', 'steelblue')

# County
mosaicplot(data_Illinois$Nest_Fate ~ data_Illinois$County, 
           col = color, 
           main="", 
           cex.axis=0.8,  
           las=2)        
title("Relationship Nest Fate & County", cex.main=1.2)  

# Habitat
mosaicplot(data_Illinois$Nest_Fate ~ data_Illinois$Habitat, 
           col = color[1:4],  
           main="",  
           cex.axis=0.8,
           las=2)
title("Relationship Nest Fate & Habitat", cex.main=1.2)  

# Species
mosaicplot(data_Illinois$Nest_Fate ~ data_Illinois$Species, 
           col = color[1:8],  
           main="", 
           cex.axis=0.8,
           las=2)
title("Relationship Nest Fate & Species", cex.main=1.2)  

# Year
mosaicplot(data_Illinois$Nest_Fate ~ data_Illinois$Year, 
           col = color[1:6],  
           main="", 
           cex.axis=0.8,
           las=2)
title("Relationship Nest Fate & Year", cex.main=1.2) 


```

Looking at those graphs it doesn't seems like the **Initiation_date**, the **County** or the **Habitat** has any effects on the **Nest_fate**. Maybe a little bit for **County** but the statistical analysis afterward will enable us to have more information on which variable has an effect. For the **Year** and the **Species** we might observe a little difference, but still really light.

### Analysing interaction between Xs

In any modelling approach there is a need to check for interactions between variables. In our study we judge that there is none.

### Checking collinearity between $Xs$

To avoid multicollinearity in modeling, we need to analyze how the explanatory variables $X_s$ are related. It is important to check for collinearity. Indeed if some variables are correlated they measure the same thing and therefore keeping both of them might lead to bad prediction.

```{r datacolin, fig.height=4, fig.width=8}
#| echo: true
#| code-fold: true
#| code-summary: "Show the code"

# Checking collinearity between qualitative explanatory variable

# Contingency table between County and Habitat
table(data_Illinois$County, data_Illinois$Habitat)


# Contingency table between Species and Year
table(data_Illinois$Species, data_Illinois$Year)

# Contingency table between Habitat and Species
table(data_Illinois$Habitat, data_Illinois$Species)


# Boxplots to check for relationship between Initiation_Date and the qualitative explanatory variables

# Initiation_Date and County
boxplot(data_Illinois$Initiation_Date ~ data_Illinois$County, 
        xlab="County", 
        ylab="Initiation Date", 
        cex.axis=0.8)          

# Initiation_Date and Habitat
boxplot(data_Illinois$Initiation_Date ~ data_Illinois$Habitat, 
        xlab="Habitat", 
        ylab="Initiation Date", 
        cex.axis=0.8)         

# Initiation_Date and Species
boxplot(data_Illinois$Initiation_Date ~ data_Illinois$Species, 
        xlab="Species", 
        ylab="Initiation Date", 
        cex.axis=0.4)         

# Initiation_Date and Year
boxplot(data_Illinois$Initiation_Date ~ data_Illinois$Year, 
        xlab="Year", 
        ylab="Initiation Date", 
        cex.axis=0.8)         

```

Here it seems that there is a strong collinearity between *County* and *Habitat* as well as between **Species** and **Year** and also between **Species** and **Habitat**. Therefore, we are not going to keep **County**, **Habitat** and **Year** as explanatory variables in our model.

## B. Statistical Analysis

### Model building up

Because our response variable is a binary variable that follows a binomial distribution we have a link function : **the logit**.

```{r fullmodel}
#| echo: true
#| code-fold: true
#| code-summary: "Show the code"

# Model formulation
mod1<-glm(Nest_Fate~Species
        + Initiation_Date
        ,data=data_Illinois
        ,family=binomial(link="logit"))
# Then we check for significance
drop1(mod1,test="Chi")
```

The results table shows that Initiation_Date is not significant. However the AIC with Initiation_Date is better which means we should keep this variable despite its lack of significance.

### Model coefficient and its equation

```{r}
#| echo: true
#| code-fold: true
#| code-summary: "Show the code"

# Coefficients of the model
summary(mod1)

```

The following equation is the one of the model : $$\log\left(\frac{p}{1-p}\right) = -1.097853 + 0.189410 \cdot \text{Species}_{\text{Dickcissel}} - 0.382551 \cdot \text{Species}_{\text{Eastern Meadowlark}} + 0.664586 \cdot \text{Species}_{\text{Grasshopper Sparrow}} - 0.327407 \cdot \text{Species}_{\text{Henslow's Sparrow}} - 0.655641 \cdot \text{Species}_{\text{Savannah Sparrow}} + 0.180147 \cdot \text{Species}_{\text{Vesper Sparrow}} + 0.961508 \cdot \text{Species}_{\text{Western Meadowlark}} + 0.000686 \cdot \text{Initiation\_Date}$$

where $p$ is the probability that the event is true.

-   **Intercept (-1.097853)**: The value of the log-odds when all explanatory variables are zero.
-   **Species Dickcissel (0.189410)**: A positive coefficient, but not significant ((p = 0.56565)), indicating that the effect of this species on the chances of nest success is not statistically significant.
-   **Species Eastern Meadowlark (-0.382551)**: A negative coefficient, not significant ((p = 0.25424)).
-   **Species Grasshopper Sparrow (0.664586)**: A positive and significant coefficient ((p = 0.03505)), suggesting that this species increases the chances of nest success.
-   **Species Henslow's Sparrow (-0.327407)**: A negative coefficient, not significant ((p = 0.77686)).
-   **Species Savannah Sparrow (-0.655641)**: A negative coefficient, not significant ((p = 0.42549)).
-   **Species Vesper Sparrow (0.180147)**: A positive coefficient, not significant ((p = 0.66871)).
-   **Species Western Meadowlark (0.961508)**: A positive and significant coefficient ((p = 0.02092)).
-   **Initiation Date (0.000686)**: A positive coefficient, but not significant ((p = 0.86557)), indicating that it does not have a statistically significant effect on nest success.

### Explanation provided by the model

One way to evaluate the goodness of fit for our models is to assess the difference between our model and the null model (which summarizes the data with a single parameter: the mean ofùëå) Y). This null model essentially explains nothing. To do so we calculate a parameter, $${pseudo}-R^2$$ by examining the distance between the deviance of the null model and the residual deviance of our model.

```{r deviance}
#| echo: true
#| code-fold: true
#| code-summary: "Show the code"

# Estimate of deviance explained
(mod1$null.deviance-mod1$deviance)/mod1$null.deviance

# Some others estimates of deviance explained - package 'rcompanion'
nagelkerke(mod1)
```

According to this table, the estimate of the explained deviance is **2.9%** which is very low.

## C. Model validation

### Checking for influential individuals

We make sure that there is no influential individuals.

```{r Contri, fig.height=4, fig.width=4}
#| echo: true
#| code-fold: true
#| code-summary: "Show the code"

par(mfrow = c(1, 1))
plot(cooks.distance(mod1), type = "h", ylim = c(0, 1))
abline(h = 1, col = 2,lwd = 3)
```

The graph does not show any influential individuals.

### Prediction with different data

Here we want to assess if our model is able to well-classify nest based on our data.

```{r Simul, fig.height=4, fig.width=4}
#| echo: true
#| code-fold: true
#| code-summary: "Show the code"

# We could do a simulation
N    <- nrow(data_Illinois)
Pi   <- fitted(mod1)
data_Illinois$Ysim <- rbinom(N, size = 1, Pi)
# Classification table
Z <- table(data_Illinois$Nest_Fate, data_Illinois$Ysim) / N
rownames(Z) <- c("Observed 0", "Observed 1")
colnames(Z) <- c("Predicted 0", "Predicted 1")
Z
#Correctly classified:
sum(diag(Z))

# And repeat this 1000 times, store the results and calculate an average classification table

Pi   <- fitted(mod1)
N    <- nrow(data_Illinois)					
NSim <- 1000                           
diagZ<- matrix(nrow = N, ncol = NSim)
for (i in 1:NSim) {
  Ysim <- rbinom(N, size = 1, Pi)
  Z<- table(data_Illinois$Nest_Fate, Ysim) / N
  diagZ[,i]<-sum(diag(Z))
  }
#Average rate of individuals well-classified by the model
boxplot(diagZ[2,], col='dodgerblue3',ylab='#Rate of nest fate well-classified')
mean(diagZ[2,])
```

Here we have **58%** of good predictions, which is somewhat below the common threshold of 70% for a model to be considered good. This suggests that the model may need improvement.

This result is not surprising given our initial data. Because they are from different studies some variables barely contains some species or years, etc... This could explain why our model is not suitable.

# III. Analysing the relationship between nest fate and county, habitat, species, year, initiation date using a generalized linear model (GLM) with a Poisson distribution

## Variables presentation:

```{r poisson_data_conversion}
data$Nest_Fate <- as.factor(data$Nest_Fate)
data$County <- as.factor(data$County)
data$Habitat <- as.factor(data$Habitat)
data$Year <- as.factor(data$Year)
```

-   *County* : the county in the state where the state has been found. 14 levels factor.
-   *Habitat* : the type of habitat in which the nest has been found. 4 levels factor.
-   *Species* : the species of the bird that has build the nest. 8 levels factor.
-   *Year* : the year of the nest building. 21 levels factor.
-   *Number_Fledged* : the number of birds that hatch on the nest when they hatch. Quantitative variable.

We want to study the impact of four qualitative variables, the habitat, the county, the species and the year over the number of young hatched in the nest *"Number_Fledged"*. It is a counting variable, which imply that it follows a Poisson distribution. A negative binomial distribution could be used but is preferred when the count values are high (which is not really the case here since the highest value is of 6)

A Poisson law is used to describe rare, discrete and independent events. Hence the variable $Y$ that follows a Poisson distribution of parameter $\lambda$ is written: $$Pr(Y=y)=\frac{e^{-\lambda}.\lambda^y}{y!}$$ where $y$ represent the value of the count (here $y$ ‚àà \[0-6\]) and $\lambda$ is the mean value and variance of the Poisson distribution (because in a Poisson law E($y$)= Var($y$)=$\lambda$).

## A. Data exploration

Before any analysis, it is important to have a look at the data.

### Outlayer values in the response variable $Y$ (the number of young in the nest, Number_Fledged) and values distribution:

```{r poisson_datahist, include=TRUE, fig.height=5, fig.width=5}
par(mfrow=c(2,2))
# Boxplot
boxplot(data$Number_Fledged,col='dodgerblue3',ylab='Number of young in nest')
# Cleveland plot
dotchart(data$Number_Fledged,pch=16,col='dodgerblue3',xlab='Number of young in nest')
# Histogram
hist(data$Number_Fledged,col='dodgerblue3',xlab="Number of young in nest",main="")
# Quantile-Quantile plot
qqnorm(data$Number_Fledged,pch=16,col='dodgerblue3',xlab='')
qqline(data$Number_Fledged,col='red',lwd=2)
```

There aren't any outlayer values. There are a lot of value at 0. Maybe we can study only the number of young when there are some. It could be a normal distribution.

```{r poisson_data_filtered, include=TRUE}
# Get rid of the lines where the Number of young individuals in the nest is equal to 0
data_filtered <- subset(data, Number_Fledged != 0)
```

```{r poisson_datahist2, include=TRUE, fig.height=5, fig.width=5}
par(mfrow=c(2,2))
# Boxplot
boxplot(data_filtered$Number_Fledged,col='dodgerblue3',ylab='Number of young in nest')
# Cleveland plot
dotchart(data_filtered$Number_Fledged,pch=16,col='dodgerblue3',xlab='Number of young in nest')
# Histogram
hist(data_filtered$Number_Fledged,col='dodgerblue3',xlab="Number of young in nest",main="")
# Quantile-Quantile plot
qqnorm(data_filtered$Number_Fledged,pch=16,col='dodgerblue3',xlab='')
qqline(data_filtered$Number_Fledged,col='red',lwd=2)
```

Now we have a better view of the data.

### Outlayer values in the explanatory variable $Xs$ and values distribution:

```{r poisson_datafact, include=TRUE}
# Factor County
summary(data_filtered$County)
# Factor Habitat
summary(data_filtered$Habitat)
# Factor Species
summary(data_filtered$Species)
# Factor Year
summary(data_filtered$Year)
```

Problem: there aren't the same number of observations in each level of each factors. Suggestion: normalize by the number of observation for each level.

### Analyze the relation between Y and Xs

```{r poisson_datagraph, include=TRUE, fig.height=7, fig.width=7}

par(mfrow=c(2,2))

# County
boxplot(Number_Fledged~County, varwidth = TRUE, ylab = "Number of young in nest", xlab = "County", col=terrain.colors(14), main = "", data=data_filtered)

# Habitat
boxplot(Number_Fledged~Habitat, varwidth = TRUE, ylab = "Number of young in nest", xlab = "Habitat", col=terrain.colors(4), main = "",data=data_filtered)

# Species
boxplot(Number_Fledged~Species, varwidth = TRUE, ylab = "Number of young in nest", xlab = "Species", col=terrain.colors(8), main = "",data=data_filtered)

# Year
boxplot(Number_Fledged~Year, varwidth = TRUE, ylab = "Number of young in nest", xlab = "Year", col=terrain.colors(21), main = "",data=data_filtered)
```

It's not easy to see if the variables have an impact because some of them have a lot of levels, but it is possible to see small differences between them. The analysis will tell us if they really got an impact over the number of young in the nest.

### Analyze the interactions between Xs

There are a lot of levels so it's hard to plot the interactions. We will see if there are some in the analysis.

```{r poisson_dataInter, include=TRUE, fig.height=3, fig.width=8}

par(mfrow=c(1,3))
# Interactions between County & Habitat
plot(Number_Fledged~County,type='n',ylab = "Number of young in nest",xlab="County", data=data_filtered)
points(Number_Fledged[Habitat=="Pasture"]~County[Habitat=="Pasture"],pch=16,cex=2,col='#000099', data=data_filtered)
points(Number_Fledged[Habitat=="Cool-season Grassland"]~County[Habitat=="Cool-season Grassland"],pch=16,cex=2,col='green', data=data_filtered)
points(Number_Fledged[Habitat=="Prairie"]~County[Habitat=="Prairie"],pch=16,cex=2,col='red', data=data_filtered)
points(Number_Fledged[Habitat=="Warm-season Grassland"]~County[Habitat=="Warm-season Grassland"],pch=16,cex=2,col='yellow', data=data_filtered)
```

Here the example between county and habitat doesn't show a clear pattern. It's hard to conclude on the interaction aspect.

### Checking collinearity between categorical independent variables Xs:

The following code only presents the contingency table between the variables Habitat and Species for convenience, but the same table has to be done with every couple of 4 variables.

```{r poisson_datacolin, include=TRUE, fig.height=4, fig.width=8}

contingency_table<-table(data_filtered$Habitat,data_filtered$Species)
print(contingency_table)

chi2_test<-chisq.test(contingency_table)
print(chi2_test)
print(chi2_test$expected)
```

Problem : for most of the variables the chi¬≤ test can't be done because of the low number of values in each group. The only one that fulfill the conditions and therefore can be made is between Habitat and Species but the result shows that the variables are correlated.

## B. Statistical Analysis

Now that we have a better idea of the data implied in this study, we can begin the statistical analysis.

## Building of the model

Because our response variable follows a poisson distribution we use a link function : **the log function**.

```{r poisson_fullmodel,include=TRUE}
# Model formulation
mod1<-glm(Number_Fledged~ County
        + Species
        + Habitat
        + Year
        ,data=data_filtered
        ,family=poisson(link="log"))
# Variable type : poisson. Link fonction : log
# Then we check for significance
drop1(mod1,test="Chi")
```

We decide to remove the less significative variable : here it's Year.

```{r poisson_model1,include=TRUE}
# Model formulation
mod1<-glm(Number_Fledged~ County
        + Species
        + Habitat
        ,data=data_filtered
        ,family=poisson(link="log"))
#type de la variable : poisson et fonction de lien de type log
# Then we check for significance
drop1(mod1,test="Chi")
```

Now the less significative is Habitat

```{r poisson_model2,include=TRUE}
# Model formulation
mod1<-glm(Number_Fledged~ County
        + Species
        ,data=data_filtered
        ,family=poisson(link="log"))
#type de la variable : poisson et fonction de lien de type log
# Then we check for significance
drop1(mod1,test="Chi")
```

County is still not significative so we have to remove it.

```{r poisson_model3,include=TRUE}
# Model formulation
mod1<-glm(Number_Fledged~ Species
        ,data=data_filtered
        ,family=poisson(link="log"))
#type de la variable : poisson et fonction de lien de type log
# Then we check for significance
drop1(mod1,test="Chi")

summary(mod1)
```

We have the final model with only the Species.

-   $Species{Bobolink }$ = 0 (intercept)\
-   $Species{Dickcissel }$ = $-0.18^{**}$
-   $Species{Eastern Meadowlark }$ = $-0.14^{**}$
-   $Species{Grasshopper Sparrow }$ = $-0.05$
-   $Species{Henslow's Sparrow }$ = $-0.18$
-   $Species{Savannah Sparrow }$ = $-0.19^{***}$
-   $Species{Vesper Sparrow }$ = $-0.32^{***}$
-   $Species{Western Meadowlark }$ = $-0.04$

The equation of the model is the following:

$$ Number_Fledged = 1.29^{***} + (Species{Bobolink} = 0 ;\:Species{Dickcissel} = -0.18^{**} ; \:Species{Eastern Meadowlark} = -0.14^{**} ; \:Species{Grasshopper Sparrow} = -0.05 ; \:Species{Henslow's Sparrow} = -0.18 ; \:Species{Savannah Sparrow = -0.19^{***} ; \:Species{Vesper Sparrow = -0.32^{***} ; \:Species{Western Meadowlark} = -0.04) $$

According to the model's summary, the null deviance is of 599.76 and residual deviance is of 572.82. In order to estimate the explained deviance, one can use the following formula:\

$$Pseudo\:R^2=100\:.\:\frac{Null\:Deviance- Residual\:Deviance}{Null\:Deviance}$$

```{r poisson_deviance, include=TRUE}
# Estimate of deviance explained
(mod1$null.deviance-mod1$deviance)/mod1$null.deviance
```

This is very very bad... The variable species doesn't seem to explain a lot of the variation in the number of young individuals in the nest.

## C. Model validation:

The model that we have done is a generalized linear model so there aren't residual normality or homogeneity. However, it is important to check the independence of residuals.

First of all, in situations where a counting model is used, such as when following a Poisson distribution, the overdispersion has to be checked. It can be done with the following code. If the result is over 1, there are overdispersion and the model should be reconsidered.

```{r poisson_overdisp, include=TRUE}
# Scale parameter calculation
E1 <- resid(mod1, type = "pearson") # (Y - mu) / sqrt(mu)
N  <- nrow(data_filtered)
p  <- length(coef(mod1))
sum(E1^2) / (N - p)
```

The value is of 0.44 so it's okay, the residuals aren't overdispersed.

We can also check for the most influential individuals:

```{r poisson_Contri, include=TRUE, fig.height=4, fig.width=4}

par(mfrow = c(1, 1))
plot(cooks.distance(mod1), type = "h", ylim = c(0, 1))
abline(h = 1, col = 2,lwd = 3)

```

There aren't very influential individuals which can be logical because of the high number of them and the low impact of species over the number of young individuals in the nest.

## Conclusions:

The species of the birds has an impact over the number of young individuals in the nest, but it is clearly not the only variable that explain the variation of the response (only 4% are due to the species).

# IV. ANOVA

Analysis of variance (ANOVA) is one of the most widely used statistical methods in various disciplines. It allows to model the relationship between a quantitative dependent variable $Y$ according to the different modalities of one or more qualitative explanatory variables $Xs$.

We will perform an ANOVA to see the effect of qualitatives variables (state, habitat, species, year) on the quantitative variable Initiation_Date in the Bird_dataset.csv dataset.

We need to check the type of the variables :

```{r Ini_factor data}
#| echo: true
#| code-fold: true
#| code-summary: "Show the code"

# Dataset : variables as factors

data$State<-as.factor(data$State)
data$Habitat<-as.factor(data$Habitat)
data$Species<-as.factor(data$Species)
data$Year<-as.factor(data$Year)
str(data)

```

```{r Ini_missing_data}
#| echo: true
#| code-fold: true
#| code-summary: "Show the code"

# Checking for missing data

colSums(is.na(data))  
```

There is no missing data here.

Before any modeling, we must explore the data in order to avoid possible errors. Below we present the list of steps to follow before proceeding to the modeling:

-   1: Check for the presence of outliers in $Y$ and the distribution of the values of $Y$

-   2: If $X$ is a **quantitative** explanatory variable, check for the presence of outliers and the distribution of the values of $X$ **OR/AND** If $X$ is a **qualitative** explanatory variable, analyze the number of modalities and the number of individuals per modality

-   3: Analyze the potential relationship between $Y$ and the $X_{s}$

-   4: Check for the presence of possible interactions between the $X_{s}$

### Outliers in $Y$ and distribution of values of $Y$

```{r Ini_datahist, fig.height=5, fig.width=5}
#| echo: true
#| code-fold: true
#| code-summary: "Show the code"
par(mfrow=c(2,2))
# Boxplot
boxplot(data$Initiation_Date,col='dodgerblue3',ylab='Initiation date')
# Cleveland plot
dotchart(data$Initiation_Date,pch=16,col='dodgerblue3',xlab='Initiation date')
# Histogram
hist(data$Initiation_Date,col='dodgerblue3',xlab="Initiation date",main="")
# Quantile-Quantile plot
qqnorm(data$Initiation_Date,pch=16,col='dodgerblue3',xlab='')
qqline(data$Initiation_Date,col='red',lwd=2)
```

The different graphs show us no outliers for Initiation_Date. In addition, our Y variable seems to follow a Normal Distribution.

### Outliers and distribution of the values of $X$

The four $Xs$ are factors. We can analyze the number of modalities and the number of individuals per modality.

```{r Ini_datafact}
#| echo: true
#| code-fold: true
#| code-summary: "Show the code"

# Factor State
summary(data$State)
# Factor Habitat
summary(data$Habitat)
# Factor Species
summary(data$Species)
# Factor Year
summary(data$Year)
```

Factor State: The experimental design is not balanced (1071 and 2150 data), but the analysis can be performed because there are enough data in each modality (\> 10).

Factor Habitat: The experimental design is not balanced (from 392 to 1683 data), but the analysis can be performed because there are enough data in each modality (\> 10).

Factor Species: The experimental design is not balanced. Several species have less than 10 data per modality. It will therefore be necessary to remove these data before continuing the analysis

Factor Year: The experimental design is not balanced (from 24 to 448 data), but the analysis can be performed because there are enough data in each modality (\> 10 : threshold from which we consider that carrying out statistical analyses makes sense. You can choose your own threshold).

### Removal of poorly represented modalities (\< 10 data)

```{r Ini_delete_modalites}
#| echo: true
#| code-fold: true
#| code-summary: "Show the code"

# Count the number of occurrences for each modality in data$Species
species_count <- table(data$Species)

# Keep only terms with 10 or more occurrences
data <- data %>% filter(Species %in% names(species_count[species_count >= 10]))

# Show filtered data
head(data)
summary(data$Species)
```

### Analyzing the potential relationship between Y vs Xs

We can graphically analyze the possible relationships between Y and X. This graphical analysis of the relationships between Y and X **does not allow us to predict the significance of the relationship**. Statistical modeling remains the only available means to identify whether a relationship exists or not.

```{r Ini_datagraph, fig.height=3, fig.width=6}
#| echo: true
#| code-fold: true
#| code-summary: "Show the code"

# Boxplot 
par(mfrow=c(1,2))
boxplot(data$Initiation_Date~data$State, varwidth = TRUE, ylab = "Initiation date", xlab = "State", col='darkgrey', main = "")
boxplot(data$Initiation_Date~data$Habitat, varwidth = TRUE, ylab = "Initiation date", xlab = "Habitat", col='darkgrey', main = "")
boxplot(data$Initiation_Date~data$Species, varwidth = TRUE, ylab = "Initiation date", xlab = "Species", col='darkgrey', main = "")
boxplot(data$Initiation_Date~data$Year, varwidth = TRUE, ylab = "Initiation date", xlab = "Year", col='darkgrey', main = "")
```

From the first visualizations, we could make the hypothesis that Year and Species influence Initiation_Date.

### Analysis of possible interactions between the four Xs

The interaction between two factors can only be tested if the factors are crossed (all the modalities of one factor are represented in all the modalities of the other factor and vice versa = a complete factorial design). To estimate the presence of interactive effects, we will develop a graphical approach.

```{r Ini_dataInter, fig.height=4, fig.width=7}
#| echo: true
#| code-fold: true
#| code-summary: "Show the code"

# Interaction table
table(data$State,data$Habitat)
table(data$State,data$Species)
table(data$State,data$Year)
table(data$Habitat,data$Species)
table(data$Habitat,data$Year)
table(data$Species,data$Year)


```

Subsequently, we will not analyze the interactions between the factors since there is no interaction between the Xs variables.

### Search for candidate model

```{r Ini_fullmodel}
#| echo: true
#| code-fold: true
#| code-summary: "Show the code"

# Model formulation
mod1<-lm(Initiation_Date~State+Habitat+Species+Year,data=data)

# Then we check for significance
drop1(mod1,test="F")
```

Since the Habitat factor is not significant, we can remove it in our search for the candidate model.

```{r Ini_candidate_model}
#| echo: true
#| code-fold: true
#| code-summary: "Show the code"

# Model formulation
mod2<-lm(Initiation_Date~State+Species+Year,data=data)

# Then we check for significance
drop1(mod2,test="F")
```

All factors are significant. So we have our candidate model.

To understand how factors influence Initiation_Date, we need to analyze the coefficients of the model.

### Analysis of the coefficients of the candidate model

```{r Ini_coeff_mod2}
#| echo: true
#| code-fold: true
#| code-summary: "Show the code"

# Coefficients of the model
summary(mod2)

# From this listing, you read the coefficients table hereafter :

# Coefficients:
#                            Estimate Std. Error t value Pr(>|t|)    
# (Intercept)                 75.7832     3.1611  23.974  < 2e-16 ***
# StateWisconsin              -4.4838     1.3892  -3.228 0.001261 ** 
# SpeciesDickcissel           21.9212     1.4579  15.036  < 2e-16 ***
# SpeciesEastern Meadowlark    0.5278     1.1198   0.471 0.637432    
# SpeciesGrasshopper Sparrow  10.6652     1.2095   8.818  < 2e-16 ***
# SpeciesSavannah Sparrow      1.9590     1.2370   1.584 0.113382    
# SpeciesVesper Sparrow        6.2687     1.7225   3.639 0.000278 ***
# SpeciesWestern Meadowlark    4.5978     2.3695   1.940 0.052424 .  
# Year1992                    -8.1836     3.9411  -2.076 0.037930 *  
# Year1993                    -9.3039     4.1136  -2.262 0.023780 *  
# Year1994                   -11.0971     4.1890  -2.649 0.008111 ** 
# Year1995                   -11.7709     2.9221  -4.028 5.75e-05 ***
# Year1996                   -11.2748     3.0178  -3.736 0.000190 ***
# Year1997                   -10.4340     2.9302  -3.561 0.000375 ***
# Year1998                    -9.4950     2.7335  -3.474 0.000520 ***
# Year1999                    -6.4308     2.6686  -2.410 0.016018 *  
# Year2000                    -4.7644     2.5708  -1.853 0.063934 .  
# Year2001                    -6.3518     2.6071  -2.436 0.014893 *  
# Year2002                   -10.3377     2.7027  -3.825 0.000133 ***
# Year2003                   -12.4141     3.3412  -3.716 0.000206 ***
# Year2004                   -17.6615     2.9707  -5.945 3.06e-09 ***
# Year2005                   -14.4370     3.4662  -4.165 3.20e-05 ***
# Year2006                   -20.7535     3.0848  -6.728 2.04e-11 ***
# Year2007                   -15.3033     2.8578  -5.355 9.17e-08 ***
# Year2008                   -17.9192     2.7567  -6.500 9.28e-11 ***
# Year2009                   -19.0311     3.2531  -5.850 5.41e-09 ***
# Year2010                   -15.0863     3.2508  -4.641 3.61e-06 ***
# Year2011                   -13.2651     3.5681  -3.718 0.000205 ***
```

### Explanatory power of the model: R¬≤

We can determine the portion of variance of $Y$ explained by our model.

```{r ini_R¬≤}
#| echo: true
#| code-fold: true
#| code-summary: "Show the code"

# R¬≤ of the model
summary(mod2)$adj.r.squared
```

We obtain the adjusted R¬≤ = 0.22. This means that approximately 22% of the variance of Initiation_Date is explained by our modeling.

## Validation of modeling

The assumptions of ANOVA are the same as for any general linear model, namely **independence**, **normality of residuals** and **homogeneity of variances**. In addition, one must check the presence of influential statistical units (i.e. observations having a significant contribution to the construction of the model).

### Normality of residuals

```{r ini_ResidNorm, fig.height=4, fig.width=6}
#| echo: true
#| code-fold: true
#| code-summary: "Show the code"

par(mfrow=c(1,2))
# Histogram
hist(mod2$residuals,col='dodgerblue3',xlab="residuals",main="Check Normality")
# Quantile-Quantile plot
qqnorm(mod2$residuals,pch=16,col='dodgerblue3',xlab='')
qqline(mod2$residuals,col='red',lwd=2)
```

The residuals seem to follow a Normal Distribution.

### Homogeneity of variance

The assumption of homogeneity of variance is the fact that the variation of the residuals is approximately equal over the entire range of explanatory variables, should be verified by plotting the residuals at the estimated values ‚Äã‚Äãand the residuals at the values ‚Äã‚Äãof the significant variables. The residuals should show **no trend**.

```{r ini_Residhomo, fig.height=6, fig.width=8}
#| echo: true
#| code-fold: true
#| code-summary: "Show the code"

par(mfrow=c(2,2))
# residuals vs fitted
plot(residuals(mod1)~fitted(mod1)
     , col='dodgerblue3'
     , pch=16)
# residuals against state factor
boxplot(residuals(mod2)~ data$State, 
        varwidth = TRUE,
        col='darkgrey',
        ylab = "Residuals",
        xlab = "States",
        main = "")
# residuals against species factor
boxplot(residuals(mod2)~ data$Species, 
        varwidth = TRUE,
        col='brown',
        ylab = "Residuals",
        xlab = "Species",
        main = "")
# residuals against year factor
boxplot(residuals(mod2)~ data$Year, 
        varwidth = TRUE,
        col='brown',
        ylab = "Residuals",
        xlab = "Years",
        main = "")
```

We do not observe any trend. Therefore the hypothesis of homogeneity of variance is verified.

### Independence

ANOVA (like any other general linear model) assumes that all statistical units (and therefore residuals) are independent of each other. This issue must be taken into account at the *research design stage*. Given the approach here, the statistical individuals are independent. This assumption is verified.

### Verification of influential individuals

```{r ini_Contri, fig.height=4, fig.width=4}
#| echo: true
#| code-fold: true
#| code-summary: "Show the code"

par(mfrow = c(1, 1))
plot(cooks.distance(mod2), type = "h", ylim = c(0, 1))
abline(h = 1, col = 2,lwd = 3)
```

There is no influential individual.

All conditions being verified, our modeling can be validated.

### Conclusion of our ANOVA

The explanatory variables retained in our model are "State", "Species" and "Year".

The equation of our model is:

$$
\text{Y} = 75.7832 - 4.4838 \cdot \text{State}_{\text{Wisconsin}} + 21.9212 \cdot \text{Species}_{\text{Dickcissel}} + 0.5278 \cdot \text{Species}_{\text{Eastern Meadowlark}} + 10.6652 \cdot \text{Species}_{\text{Grasshopper Sparrow}} + 1.9590 \cdot \text{Species}_{\text{Savannah Sparrow}} + 6.2687 \cdot \text{Species}_{\text{Vesper Sparrow}} + 4.5978 \cdot \text{Species}_{\text{Western Meadowlark}} - 8.1836 \cdot \text{Year}_{1992} - 9.3039 \cdot \text{Year}_{1993} - 11.0971 \cdot \text{Year}_{1994} - 11.7709 \cdot \text{Year}_{1995} - 11.2748 \cdot \text{Year}_{1996} - 10.4340 \cdot \text{Year}_{1997} - 9.4950 \cdot \text{Year}_{1998} - 6.4308 \cdot \text{Year}_{1999} - 4.7644 \cdot \text{Year}_{2000} - 6.3518 \cdot \text{Year}_{2001} - 10.3377 \cdot \text{Year}_{2002} - 12.4141 \cdot \text{Year}_{2003} - 17.6615 \cdot \text{Year}_{2004} - 14.4370 \cdot \text{Year}_{2005} - 20.7535 \cdot \text{Year}_{2006} - 15.3033 \cdot \text{Year}_{2007} - 17.9192 \cdot \text{Year}_{2008} - 19.0311 \cdot \text{Year}_{2009} - 15.0863 \cdot \text{Year}_{2010} - 13.2651 \cdot \text{Year}_{2011}
$$

In this equation each variable takes the value 1 if the corresponding condition is true and 0 otherwise.

But despite all the conditions of the model being validated, this model only explains 22% (R¬≤ = 0.22) of our variable Y (Initiation_Date).

# V. FAMD

### Generical exploration

Here, we perform an FAMD on the initial dataframe. The FAMD is used for tables with qualitative and quantitative variables. The ID are removed because of their uselessness.

```{r famd.format}
#| echo: true
#| code-fold: true
#| code-summary: "Show the code"
data_famd <- data
### Conversion of the Year into factor
data_famd$Year <- as.factor(data_famd$Year)

### Removing of ID
data_famd <- data_famd |>
  dplyr::select(-Nest_ID)
```

We can perform the famd (see @fig-)

```{r famd.real, fig.height=3, fig.width=8, message = FALSE, warning = FALSE}
#| echo: true
#| code-fold: true
#| code-summary: "Show the code"
famd <- FAMD(base = data_famd, graph = FALSE)
```

First, let's see the summary :

```{r famd.summary, fig.height=4, fig.width=8}
#| echo: true
#| code-fold: true
#| code-summary: "Show the code"
#| label : fig-FAMD-summary
#| fig-cap : Summary of the Factorial Analysis of Mixed Data
summary(famd)
```

### Realisation of the FAMD

We can couple the summary with a plot of the inertia per axes :

```{r famd.eig, fig.height=4, fig.width=8}
#| echo: true
#| code-fold: true
#| code-summary: "Show the code"
#| label : fig-FAMD-eig
#| fig-cap : Percentage of explained variances depending on the dimensions
fviz_eig(X = famd,
         addlabels = TRUE)
```

*Conclusion :* We can see that keeping three axes is necessary to cover as much inertia as possible while being parcimonious. However, we will simplify the analysis by keeping only two axes in the interpretation parts. Now, we can see the contribution of the variables to the factorial axes :

```{r fam.contrib, fig.height=4, fig.width=8}
#| echo: true
#| code-fold: true
#| code-summary: "Show the code"
#| label : fig-FAMD-contrib
#| fig-cap : Contributions of the variables to the axes
par(mfrow = c(1,3))
fviz_contrib(X = famd,
             choice = "var",
             axes = 1
             )
### County / State / Year / Species
fviz_contrib(X = famd,
             choice = "var",
             axes = 2
             )
### Year / Habitat / County / Species

fviz_contrib(X = famd,
             choice = "var",
             axes = 3
             )
famd$var$contrib[,1:3] > 1/9*100
### County / Habitat / Year / Species
```

We can see that the only variables that contributed to the axes are the qualitative variables such as County, State, Year, Habitat and Species. The quantitative variables have low contributions.

And now, let's observe the projections of the variables and of the observations :

```{r famd_axes_12}
#| echo: true
#| code-fold: true
#| code-summary: "Show the code"
### Axes 1 and 2
fviz_famd_var(X = famd, 
              repel = TRUE,
              axes = c(1,2),
              col.var = "red",
              alpha.var = 2,
              "quali.var"
              )
fviz_famd_var(X = famd, 
              repel = TRUE,
              axes = c(1,2),
              col.var = "red",
              "quanti.var"
              )
fviz_famd_ind(X = famd, 
              repel = FALSE,
              axes = c(1,2),
              col.ind = "orange",
              col.quali.var = "red"
              )

```

### Realisation of a Hierarchical clustering

We can use the function fviz_cluster to visualise the optimal number of clusters to make. The k-means method is used.

```{r cluster}
#| echo: true
#| code-fold: true
#| code-summary: "Show the code"
famd_g <- as.data.frame(famd$ind$coord[,1:2])
class <- HCPC(famd_g,
              nb.clust = 3
              )

fviz_nbclust(x = famd_g,
             method = "silhouette",
             FUNcluster = kmeans,
             linecolor = "green3"
             )
```

Three clusters is the best choice according to the k-means method.

We can define classes for a Hierarchical Clustering thanks to the function fviz_cluster.

```{r cluster_graph}
#| echo: true
#| code-fold: true
#| code-summary: "Show the code"
fviz_cluster(class, axes = c(1,2), ellipse.type = "convex")
```

The fviz_cluster function shows three clusters. The projection of the variables shows an homogeneous scatterplots. The projection of the observations suggests two groups of individuals, separated merely by the axe of the ordinates. To determine the kinds of the groups, we have to gather variables.

The blue cluster is characterised by :

-   Year = 1991, 1992, 1993, 1995, 1996 et 1997, 1998
-   County = Jo_Daviess, Lee, Lee/Ogle, Grundy, Rock, Will (Illinois)
-   State : Illinois
-   Species : Dickcissel, Western_Meadowlark,
-   Habitat : Prairie, Warm-season Grassland

The red cluster is characterised by :

-   Year : 1994, 1999, 2000, 2001, 2002
-   County : Green, Grant , Monroe, Lafayette
-   State : Wisconsin
-   Species : Savanah Sparrow
-   Habitat : Pasture

The green side is characterised by :

-   Year : 2003, 2004, 2005, 2006
-   County : Dane
-   State : Wisconsin
-   Species : Bobolink, Henslow's Sparrow, Eastern Meadowlark
-   Habitat : Cool-season Grassland

It is necessary to note that several species are near the border between the Illinois and the Wisconsin. Thus they can be seen in both states, which can be counter-intuitive by seeing the FAMD. However, the only factor that can explain this distribution could be years of sampling. There is a clear separation of the years depending on the part of the graphics.

[@byers2017; @ellison2013; @herkert2003; @renfrew2005; @ribic; @ribic2012; @vos2013]

### References

::: {#refs}
:::
