---
title: "groupe 3"
autor: "Gabriel-Marie Arnault, Giuliana Brambilla, Apolline Byrdy, Anaelle Hulbert, Manon Le Bihan, Kilian Prevost, Chloé Van der Swaelmen, Léa Vuille "
editor: visual
---

# **INTRODUCTION** (Apolline et Kilian)

# **EXPLORATION DU JEU DE DONNEES**

## 1. Présentation du jeu de données (Léa et Giuliana)

## 2. Analyse des interactions entre les variables (Chloé et Manon)

# **ANALYSE STATISTIQUE** (Anaelle et Gabriel)

## 1. Construction du modèle (Gabriel)

On cherche à produire le meilleur modèle pour prédire le nombre d'espèces. La variable réponse est un comptage (variable quantitative discrète) de petit effectifs (\<30), la loi appropriée est donc la loi de **Poisson**. Nous allons donc réaliser la modélisation avec un modèle linéaire généralisée de Poisson.

Pour arriver au modèle dit candidat à tester, nous allons partir du modèle dit complet, c'est-à-dire avec toutes les variables explicatives et interactions, et utiliser une méthode pas à pas arrière ou **Backward selection** pour sélectionner les variables et interactions à conserver.

Commençons avec le modèle complet:

```{r}
# Formulation du modèle avec la fonction glm() et family=poisson(link="log")
mod1<-glm(Nsp~ Location
        + Latitude
        + Elevation
        + LogArea
        + Location:Latitude
        + Location:Elevation
        + Location:LogArea
        ,data=dataAnts
        ,family=poisson(link="log"))
```

A partir de ce modèle complet nous allons donc éliminer pas à pas les interactions non significatives.

```{r}
# Etape 1
drop1(mod1,test="Chi")
```

Les trois interactions ne sont pas significatives. On enlève l'interaction 'Location:Latitude' car c'est la 'moins significative'. On peut également remarquer que la fonction drop1() nous informe que c'est en enlevant cette interaction que l'on obtient le meilleur AIC.

On obtient donc le modèle suivant:

```{r}
# Etape 2
mod1<-glm(Nsp~ Location
        + Latitude
        + Elevation
        + LogArea
        + Location:Elevation
        + Location:LogArea
        ,data=dataAnts
        ,family=poisson(link="log"))

drop1(mod1,test="Chi")
```

De la même façon, on enlève l'interaction 'Location:LogArea'.

```{r}
# Etape 3
mod1<-glm(Nsp~ Location
        + Latitude
        + Elevation
        + LogArea
        + Location:Elevation
        ,data=dataAnts
        ,family=poisson(link="log"))

drop1(mod1,test="Chi")
```

On enlève donc également l'interaction 'Location:Elevation'. On regarde donc maintenant la significativité des variables explicatives.

```{r}
# Etape 4
mod1<-glm(Nsp~ Location
        + Latitude
        + Elevation
        + LogArea
        ,data=dataAnts
        ,family=poisson(link="log"))

drop1(mod1,test="Chi")
```

La variable 'LogArea' n'a pas un effet siginificatif, on l'élimine du modèle.

```{r}
# Etape 5
mod1<-glm(Nsp~ Location
        + Latitude
        + Elevation
        ,data=dataAnts
        ,family=poisson(link="log"))

drop1(mod1,test="Chi")
```

Les variables explicatives restantes sont significatives, on conserve donc ce modèle comme modèle candidat.

On va identifier le modèle candidat basé sur la règle de l'AIC et le mode stepwise.

```{r modelAIC, include=TRUE}
library(MASS)
# On construit le modèle complet
modelcomplet<- glm(Nsp~ Location
        + Latitude
        + Elevation
        + LogArea
        + Location:Latitude
        + Location:Elevation
        + Location:LogArea
        ,data=dataAnts
        ,family=poisson(link="log"))

# Sélection du modèle sur la base AIC
modfinal<-stepAIC(modelcomplet,direction="both")

# Analyse du modèle final
drop1(modfinal,test="Chi")
summary(modfinal)

```

Remarque : il est recommandé d'utiliser l'AIC avec plus de 40 individus par paramètre, sinon il existe l'AICc (@YannickOutreman).

Les deux procédures (Backward et StepAIC) convergent : nous obtenons les mêmes modèles candidats.

Pour comprendre comment les 3 variables explicatives (Latitude, Elevation, LogArea) influencent la richesse spécifique des fourmis, nous devons analyser les coefficients du modèle.

## 2. Analyse des coefficients (Gabriel)

```{r}
# Coefficients du modèle
summary(mod1)
#                 Estimate Std. Error z value Pr(>|z|)    
#(Intercept)    11.9368121  2.6214970   4.553 5.28e-06 ***
#LocationForest  0.6354389  0.1195664   5.315 1.07e-07 ***
#Latitude       -0.2357930  0.0616638  -3.824 0.000131 ***
#Elevation      -0.0011411  0.0003749  -3.044 0.002337 ** 
```

Ce tableau détaille les coefficients du modèle avec les coefficients associés à chaque effet majeur significatif. Rappelons que pour un facteur, une modalité est appelée "modalité de référence", c'est-à-dire que son coefficient est égal à 0. D'après ce tableau, les coefficients sont :

**Location factor**\
- $Location_{Bog}$ = 0 (modalité de référence du facteur Location)\
- $Location_{Forest}$ = $+0.63^{**}$\
**Latitude covariate**\
- $\beta_{Latitude}$ = $-0.23^{***}$\
**Elevation covariate**\
- $\beta_{Elevation}$ = $-0.001^{***}$

Ainsi, le modèle candidat s'écrit : $$ log(Species\:Richness) = 11.93^{***} + (Location_{Bog} = 0 ;\:Location_{Forest} = +0.63^{***})\:- 0.23^{***}.Latitude\: -0.001^{***}. Elevation  $$

Rappel : pour modéliser une variable quantitative discrète avec un modèle linéaire généralisé on passe par une fonction de lien, ici avec la loi de Poisson on utilise la fonction log().

## 3. Pouvoir explicatif du modèle (Anaelle)

Afin de connaître la qualité de notre modèle, nous allons calculer la distance entre le modèle candidat et le modèle nul. Le modèle nul est un modèle qui résume les données avec un unique paramètre : la moyenne de $Y$. Ce modèle n'explique pas les données.

Un moyen de connaître la qualité du modèle est de calculer un *pseudo R²*. Pour cela, on détermine la distance entre la déviance du modèle nul et la déviance résiduelle du modèle candidat.

$$Pseudo\:R^2=100\:.\:\frac{Déviance\:nulle- Déviance\:résiduelle}{Déviance\:nulle}$$

Nous pouvons calculer le *pseudo R²* de trois manières différentes. Soit avec la méthode de McFadden, celle de Cox et Snell ou celle de Nagelkerke. Les deux dernières méthodes nécessite le package 'rcompagnon'.

Dans notre exemple, comme vu dans la partie précédente, le modèle nul a une déviance de 102,76 et la déviance résiduelle est de 40,69.

Nous allons donc calculer la qualité du modèle avec les commandes suivantes :

```{r deviance, include=TRUE}
# Estimate of deviance explained
(mod1$null.deviance-mod1$deviance)/mod1$null.deviance

# Some others estimates of deviance explained - package 'rcompanion'
nagelkerke(mod1)
```

Ici, l'estimation de la déviance expliquée est de 60% ou 75%, en fonction de la méthode utilisée.

```{r Prediction,include=TRUE, fig.height=6, fig.width=6}
plot(fitted(mod1)~dataAnts$Nsp,col='dodgerblue3',pch=16,ylab="Valeurs estimées par le modèle",xlab="Valeurs observées")
abline(0,1)
```

## 4. Validation du modèle (Anaelle)

L'*indépendance des résidus* est la seule chose qui limite le modèle linéaire généralisé. L'analyse des résidus permet donc d'identifier d'éventuelles tendances et de vérifier la présence d'unités statistiques influentes.

Dans un premier temps, vérifier la présence de **surdispersion** est indispensable lorsque l'on fait un modèle linéaire généralisé suivant une loi de Poisson. Pour tous les modèles linéaires généralisés utilisant des données de comptage, il faut vérifier l'absence de surdispersion.

Pour cela, nous allons calculer un paramètre appelé 'scale parameter'. Si sa valeur est nettement supérieure à 1 (à partir de 1.6 ou 1.7), il y a surdispersion. Le modèle n'est donc pas valable.

### Vérification de la surdispersion

Quand l'index de dispersion est supérieur à 1,5 , il existe différentes explications.

Cela peut être dû à :

-   Des valeurs abérrantes sont présentes dans le jeu de données. Il faut donc les éliminer.

-   Des covariables sont manquantes. Il faut les ajouter au modèle.

-   Des interactions sont manquantes. Il faut les ajouter au modèle.

-   Une inflation des zéros se produit. Il faut utiliser une regression Binomiale négative à inflation des zéros. (*source*)

-   Une dépendance entre les données et un facteur ou une variable est présente. Il faut utiliser un modèle linéaire général mixte. (*source*)

-   Relation entre les données et les variables ou facteurs n'est pas linéaire. Il faut utiliser un modèle additif généralisé. (*source*)

-   La fonction de lien est mauvaise. Il faut changer la fonction de lien.

-   La variation de $Y$ est grande. Il faut utiliser un modèle linéaire généralisé suivant une loi binomiale négative. (*source*)

Dans notre exemple, nous allons calculer le 'scale parameter'. Pour cela nous allons utiliser la commande :

```{r overdisp, include=TRUE}
# Scale parameter calculation
E1 <- resid(mod1, type = "pearson") # (Y - mu) / sqrt(mu)
N  <- nrow(dataAnts)
p  <- length(coef(mod1))
sum(E1^2) / (N - p)
```

Ici, la dispersion est de 1,02. Il n'y a pas de surdispersion.

### Analyses des résidus

Si les hypothèses de normalité et d'homogénéité des résidus ne sont pas attendues dans les GLM, nous pouvons cependant les analyser graphiquement. En traçant les résidus en fonction des $X_s$ significatifs du modèle, on doit valider l'absence de tendance dans leur distribution. Si on constate une tendance, la modélisation peut être problématique : cela peut être dû à un manque d'ajustement, à une dépendance dans les données ou à des observations influentes. Rappelons que dans les GLM, nous utilisons **les résidus de Pearson** car ils incluent l'hétérogénéité de la variance et sont faciles à calculer et à comprendre.

```{r}
resid<-residuals(mod1, type="pearson")

par(mfrow=c(3,2))
# Histogram
hist(resid,col='dodgerblue3',xlab="residuals",main="")
# Quantile-Quantile plot
qqnorm(resid,pch=16,col='dodgerblue3',xlab='')
qqline(resid,col='red',lwd=2)

# residuals vs fitted
plot(resid~fitted(mod1)
      , col='dodgerblue3'
      , pch=16)
abline(h = 0)

# residuals against Location factor
boxplot(resid~ dataAnts$Location, 
         varwidth = TRUE,
         ylab = "Residuals",
         xlab = "Location",
         main = "")

# residuals against Latitude
plot(resid~ dataAnts$Latitude, 
         pch=16,
         col="dodgerblue3",
         ylab = "Residuals",
         xlab = "Latitude",
         main = "")
abline(h = 0)

# residuals against Elevation
plot(resid~ dataAnts$Elevation, 
         pch=16,
         col="dodgerblue3",
         ylab = "Residuals",
         xlab = "Elevation",
         main = "")
abline(h = 0)

```

L'histogramme des résidus et le Q-Q plot montrent des résidus relativement normaux. Les quatres graphiques suivant montrent la distribution les résidus selon les estimations du modèle et les trois variables explicatives. On peut voir que les résidus restent homogènes peu importe les valeurs des variables explicatives.

### Vérification des individus influents

Afin de vérifier qu'aucun individu est une influence trop importante dans l'analyse, nous allons faire une représentation graphique du poid de chaque individus. Si individus dépasse un poid de 1, il est trop influent dans l'analyse. L'analyse n'est pas valide et il faut la refaire en retirant cet individus.

```{r Contri, include=TRUE, fig.height=4, fig.width=4}

par(mfrow = c(1, 1))
plot(cooks.distance(mod1), type = "h", ylim = c(0, 1))
abline(h = 1, col = 2,lwd = 3)

```

Ici, il n'y a pas d'individus trop influent.

### Analyses des résidus avec DHARMa (bonus)

Pour une représentation graphique différente, nous pouvons utiliser le package DHARMa. Ce package permet d'analyser les résidus et plus particulièrement leur surdispersion et les valeurs abérantes. Ce package met en couleur rouge les résidus ne respèctant les valeurs attendues.

```{r Dharma, include=TRUE}
#testDispersion(mod1)
simulationOutput <- simulateResiduals(fittedModel = mod1, plot = F)
residuals(simulationOutput)
plot(simulationOutput)
residuals(simulationOutput, quantileFunction = qnorm, outlierValues = c(-7,7))
#Représentation des résidus selon la covariable
plotResiduals(simulationOutput, form = dataAnts$Latitude)
```

Dans notre exemple, les résidus ne sont pas surdispersés et ne montre pas de valeurs abérantes.

# **CONCLUSION** (Apolline et Kilian)
