---
title: "groupe 3"
autor: "Gabriel-Marie Arnault, Giuliana Brambilla, Apolline Byrdy, Anaelle Hulbert, Manon Le Bihan, Kilian Prevost, Chloé Van der Swaelmen, Léa Vuille "
editor: visual
---

# **INTRODUCTION** (Apolline et Kilian)

# **EXPLORATION DU JEU DE DONNEES**

## 1. Présentation du jeu de données (Léa et Giuliana)

## 2. Analyse des interactions entre les variables (Chloé et Manon)

# **ANALYSE STATISTIQUE** (Anaelle et Gabriel)

## 1. Construction du modèle (Gabriel)

On cherche à produire le meilleur modèle pour prédire le nombre d'espèces. La variable réponse est un comptage (variable quantitative discrète) de petit effectifs (\<30), la loi appropriée est donc la loi de **Poisson**. Nous allons donc réaliser la modélisation avec un modèle linéaire généralisée de Poisson.

Pour arriver au modèle dit candidat à tester, nous allons partir du modèle dit complet, c'est-à-dire avec toutes les variables explicatives et interactions, et utiliser une méthode pas à pas arrière ou **Backward selection** pour sélectionner les variables et interactions à conserver.

Commençons avec le modèle complet:

```{r}
# Formulation du modèle avec la fonction glm() et family=poisson(link="log")
mod1<-glm(Nsp~ Location
        + Latitude
        + Elevation
        + LogArea
        + Location:Latitude
        + Location:Elevation
        + Location:LogArea
        ,data=dataAnts
        ,family=poisson(link="log"))
```

A partir de ce modèle complet nous allons donc éliminer pas à pas les interactions non significatives.

```{r}
# Etape 1
drop1(mod1,test="Chi")
```

Les trois interactions ne sont pas significatives. On enlève l'interaction 'Location:Latitude' car c'est la 'moins significative'. On peut également remarquer que la fonction drop1() nous informe que c'est en enlevant cette interaction que l'on obtient le meilleur AIC.

On obtient donc le modèle suivant:

```{r}
# Etape 2
mod1<-glm(Nsp~ Location
        + Latitude
        + Elevation
        + LogArea
        + Location:Elevation
        + Location:LogArea
        ,data=dataAnts
        ,family=poisson(link="log"))

drop1(mod1,test="Chi")
```

De la même façon, on enlève l'interaction 'Location:LogArea'.

```{r}
# Etape 3
mod1<-glm(Nsp~ Location
        + Latitude
        + Elevation
        + LogArea
        + Location:Elevation
        ,data=dataAnts
        ,family=poisson(link="log"))

drop1(mod1,test="Chi")
```

On enlève donc également l'interaction 'Location:Elevation'. On regarde donc maintenant la significativité des variables explicatives.

```{r}
# Etape 4
mod1<-glm(Nsp~ Location
        + Latitude
        + Elevation
        + LogArea
        ,data=dataAnts
        ,family=poisson(link="log"))

drop1(mod1,test="Chi")
```

La variable 'LogArea' n'a pas un effet siginificatif, on l'élimine du modèle.

```{r}
# Etape 5
mod1<-glm(Nsp~ Location
        + Latitude
        + Elevation
        ,data=dataAnts
        ,family=poisson(link="log"))

drop1(mod1,test="Chi")
```

Les variables explicatives restantes sont significatives, on conserve donc ce modèle comme modèle candidat.

On va identifier le modèle candidat basé sur la règle de l'AIC et le mode stepwise. 
```{r modelAIC, include=TRUE}
library(MASS)
# On construit le modèle complet
modelcomplet<- glm(Nsp~ Location
        + Latitude
        + Elevation
        + LogArea
        + Location:Latitude
        + Location:Elevation
        + Location:LogArea
        ,data=dataAnts
        ,family=poisson(link="log"))

# Sélection du modèle sur la base AIC
modfinal<-stepAIC(modelcomplet,direction="both")

# Analyse du modèle final
drop1(modfinal,test="Chi")
summary(modfinal)

```

Remarque : il est recommandé d'utiliser l'AIC avec plus de 40 individus par paramètre, sinon il existe l'AICc.

Les deux procédures (Backward et StepAIC) convergent : nous obtenons les mêmes modèles candidats.

Pour comprendre comment les 3 variables explicatives (Latitude, Elevation, LogArea) influencent la richesse spécifique des fourmis, nous devons analyser les coefficients du modèle.

## 2. Analyse des coefficients (Gabriel)

```{r}
# Coefficients du modèle
summary(mod1)
#                 Estimate Std. Error z value Pr(>|z|)    
#(Intercept)    11.9368121  2.6214970   4.553 5.28e-06 ***
#LocationForest  0.6354389  0.1195664   5.315 1.07e-07 ***
#Latitude       -0.2357930  0.0616638  -3.824 0.000131 ***
#Elevation      -0.0011411  0.0003749  -3.044 0.002337 ** 
```

Ce tableau détaille les coefficients du modèle avec les coefficients associés à chaque effet majeur significatif. Rappelons que pour un facteur, une modalité est appelée "modalité de référence", c'est-à-dire que son coefficient est égal à 0. D'après ce tableau, les coefficients sont :

**Location factor**  
- $Location_{Bog}$ = 0 (modalité de référence du facteur Location)  
- $Location_{Forest}$ = $+0.63^{**}$  
**Latitude covariate**  
- $\beta_{Latitude}$ = $-0.23^{***}$  
**Elevation covariate**  
- $\beta_{Elevation}$ = $-0.001^{***}$

Ainsi, le modèle candidat s'écrit :
$$ log(Species\:Richness) = 11.93^{***} + (Location_{Bog} = 0 ;\:Location_{Forest} = +0.63^{***})\:- 0.23^{***}.Latitude\: -0.001^{***}. Elevation  $$

## 3. Pouvoir explicatif du modèle (Anaelle)

Afin de connaître la qualité de notre modèle, nous allons calculer la distance entre le modèle candidat et le modèle nul. Le modèle nul est un modèle qui résume les données avec un unique paramètre : la moyenne de Y. Ce modèle n'explique pas les données.

Un moyen de connaître la qualité du modèle est de calculer un *pseudo R²*. Pour cela, on détermine la distance entre la déviance du modèle nul et la déviance résiduelle du modèle candidat.

$$Pseudo\:R^2=100\:.\:\frac{Null\:Deviance- Residual\:Deviance}{Null\:Deviance}$$

Nous pouvons calculer le *pseudo R²*, de trois manières différentes. Soit avec la méthode de McFadden, celle de Cox et Snell ou celle de Nagelkerke. Les deux dernières méthodes nécessite le package 'rcompagnon'.

Dans notre exemple, comme vu dans la partie précédente, le modèle nul a une déviance de 102,76 et la déviance résiduelle est de 40,69.

Nous allons donc calculé la qualité avec les commandes suivantes :

```{r deviance, include=TRUE}
# Estimate of deviance explained
(mod1$null.deviance-mod1$deviance)/mod1$null.deviance

# Some others estimates of deviance explained - package 'rcompanion'
nagelkerke(mod1)
```

Ici, l'estiamtion de la déviance expliquée est de 60% ou 75%, en fonction de la méthode utilisée.

```{r Prediction,include=TRUE, fig.height=6, fig.width=6}
plot(fitted(mod1)~dataAnts$Nsp,col='dodgerblue3',pch=16,ylab="Valeurs estimées par le modèle",xlab="Valeurs observées")
abline(0,1)
```

## 4. Validation du modèle (Anaelle)

### Vérification de la surdispersion

### Analyses des résidus

### Vérification des individus influents

### Analyses des résidus avec DHARMa (bonus)

# **CONCLUSION** (Apolline et Kilian)
