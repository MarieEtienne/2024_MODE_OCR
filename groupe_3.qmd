---
title: "groupe 3"
autor: "Gabriel-Marie Arnault, Giuliana Brambilla, Apolline Byrdy, Anaelle Hulbert, Manon Le Bihan, Kilian Prevost, Chloé Van der Swaelmen, Léa Vuille "
editor: visual
---

# **INTRODUCTION** (Apolline et Kilian)

# **EXPLORATION DU JEU DE DONNEES**

## 1. Présentation du jeu de données (Léa et Giuliana)

## 2. Analyse des interactions entre les variables (Chloé et Manon)

# **ANALYSE STATISTIQUE** (Anaelle et Gabriel)

## 1. Construction du modèle (Gabriel)

On cherche à produire le meilleur modèle pour prédire le nombre d'espèces. La variable réponse est un comptage (variable quantitative discrète) de petit effectifs (\<30), la loi appropriée est donc la loi de **Poisson**. Nous allons donc réaliser la modélisation avec un modèle linéaire généralisée de Poisson.

Pour arriver au modèle dit candidat à tester, nous allons partir du modèle dit complet, c'est-à-dire avec toutes les variables explicatives et interactions, et utiliser une méthode pas à pas arrière ou **Backward selection** pour sélectionner les variables et interactions à conserver.

Commençons avec le modèle complet:

```{r}
# Formulation du modèle avec la fonction glm() et family=poisson(link="log")
mod1<-glm(Nsp~ Location
        + Latitude
        + Elevation
        + LogArea
        + Location:Latitude
        + Location:Elevation
        + Location:LogArea
        ,data=dataAnts
        ,family=poisson(link="log"))
```

A partir de ce modèle complet nous allons donc éliminer pas à pas les interactions non significatives.

```{r}
# Etape 1
drop1(mod1,test="Chi")
```

Les trois interactions ne sont pas significatives. On enlève l'interaction 'Location:Latitude' car c'est la 'moins significative'. On peut également remarquer que la fonction drop1() nous informe que c'est en enlevant cette interaction que l'on obtient le meilleur AIC.

On obtient donc le modèle suivant:

```{r}
# Etape 2
mod1<-glm(Nsp~ Location
        + Latitude
        + Elevation
        + LogArea
        + Location:Elevation
        + Location:LogArea
        ,data=dataAnts
        ,family=poisson(link="log"))

drop1(mod1,test="Chi")
```
De la même façon, on enlève l'interaction 'Location:LogArea'.

```{r}
# Etape 3
mod1<-glm(Nsp~ Location
        + Latitude
        + Elevation
        + LogArea
        + Location:Elevation
        ,data=dataAnts
        ,family=poisson(link="log"))

drop1(mod1,test="Chi")
```
On enlève donc également l'interaction 'Location:Elevation'. On regarde donc maintenant la significativité des variables explicatives.

```{r}
# Etape 4
mod1<-glm(Nsp~ Location
        + Latitude
        + Elevation
        + LogArea
        ,data=dataAnts
        ,family=poisson(link="log"))

drop1(mod1,test="Chi")
```
La variable 'LogArea' n'a pas un effet siginificatif, on l'élimine du modèle.

```{r}
# Etape 5
mod1<-glm(Nsp~ Location
        + Latitude
        + Elevation
        ,data=dataAnts
        ,family=poisson(link="log"))

drop1(mod1,test="Chi")
```

Les variables explicatives restantes sont significatives, on conserve donc ce modèle comme modèle candidat.

On va identifier le modèle candidat basé sur la règle de l'AIC et le mode stepwise. 
```{r modelAIC, include=TRUE}
library(MASS)
#On construit le modèle complet
modelcomplet<- glm(Nsp~ Location
        + Latitude
        + Elevation
        + LogArea
        + Location:Latitude
        + Location:Elevation
        + Location:LogArea
        ,data=dataAnts
        ,family=poisson(link="log"))
#Sélection du modèle sur la base AIC
modfinal<-stepAIC(modelcomplet,direction="both")
#Analyse du modèle final
drop1(modfinal,test="Chi")
summary(modfinal)

## AIC si plus de 40 pour indiv/parametres, sinon AICc
```

Remarque : il est recommandé d'utiliser l'AIC avec plus de 40 individus par paramètre, sinon il existe l'AICc.

Les deux procédures (Backward et StepAIC) convergent : nous obtenons les mêmes modèles candidats.

Pour comprendre comment les 3 variables explicatives (Latitude, Elevation, LogArea) influencent la richesse spécifique des fourmis, nous devons analyser les coefficients du modèle.

## 2. Analyse des coefficients (Gabriel)

## 3. Pouvoir explicatif du modèle (Anaelle)

Afin de connaître la qualité de notre modèle, nous allons calculer la distance entre le modèle candidat et le modèle nul. Le modèle nul est un modèle qui résume les données avec un unique paramètre : la moyenne de Y. Ce modèle n'explique pas les données.

Un moyen de connaître la qualité du modèle est de calculer un *pseudo R²*. Pour cela, on détermine la distance entre la déviance du modèle nul et la déviance résiduelle du modèle candidat.

$$Pseudo\:R^2=100\:.\:\frac{Null\:Deviance- Residual\:Deviance}{Null\:Deviance}$$

Nous pouvons calculer le *pseudo R²*, de trois manières différentes. Soit avec la méthode de McFadden, celle de Cox et Snell ou celle de Nagelkerke. Les deux dernières méthodes nécessite le package 'rcompagnon'.

Dans notre exemple, comme vu dans la partie précédente, le modèle nul a une déviance de 102,76 et la déviance résiduelle est de 40,69.

Nous allons donc calculé la qualité avec les commandes suivantes : 

```{r deviance, include=TRUE}
# Estimate of deviance explained
(mod1$null.deviance-mod1$deviance)/mod1$null.deviance

# Some others estimates of deviance explained - package 'rcompanion'
nagelkerke(mod1)
```

Ici, l'estiamtion de la déviance expliquée est de 60% ou 75%, en fonction de la méthode utilisée.

## 4. Validation du modèle (Anaelle)


# **CONCLUSION** (Apolline et Kilian)
