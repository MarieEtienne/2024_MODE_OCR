---
title: "groupe 3"
autor: "Gabriel-Marie Arnault, Giuliana Brambilla, Apolline Byrdy, Anaelle Hulbert, Manon Le Bihan, Kilian Prevost, Chloé Van der Swaelmen, Léa Vuille "
editor: visual
---

# **INTRODUCTION** (Apolline et Kilian)

# **EXPLORATION DU JEU DE DONNEES**

## 1. Présentation du jeu de données (Léa et Giuliana)

## 2. Analyse des interactions entre les variables (Chloé et Manon)

# **ANALYSE STATISTIQUE** (Anaelle et Gabriel)

## 1. Construction du modèle (Gabriel)

On cherche à produire le meilleur modèle pour prédire le nombre d'espèces. La variable réponse est un comptage (variable quantitative discrète) de petit effectifs (\<30), la loi appropriée est donc la loi de **Poisson**. Nous allons donc réaliser la modélisation avec un modèle linéaire généralisée de Poisson.

Pour arriver au modèle dit candidat à tester, nous allons partir du modèle dit complet, c'est-à-dire avec toutes les variables explicatives et interactions, et utiliser une méthode pas à pas arrière ou **Backward selection** pour sélectionner les variables et interactions à conserver.

Commençons avec le modèle complet:

```{r}
# Formulation du modèle avec la fonction glm() et family=poisson(link="log")
mod1<-glm(Nsp~ Location
        + Latitude
        + Elevation
        + LogArea
        + Location:Latitude
        + Location:Elevation
        + Location:LogArea
        ,data=dataAnts
        ,family=poisson(link="log"))
```

A partir de ce modèle complet nous allons donc éliminer pas à pas les interactions non significatives.

```{r}
# Etape 1
drop1(mod1,test="Chi")
```

Les trois interactions ne sont pas significatives. On enlève l'interaction 'Location:Latitude' car c'est la 'moins significative'. On peut également remarquer que la fonction drop1() nous informe que c'est en enlevant cette interaction que l'on obtient le meilleur AIC.

On obtient donc le modèle suivant:

```{r}
# Etape 2
mod1<-glm(Nsp~ Location
        + Latitude
        + Elevation
        + LogArea
        + Location:Elevation
        + Location:LogArea
        ,data=dataAnts
        ,family=poisson(link="log"))

drop1(mod1,test="Chi")
```

De la même façon, on enlève l'interaction 'Location:LogArea'.

```{r}
# Etape 3
mod1<-glm(Nsp~ Location
        + Latitude
        + Elevation
        + LogArea
        + Location:Elevation
        ,data=dataAnts
        ,family=poisson(link="log"))

drop1(mod1,test="Chi")
```

On enlève donc également l'interaction 'Location:Elevation'. On regarde donc maintenant la significativité des variables explicatives.

```{r}
# Etape 4
mod1<-glm(Nsp~ Location
        + Latitude
        + Elevation
        + LogArea
        ,data=dataAnts
        ,family=poisson(link="log"))

drop1(mod1,test="Chi")
```

La variable 'LogArea' n'a pas un effet siginificatif, on l'élimine du modèle.

```{r}
# Etape 5
mod1<-glm(Nsp~ Location
        + Latitude
        + Elevation
        ,data=dataAnts
        ,family=poisson(link="log"))

drop1(mod1,test="Chi")
```

Les variables explicatives restantes sont significatives, on conserve donc ce modèle comme modèle candidat.

On va identifier le modèle candidat basé sur la règle de l'AIC et le mode stepwise.

```{r modelAIC, include=TRUE}
library(MASS)
# On construit le modèle complet
modelcomplet<- glm(Nsp~ Location
        + Latitude
        + Elevation
        + LogArea
        + Location:Latitude
        + Location:Elevation
        + Location:LogArea
        ,data=dataAnts
        ,family=poisson(link="log"))

# Sélection du modèle sur la base AIC
modfinal<-stepAIC(modelcomplet,direction="both")

# Analyse du modèle final
drop1(modfinal,test="Chi")
summary(modfinal)

```

Remarque : il est recommandé d'utiliser l'AIC avec plus de 40 individus par paramètre, sinon il existe l'AICc @YannickOutreman.

Les deux procédures (Backward et StepAIC) convergent : nous obtenons les mêmes modèles candidats.

Pour comprendre comment les 3 variables explicatives (Latitude, Elevation, LogArea) influencent la richesse spécifique des fourmis, nous devons analyser les coefficients du modèle.

## 2. Analyse des coefficients (Gabriel)

```{r}
# Coefficients du modèle
summary(mod1)
#                 Estimate Std. Error z value Pr(>|z|)    
#(Intercept)    11.9368121  2.6214970   4.553 5.28e-06 ***
#LocationForest  0.6354389  0.1195664   5.315 1.07e-07 ***
#Latitude       -0.2357930  0.0616638  -3.824 0.000131 ***
#Elevation      -0.0011411  0.0003749  -3.044 0.002337 ** 
```

Ce tableau détaille les coefficients du modèle avec les coefficients associés à chaque effet majeur significatif. Rappelons que pour un facteur, une modalité est appelée "modalité de référence", c'est-à-dire que son coefficient est égal à 0. D'après ce tableau, les coefficients sont :

**Location factor**\
- $Location_{Bog}$ = 0 (modalité de référence du facteur Location)\
- $Location_{Forest}$ = $+0.63^{**}$\
**Latitude covariate**\
- $\beta_{Latitude}$ = $-0.23^{***}$\
**Elevation covariate**\
- $\beta_{Elevation}$ = $-0.001^{***}$

Ainsi, le modèle candidat s'écrit : $$ log(Species\:Richness) = 11.93^{***} + (Location_{Bog} = 0 ;\:Location_{Forest} = +0.63^{***})\:- 0.23^{***}.Latitude\: -0.001^{***}. Elevation  $$

Rappel : pour modéliser une variable quantitative discrète avec un modèle linéaire généralisé on passe par une fonction de lien, ici avec la loi de Poisson on utilise la fonction log().

## 3. Pouvoir explicatif du modèle (Anaelle)

Afin de connaître la qualité de notre modèle, nous allons calculer la distance entre le modèle candidat et le modèle nul. Le modèle nul est un modèle qui résume les données avec un unique paramètre : la moyenne de $Y$. Ce modèle n'explique pas les données.

Un moyen de connaître la qualité du modèle est de calculer un *pseudo R²*. Pour cela, on détermine la distance entre la déviance du modèle nul et la déviance résiduelle du modèle candidat.

$$Pseudo\:R^2=100\:.\:\frac{Déviance\:nulle- Déviance\:résiduelle}{Déviance\:nulle}$$

Nous pouvons calculer le *pseudo R²* de trois manières différentes. Soit avec la méthode de McFadden, celle de Cox et Snell ou celle de Nagelkerke. Les deux dernières méthodes nécessite le package 'rcompagnon'.

Dans notre exemple, comme vu dans la partie précédente, le modèle nul a une déviance de 102,76 et la déviance résiduelle est de 40,69.

Nous allons donc calculer la qualité du modèle avec les commandes suivantes :

```{r deviance, include=TRUE}
# Estimate of deviance explained
(mod1$null.deviance-mod1$deviance)/mod1$null.deviance

# Some others estimates of deviance explained - package 'rcompanion'
nagelkerke(mod1)
```

Ici, l'estimation de la déviance expliquée est de 60% ou 75%, en fonction de la méthode utilisée.

```{r Prediction,include=TRUE, fig.height=6, fig.width=6}
plot(fitted(mod1)~dataAnts$Nsp,col='dodgerblue3',pch=16,ylab="Valeurs estimées par le modèle",xlab="Valeurs observées")
abline(0,1)
```

## 4. Validation du modèle (Anaelle)

L'*indépendance des résidus* est la seule chose qui limite le modèle linéaire généralisé. L'analyse des résidus permet donc d'identifier d'éventuelles tendances et de vérifier la présence d'unités statistiques influentes.

Dans un premier temps, vérifier la présence de **surdispersion** est indispensable lorsque l'on fait un modèle linéaire généralisé suivant une loi de Poisson. Pour tous les modèles linéaires généralisés utilisant des données de comptage, il faut vérifier l'absence de surdispersion.

Pour cela, nous allons calculer un paramètre appelé 'scale parameter'. Si sa valeur est nettement supérieure à 1 (à partir de 1.6 ou 1.7), il y a surdispersion. Le modèle n'est donc pas valable.

### Vérification de la surdispersion

Quand l'index de dispersion est supérieur à 1,5 , il existe différentes explications.

Cela peut être dû à :

-   Des valeurs abérrantes sont présentes dans le jeu de données. Il faut donc les éliminer.

-   Des covariables sont manquantes. Il faut les ajouter au modèle.

-   Des interactions sont manquantes. Il faut les ajouter au modèle.

-   Une inflation des zéros se produit. Il faut utiliser une regression Binomiale négative à inflation des zéros. (*source*)

-   Une dépendance entre les données et un facteur ou une variable est présente. Il faut utiliser un modèle linéaire général mixte. (*source*)

-   Relation entre les données et les variables ou facteurs n'est pas linéaire. Il faut utiliser un modèle additif généralisé. (*source*)

-   La fonction de lien est mauvaise. Il faut changer la fonction de lien.

-   La variation de $Y$ est grande. Il faut utiliser un modèle linéaire généralisé suivant une loi binomiale négative. (*source*)

Dans notre exemple, nous allons calculer le 'scale parameter'. Pour cela nous allons utiliser la commande :

```{r overdisp, include=TRUE}
# Scale parameter calculation
E1 <- resid(mod1, type = "pearson") # (Y - mu) / sqrt(mu)
N  <- nrow(dataAnts)
p  <- length(coef(mod1))
sum(E1^2) / (N - p)
```

Ici, la dispersion est de 1,02. Il n'y a pas de surdispersion.

### Analyses des résidus

### Vérification des individus influents

### Analyses des résidus avec DHARMa (bonus)

# **CONCLUSION** (Apolline et Kilian)
